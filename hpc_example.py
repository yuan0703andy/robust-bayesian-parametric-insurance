#!/usr/bin/env python3
"""
HPC/OnDemand ç’°å¢ƒä½¿ç”¨ç¤ºä¾‹
Example usage for HPC/OnDemand environments

æ­¤è…³æœ¬å±•ç¤ºå¦‚ä½•åœ¨ HPC ç’°å¢ƒä¸­æ­£ç¢ºé…ç½®å’Œä½¿ç”¨ Bayesian æ¡†æž¶
This script demonstrates how to properly configure and use the Bayesian framework in HPC environments
"""

import numpy as np
from bayesian import RobustBayesianAnalyzer
from skill_scores.basis_risk_functions import BasisRiskType

def hpc_example():
    """HPC ç’°å¢ƒä½¿ç”¨ç¤ºä¾‹"""
    
    print("ðŸ–¥ï¸ HPC/OnDemand ç’°å¢ƒè²è‘‰æ–¯åˆ†æžç¤ºä¾‹")
    print("=" * 60)
    
    # ç”Ÿæˆç¤ºä¾‹æ•¸æ“š
    np.random.seed(42)
    n_total = 200
    
    # æ¨¡æ“¬æå¤±æ•¸æ“š
    hazard_indices = np.random.uniform(25, 65, n_total)
    base_losses = np.where(
        hazard_indices > 45,
        np.random.lognormal(np.log(1e8), 0.8),
        np.where(
            hazard_indices > 35,
            np.random.lognormal(np.log(5e7), 0.6),
            np.random.exponential(1e6) * (np.random.random(n_total) < 0.2)
        )
    )
    
    # æ•¸æ“šåˆ†å‰²
    n_train = 140
    train_losses = base_losses[:n_train] 
    validation_losses = base_losses[n_train:]
    train_indices = hazard_indices[:n_train]
    
    print(f"ðŸ“Š æ•¸æ“š: è¨“ç·´({n_train}) / é©—è­‰({len(validation_losses)})")
    
    # å‰µå»ºæå¤±æƒ…å¢ƒçŸ©é™£
    n_scenarios = 200  # HPC ä¸Šå¯ä»¥ä½¿ç”¨æ›´å¤šæƒ…å¢ƒ
    actual_losses_matrix = np.zeros((n_scenarios, len(train_indices)))
    
    for i in range(n_scenarios):
        scenario_multiplier = np.random.lognormal(0, 0.3)
        actual_losses_matrix[i, :] = train_losses * scenario_multiplier
    
    print(f"ðŸŽ² ç”Ÿæˆ {n_scenarios} å€‹æå¤±æƒ…å¢ƒ")
    
    # åˆå§‹åŒ–åˆ†æžå™¨
    analyzer = RobustBayesianAnalyzer(
        density_ratio_constraint=2.0,
        n_monte_carlo_samples=1000,  # HPC ä¸Šå¯ä»¥ç”¨æ›´å¤šæ¨£æœ¬
        n_mixture_components=4
    )
    
    # ç”¢å“åƒæ•¸é‚Šç•Œ
    product_bounds = {
        'trigger_threshold': (30, 60),
        'payout_amount': (5e7, 3e8),
        'max_payout': (1e9, 1e9)
    }
    
    print("\nðŸš€ åŸ·è¡Œæ•´åˆè²è‘‰æ–¯æœ€ä½³åŒ– (HPC é…ç½®)")
    
    # ============================================================================
    # HPC ç’°å¢ƒé…ç½®ç¤ºä¾‹
    # ============================================================================
    
    # æƒ…å¢ƒ 1: CPU å¯†é›†åž‹ HPC ç¯€é»ž
    print("\nðŸ’» æƒ…å¢ƒ 1: CPU å¯†é›†åž‹ HPC ç¯€é»ž")
    try:
        results_cpu = analyzer.integrated_bayesian_optimization(
            observations=train_losses,
            validation_data=validation_losses,
            hazard_indices=train_indices,
            actual_losses=actual_losses_matrix,
            product_bounds=product_bounds,
            basis_risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0, w_over=0.5,
            # CPU å¯†é›†åž‹é…ç½®
            pymc_backend="cpu",
            pymc_mode="FAST_RUN",      # ç”Ÿç”¢ç’°å¢ƒç”¨å¿«é€Ÿé‹è¡Œ
            n_threads=8,               # ä½¿ç”¨å¤šæ ¸å¿ƒ (æ ¹æ“š HPC ç¯€é»žèª¿æ•´)
            configure_pymc=True
        )
        print("âœ… CPU å¯†é›†åž‹é…ç½®æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ CPU é…ç½®å¤±æ•—: {e}")
    
    # æƒ…å¢ƒ 2: GPU åŠ é€Ÿ HPC ç¯€é»ž
    print("\nðŸŽ® æƒ…å¢ƒ 2: GPU åŠ é€Ÿ HPC ç¯€é»ž")
    try:
        results_gpu = analyzer.integrated_bayesian_optimization(
            observations=train_losses[:50],  # å°è¦æ¨¡æ¸¬è©¦
            validation_data=validation_losses[:20],
            hazard_indices=train_indices[:50],
            actual_losses=actual_losses_matrix[:50, :50],
            product_bounds=product_bounds,
            basis_risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0, w_over=0.5,
            # GPU åŠ é€Ÿé…ç½®
            pymc_backend="gpu",
            pymc_mode="FAST_RUN",
            n_threads=4,               # GPU æ™‚ç·šç¨‹æ•¸å¯ä»¥è¼ƒå°‘
            configure_pymc=True
        )
        print("âœ… GPU åŠ é€Ÿé…ç½®æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ GPU é…ç½®å¤±æ•—: {e}")
        print("   å¯èƒ½åŽŸå› : GPU ä¸å¯ç”¨æˆ– JAX GPU æ”¯æ´æœªå®‰è£")
    
    # æƒ…å¢ƒ 3: è‡ªå‹•æª¢æ¸¬ç’°å¢ƒ
    print("\nðŸ” æƒ…å¢ƒ 3: è‡ªå‹•æª¢æ¸¬ç’°å¢ƒ")
    try:
        results_auto = analyzer.integrated_bayesian_optimization(
            observations=train_losses[:30],  # æœ€å°æ¸¬è©¦
            validation_data=validation_losses[:10],
            hazard_indices=train_indices[:30],
            actual_losses=actual_losses_matrix[:30, :30],
            product_bounds=product_bounds,
            basis_risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0, w_over=0.5,
            # è‡ªå‹•æª¢æ¸¬é…ç½®
            pymc_backend="auto",       # è®“ç³»çµ±è‡ªå‹•é¸æ“‡
            pymc_mode="FAST_COMPILE",  # å¿«é€Ÿæ¸¬è©¦
            n_threads=None,            # è‡ªå‹•è¨­ç½®
            configure_pymc=True
        )
        print("âœ… è‡ªå‹•æª¢æ¸¬é…ç½®æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ è‡ªå‹•æª¢æ¸¬é…ç½®å¤±æ•—: {e}")
    
    # ============================================================================
    # HPC ä½¿ç”¨å»ºè­°
    # ============================================================================
    print("\nðŸ’¡ HPC/OnDemand ä½¿ç”¨å»ºè­°")
    print("-" * 40)
    print("ðŸ“‹ é…ç½®é¸æ“‡æŒ‡å—:")
    print()
    print("ðŸ–¥ï¸ CPU ç¯€é»ž (æŽ¨è–¦):")
    print("   pymc_backend='cpu'")
    print("   pymc_mode='FAST_RUN'")
    print("   n_threads=ç¯€é»žæ ¸å¿ƒæ•¸ (å¦‚ 8, 16, 32)")
    print()
    print("ðŸŽ® GPU ç¯€é»ž:")
    print("   pymc_backend='gpu'")
    print("   pymc_mode='FAST_RUN'") 
    print("   n_threads=4-8")
    print("   éœ€è¦: pip install jax[cuda] æˆ– jax[tpu]")
    print()
    print("ðŸ” ä¸ç¢ºå®šç’°å¢ƒ:")
    print("   pymc_backend='auto'")
    print("   pymc_mode='FAST_COMPILE' (æ¸¬è©¦)")
    print("   n_threads=None (è‡ªå‹•)")
    print()
    print("âš¡ æ€§èƒ½å„ªåŒ–:")
    print("   - å¢žåŠ  n_monte_carlo_samples (500-2000)")
    print("   - å¢žåŠ æå¤±æƒ…å¢ƒæ•¸ (200-1000)")
    print("   - ä½¿ç”¨æ›´å¤§çš„æ•¸æ“šé›†")
    print("   - è€ƒæ…®ä¸¦è¡ŒåŒ–å¤šå€‹åˆ†æž")
    print()
    print("ðŸ”§ æ•…éšœæŽ’é™¤:")
    print("   - å¦‚æžœ Metal éŒ¯èª¤ â†’ pymc_backend='cpu'")
    print("   - å¦‚æžœè¨˜æ†¶é«”ä¸è¶³ â†’ æ¸›å°‘æ¨£æœ¬æ•¸å’Œæƒ…å¢ƒæ•¸")
    print("   - å¦‚æžœç·¨è­¯æ…¢ â†’ pymc_mode='FAST_COMPILE'")
    print("   - å¦‚æžœç·šç¨‹è¡çª â†’ n_threads=1")


def create_hpc_batch_script():
    """å‰µå»º HPC batch è…³æœ¬ç¤ºä¾‹"""
    
    batch_script = """#!/bin/bash
#SBATCH --job-name=bayesian_analysis
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --mem=64G
#SBATCH --time=04:00:00
#SBATCH --partition=normal

# è¼‰å…¥å¿…è¦æ¨¡çµ„
module load python/3.9
module load gcc/9.3.0

# å‰µå»ºè™›æ“¬ç’°å¢ƒ (å¦‚æžœéœ€è¦)
# python -m venv bayesian_env
# source bayesian_env/bin/activate

# å®‰è£ä¾è³´ (é¦–æ¬¡é‹è¡Œæ™‚)
# pip install pymc pytensor jax jaxlib numpy pandas scipy

# è¨­ç½®ç’°å¢ƒè®Šæ•¸
export OMP_NUM_THREADS=16
export MKL_NUM_THREADS=16
export NUMEXPR_MAX_THREADS=16

# é‹è¡Œåˆ†æž
echo "é–‹å§‹è²è‘‰æ–¯åˆ†æž..."
python hpc_example.py

echo "åˆ†æžå®Œæˆ"
"""
    
    return batch_script


if __name__ == "__main__":
    hpc_example()
    
    # é¡¯ç¤º batch è…³æœ¬
    print("\n" + "=" * 60)
    print("ðŸ“„ HPC Batch è…³æœ¬ç¤ºä¾‹:")
    print("=" * 60)
    print(create_hpc_batch_script())