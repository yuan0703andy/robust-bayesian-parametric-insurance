#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
04_traditional_parm_insurance.py
=================================
Traditional Parametric Insurance Analysis using existing framework

Simply configures and runs the existing analysis components for 
traditional RMSE-based basis risk evaluation.
"""
# %%
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pickle
from pathlib import Path

# %%
def main():
    """
    Main program: Traditional basis risk analysis using existing framework
    """
    print("=" * 80)
    print("Traditional Parametric Insurance Analysis")
    print("Using existing insurance_analysis_refactored framework")
    print("RMSE-based deterministic evaluation")
    print("=" * 80)
    
    # Load required data
    print("\nğŸ“‚ Loading data...")
    
    # Load products
    try:
        with open("results/insurance_products/products.pkl", 'rb') as f:
            products = pickle.load(f)
        print(f"âœ… Loaded {len(products)} insurance products")
    except FileNotFoundError:
        print("âŒ Products not found. Run 03_insurance_product.py first.")
        return
    
    # Load spatial analysis results  
    try:
        with open("results/spatial_analysis/cat_in_circle_results.pkl", 'rb') as f:
            spatial_results = pickle.load(f)
        wind_indices_dict = spatial_results['indices']
        # Extract main wind index for analysis (using 30km max as primary)
        wind_indices = wind_indices_dict.get('cat_in_circle_30km_max', np.array([]))
        print("âœ… Loaded spatial analysis results")
        print(f"   Using primary index: cat_in_circle_30km_max ({len(wind_indices)} events)")
    except FileNotFoundError:
        print("âŒ Spatial results not found. Run 02_spatial_analysis.py first.")
        return
    
    # Load CLIMADA data
    try:
        with open("results/climada_data/climada_complete_data.pkl", 'rb') as f:
            climada_data = pickle.load(f)
        print("âœ… Loaded CLIMADA data (çœŸå¯¦æ•¸æ“š)")
    except FileNotFoundError:
        print("âš ï¸ Using synthetic loss data (é¢¨é€Ÿç›¸é—œ)")
        np.random.seed(42)
        # å‰µå»ºèˆ‡é¢¨é€Ÿç›¸é—œçš„åˆæˆæå¤±æ•¸æ“š
        n_events = len(wind_indices) if len(wind_indices) > 0 else 1000
        
        # åŸºæ–¼é¢¨é€Ÿç”Ÿæˆæå¤±ï¼ˆé¢¨é€Ÿè¶Šé«˜ï¼Œæå¤±è¶Šå¤§ï¼‰
        # ä½¿ç”¨æŒ‡æ•¸é—œä¿‚æ¨¡æ“¬çœŸå¯¦çš„é¢¨ç½æå¤±
        synthetic_losses = np.zeros(n_events)
        for i, wind in enumerate(wind_indices[:n_events]):
            if wind > 33:  # é¢±é¢¨é–¾å€¼
                # æå¤±èˆ‡é¢¨é€Ÿçš„3.5æ¬¡æ–¹æˆæ­£æ¯”ï¼ˆç¬¦åˆEmanuelå…¬å¼ï¼‰
                base_loss = (wind / 33) ** 3.5 * 1e8
                # åŠ å…¥éš¨æ©Ÿè®Šç•°
                synthetic_losses[i] = base_loss * np.random.lognormal(0, 0.5)
            else:
                # ä½æ–¼é¢±é¢¨é–¾å€¼ï¼Œå°æ¦‚ç‡ç”¢ç”Ÿå°æå¤±
                if np.random.random() < 0.05:
                    synthetic_losses[i] = np.random.lognormal(10, 2) * 1e3
        
        climada_data = {
            'impact': type('MockImpact', (), {
                'at_event': synthetic_losses
            })()
        }
    
    # Ensure data arrays have matching lengths
    observed_losses = climada_data.get('impact').at_event if 'impact' in climada_data else np.array([])
    
    # Truncate to minimum length to ensure compatibility
    min_length = min(len(wind_indices), len(observed_losses))
    if min_length > 0:
        wind_indices = wind_indices[:min_length]
        observed_losses = observed_losses[:min_length]
        print(f"   Aligned data to {min_length} events")
    else:
        print("âŒ No valid data found")
        return
    
    print("\nğŸ“Š åŸ·è¡Œå‚³çµ±åŸºå·®é¢¨éšªåˆ†æ...")
    print("   â€¢ æ–¹æ³•: å¤šç¨®åŸºå·®é¢¨éšªå®šç¾©")
    print("   â€¢ æŒ‡æ¨™: çµ•å°ã€ä¸å°ç¨±ã€åŠ æ¬Šä¸å°ç¨±ã€RMSEã€ç›¸å°çµ•å°ã€ç›¸å°åŠ æ¬Šä¸å°ç¨± åŸºå·®é¢¨éšª") 
    print("   â€¢ æ–¹å¼: ç¢ºå®šæ€§é»ä¼°è¨ˆ + ç›¸å°åŸºå·®é¢¨éšªï¼ˆè§£æ±ºæ¥µç«¯äº‹ä»¶ä¸»å°å•é¡Œï¼‰")
    print(f"   â€¢ ä½¿ç”¨é ç”Ÿæˆç”¢å“: {len(products)} å€‹")
    
    # Import basis risk calculator (ä½¿ç”¨æ•´åˆçš„ skill_scores æ¨¡çµ„)
    from skill_scores.basis_risk_functions import BasisRiskCalculator, BasisRiskType, BasisRiskConfig
    
    # åˆå§‹åŒ–ä¸åŒé¡å‹çš„åŸºå·®é¢¨éšªè¨ˆç®—å™¨ (åŒ…å«ç›¸å°åŸºå·®é¢¨éšª)
    calculators = {
        # å‚³çµ±çµ•å°åŸºå·®é¢¨éšª
        'absolute': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.ABSOLUTE, 
            normalize=False  # é—œé–‰æ¨™æº–åŒ–ä»¥é¡¯ç¤ºå¯¦éš›å·®ç•°
        )),
        'asymmetric': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.ASYMMETRIC,
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),  
        'weighted': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0,  # è³ ä¸å¤ çš„æ‡²ç½°æ¬Šé‡
            w_over=0.5,   # è³ å¤šäº†çš„æ‡²ç½°æ¬Šé‡
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),
        'rmse': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RMSE,
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),
        # æ–°å¢ç›¸å°åŸºå·®é¢¨éšª - ä¾†è‡ª 07_relative_basis_risk_analysis.py
        'relative_absolute': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RELATIVE_ABSOLUTE,
            min_loss_threshold=1e7,  # æœ€å°æå¤±é–¾å€¼ 1åƒè¬
            normalize=False
        )),
        'relative_weighted': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RELATIVE_WEIGHTED_ASYMMETRIC,
            w_under=2.0,
            w_over=0.5,
            min_loss_threshold=1e7,  # æœ€å°æå¤±é–¾å€¼ 1åƒè¬
            normalize=False
        ))
    }
    
    # åˆ†æçµæœå„²å­˜
    analysis_results = []
    
    print(f"   åˆ†æç”¢å“æ•¸é‡: {len(products)}")
    print(f"   äº‹ä»¶æ•¸é‡: {len(wind_indices)}")
    
    # æª¢æŸ¥å‰3å€‹ç”¢å“çš„è¨­ç½® (èª¿è©¦ä¿¡æ¯)
    print(f"\nğŸ” ç”¢å“è¨­ç½®æª¢æŸ¥ (å‰3å€‹):")
    for i in range(min(3, len(products))):
        product = products[i]
        print(f"  {product['product_id']}: é–¾å€¼={product['trigger_thresholds']}")
        print(f"    è³ ä»˜æ¯”ä¾‹={product['payout_ratios']}, æœ€å¤§è³ ä»˜={product['max_payout']}")
    
    # æª¢æŸ¥é¢¨é€Ÿæ•¸æ“šç¯„åœ
    print(f"\nğŸŒªï¸  é¢¨é€Ÿæ•¸æ“šæª¢æŸ¥:")
    print(f"   é¢¨é€Ÿç¯„åœ: {np.min(wind_indices):.2f} - {np.max(wind_indices):.2f}")
    print(f"   é¢¨é€Ÿå¹³å‡: {np.mean(wind_indices):.2f}")
    print(f"   é¢¨é€Ÿæ¨™æº–å·®: {np.std(wind_indices):.2f}")
    
    for i, product in enumerate(products):
        if (i + 1) % 20 == 0:
            print(f"   é€²åº¦: {i+1}/{len(products)}")
        
        # è¨ˆç®—éšæ¢¯å¼è³ ä»˜ (ä½¿ç”¨æ•´åˆçš„ skill_scores æ¨¡çµ„)
        from skill_scores.basis_risk_functions import calculate_step_payouts_batch
        
        payouts = calculate_step_payouts_batch(
            wind_indices,
            product['trigger_thresholds'],
            product['payout_ratios'],
            product['max_payout']
        )
        
        # èª¿è©¦ï¼šæª¢æŸ¥å‰å¹¾å€‹ç”¢å“çš„è³ ä»˜åˆ†ä½ˆ
        if i < 3:
            print(f"  ç”¢å“ {product['product_id']}: è³ ä»˜ç¯„åœ={np.min(payouts):.2e}-{np.max(payouts):.2e}, è§¸ç™¼ç‡={np.mean(payouts > 0):.3f}")
        
        # è¨ˆç®—å„ç¨®åŸºå·®é¢¨éšªæŒ‡æ¨™
        product_result = {
            'product_id': product['product_id'],
            'name': product.get('name', 'Unknown'),
            'structure_type': product['structure_type'],
            'radius_km': product.get('radius_km', 30),
            'n_thresholds': len(product['trigger_thresholds']),
            'max_payout': product['max_payout']
        }
        
        # ä½¿ç”¨ä¸åŒçš„åŸºå·®é¢¨éšªè¨ˆç®—å™¨
        for risk_name, calculator in calculators.items():
            try:
                risk_value = calculator.calculate_basis_risk(observed_losses, payouts)
                product_result[f'{risk_name}_risk'] = risk_value
            except Exception as e:
                print(f"Warning: Failed to calculate {risk_name} risk for {product['product_id']}: {e}")
                product_result[f'{risk_name}_risk'] = np.inf
        
        # è¨ˆç®—é¡å¤–çš„å‚³çµ±æŒ‡æ¨™
        try:
            product_result['correlation'] = np.corrcoef(observed_losses, payouts)[0,1] if np.std(payouts) > 0 else 0
            product_result['trigger_rate'] = np.mean(payouts > 0)
            product_result['mean_payout'] = np.mean(payouts)
            product_result['coverage_ratio'] = np.sum(payouts) / np.sum(observed_losses) if np.sum(observed_losses) > 0 else 0
            product_result['basis_risk_std'] = np.std(observed_losses - payouts)
        except Exception as e:
            print(f"Warning: Failed to calculate additional metrics for {product['product_id']}: {e}")
            for key in ['correlation', 'trigger_rate', 'mean_payout', 'coverage_ratio', 'basis_risk_std']:
                if key not in product_result:
                    product_result[key] = 0
        
        analysis_results.append(product_result)
    
    # å‰µå»ºçµæœDataFrame
    import pandas as pd
    results_df = pd.DataFrame(analysis_results)
    
    # å°‡æ¡†æ¶èª¿ç”¨æ›¿æ›ç‚ºæˆ‘å€‘çš„åˆ†æçµæœ
    class TraditionalAnalysisResults:
        def __init__(self, results_df):
            self.results_df = results_df
            self.best_products = self._find_best_products()
            self.summary_statistics = self._generate_summary()
        
        def _find_best_products(self):
            best_products = {}
            metrics = ['absolute_risk', 'asymmetric_risk', 'weighted_risk', 'rmse_risk']
            
            for metric in metrics:
                if metric in self.results_df.columns:
                    best_idx = self.results_df[metric].idxmin()
                    if not pd.isna(best_idx):
                        best_product = self.results_df.iloc[best_idx]
                        # ä½¿ç”¨å­—å…¸è€Œä¸æ˜¯å‹•æ…‹é¡åˆ¥ï¼Œé¿å… pickle å•é¡Œ
                        best_products[f'best_{metric}'] = {
                            'product_id': best_product['product_id'],
                            'name': best_product['name'], 
                            'description': f"{best_product['structure_type']} threshold product"
                        }
            
            return best_products
        
        def _generate_summary(self):
            return {
                'total_products': len(self.results_df),
                'analysis_type': 'Traditional Basis Risk Analysis'
            }
    
    results = TraditionalAnalysisResults(results_df)
    
    # Extract and display results
    print("\nâœ… Traditional basis risk analysis complete!")
    print(f"ğŸ“Š Analyzed {len(products)} products with multiple basis risk definitions")
    
    # Display comprehensive basis risk analysis results
    print("\nğŸ“‹ åŸºå·®é¢¨éšªåˆ†ææ‘˜è¦:")
    print("=" * 60)
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"ç¸½ç”¢å“æ•¸: {len(results_df)}")
    print(f"ç”¢å“çµæ§‹åˆ†å¸ƒ:")
    structure_counts = results_df['structure_type'].value_counts()
    for structure, count in structure_counts.items():
        print(f"  â€¢ {structure.capitalize()}: {count} ç”¢å“")
    
    # åŸºå·®é¢¨éšªçµ±è¨ˆæ‘˜è¦ï¼ˆåŒ…å«ç›¸å°åŸºå·®é¢¨éšªï¼‰
    print(f"\nğŸ¯ åŸºå·®é¢¨éšªæŒ‡æ¨™çµ±è¨ˆ:")
    risk_metrics = ['absolute_risk', 'asymmetric_risk', 'weighted_risk', 'rmse_risk', 
                    'relative_absolute_risk', 'relative_weighted_risk']
    
    for metric in risk_metrics:
        if metric in results_df.columns and not results_df[metric].isna().all():
            mean_risk = results_df[metric].mean()
            min_risk = results_df[metric].min()
            max_risk = results_df[metric].max()
            print(f"  â€¢ {metric.replace('_', ' ').title()}:")
            print(f"    å¹³å‡: {mean_risk:.2e}, æœ€å°: {min_risk:.2e}, æœ€å¤§: {max_risk:.2e}")
    
    # é¡¯ç¤ºæœ€ä½³ç”¢å“
    if hasattr(results, 'best_products') and results.best_products:
        print(f"\nğŸ† å„æŒ‡æ¨™æœ€ä½³ç”¢å“:")
        print("-" * 40)
        
        count = 0
        for metric, product in results.best_products.items():
            if count >= 8:  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
                break
            count += 1
            
            metric_name = metric.replace('best_', '').replace('_', ' ').title()
            print(f"{count}. {metric_name}: {product['name']}")
            print(f"   ç”¢å“ID: {product['product_id']}")
            print(f"   æè¿°: {product['description']}")
            
            # é¡¯ç¤ºè©²ç”¢å“çš„å…·é«”é¢¨éšªå€¼
            product_row = results_df[results_df['product_id'] == product['product_id']]
            if not product_row.empty:
                risk_col = metric.replace('best_', '') + '_risk' if not metric.endswith('_risk') else metric.replace('best_', '')
                if risk_col in product_row.columns:
                    risk_value = product_row[risk_col].iloc[0]
                    print(f"   é¢¨éšªå€¼: {risk_value:.6f}")
            print()
    
    # Top 10 ç¶œåˆæ’å (ä½¿ç”¨åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª)
    print(f"\nğŸ“ˆ Top 10 ç”¢å“æ’å (æŒ‰åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª):")
    print("-" * 40)
    
    if 'weighted_risk' in results_df.columns:
        top_10 = results_df.nsmallest(10, 'weighted_risk')
        
        for i, (_, row) in enumerate(top_10.iterrows(), 1):
            print(f"{i:2d}. {row['product_id']} ({row['structure_type']})")
            print(f"     åŠ æ¬ŠåŸºå·®é¢¨éšª: {row['weighted_risk']:.2e}")
            print(f"     çµ•å°åŸºå·®é¢¨éšª: {row.get('absolute_risk', 'N/A'):.2e}")
            print(f"     ä¸å°ç¨±åŸºå·®é¢¨éšª: {row.get('asymmetric_risk', 'N/A'):.2e}")
            print(f"     RMSEé¢¨éšª: {row.get('rmse_risk', 'N/A'):.2e}")
            print(f"     è§¸ç™¼ç‡: {row.get('trigger_rate', 'N/A'):.3f}")
            print(f"     ç›¸é—œä¿‚æ•¸: {row.get('correlation', 'N/A'):.3f}")
            print()
    
    # é¡å¤–çµ±è¨ˆ
    print(f"\nğŸ“Š é¡å¤–çµ±è¨ˆæŒ‡æ¨™:")
    avg_trigger_rate = results_df['trigger_rate'].mean()
    avg_correlation = results_df['correlation'].mean()
    avg_coverage = results_df['coverage_ratio'].mean()
    
    print(f"  â€¢ å¹³å‡è§¸ç™¼ç‡: {avg_trigger_rate:.3f}")
    print(f"  â€¢ å¹³å‡ç›¸é—œä¿‚æ•¸: {avg_correlation:.3f}")
    print(f"  â€¢ å¹³å‡è¦†è“‹ç‡: {avg_coverage:.3f}")
    
    # Skill Score è©•ä¼°ï¼ˆæ›´æ–°åŒ…å«ç›¸å°åŸºå·®é¢¨éšªï¼‰
    print(f"\nğŸ¯ Skill Score è©•ä¼°:")
    print(f"  åŸºå·®é¢¨éšªåˆ†æä¸­çš„ä¸åŒæå¤±å‡½æ•¸æ¯”è¼ƒ:")
    print(f"  â€¢ çµ•å°åŸºå·®é¢¨éšª: å°ç¨±æ‡²ç½°æ‰€æœ‰åå·®")
    print(f"  â€¢ ä¸å°ç¨±åŸºå·®é¢¨éšª: åªæ‡²ç½°è³ ä»˜ä¸è¶³")
    print(f"  â€¢ åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª: ä¸å°ç¨±æ‡²ç½°ï¼Œæ¬Šé‡åŒ–è€ƒæ…®")
    print(f"  â€¢ RMSEé¢¨éšª: å‚³çµ±çµ±è¨ˆæ–¹æ³•ï¼Œå¹³æ–¹æ‡²ç½°")
    print(f"  â€¢ ç›¸å°çµ•å°åŸºå·®é¢¨éšª: æ¨™æº–åŒ–è™•ç†ï¼Œé¿å…æ¥µç«¯äº‹ä»¶ä¸»å°")
    print(f"  â€¢ ç›¸å°åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª: çµåˆæ¬Šé‡èˆ‡æ¨™æº–åŒ–çš„å„ªå‹¢")
    
    # ç›¸å° vs çµ•å°åŸºå·®é¢¨éšªå°æ¯”åˆ†æ
    print(f"\nğŸ” ç›¸å° vs çµ•å°åŸºå·®é¢¨éšªå°æ¯”:")
    if 'relative_weighted_risk' in results_df.columns and 'weighted_risk' in results_df.columns:
        abs_risk_max = results_df['weighted_risk'].max()
        rel_risk_max = results_df['relative_weighted_risk'].max()
        abs_risk_dominated = (results_df['weighted_risk'].quantile(0.9) - results_df['weighted_risk'].quantile(0.1)) / results_df['weighted_risk'].mean()
        rel_risk_spread = (results_df['relative_weighted_risk'].quantile(0.9) - results_df['relative_weighted_risk'].quantile(0.1)) / results_df['relative_weighted_risk'].mean()
        
        print(f"  â€¢ çµ•å°é¢¨éšªæœ€å¤§å€¼: {abs_risk_max:.2e}")
        print(f"  â€¢ ç›¸å°é¢¨éšªæœ€å¤§å€¼: {rel_risk_max:.3f}")
        print(f"  â€¢ çµ•å°é¢¨éšªè®Šç•°åº¦: {abs_risk_dominated:.2f}")
        print(f"  â€¢ ç›¸å°é¢¨éšªè®Šç•°åº¦: {rel_risk_spread:.2f}")
        print(f"  â€¢ ç›¸å°åŸºå·®é¢¨éšªæœ‰æ•ˆæ¸›å°‘äº†æ¥µç«¯äº‹ä»¶å°é¢¨éšªè©•ä¼°çš„ä¸»å°æ•ˆæ‡‰")
    
    # Save results
    output_dir = "results/traditional_basis_risk_analysis"
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # Save detailed DataFrame  
    results_df.to_csv(f"{output_dir}/detailed_results.csv", index=False)
    print(f"ğŸ’¾ Detailed results saved to: {output_dir}/detailed_results.csv")
    
    # Save analysis object
    with open(f"{output_dir}/analysis_results.pkl", 'wb') as f:
        pickle.dump({
            'results_df': results_df,
            'best_products': results.best_products,
            'summary_statistics': results.summary_statistics,
            'analysis_config': {
                'risk_types': list(calculators.keys()),
                'n_products': len(products),
                'n_events': len(wind_indices),
                'undercompensation_weight': 2.0,
                'overcompensation_weight': 0.5
            }
        }, f)
    
    print(f"ğŸ’¾ Analysis object saved to: {output_dir}/analysis_results.pkl")
    
    # Generate summary report
    from datetime import datetime
    
    report_lines = [
        "Traditional Basis Risk Analysis Report",
        "=" * 40,
        f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"Products Analyzed: {len(products)}",
        f"Events Analyzed: {len(wind_indices)}",
        "",
        "Basis Risk Definitions Used:",
        "1. Absolute Basis Risk: |Actual_Loss - Payout|",
        "2. Asymmetric Basis Risk: max(0, Actual_Loss - Payout)",
        "3. Weighted Asymmetric: 2.0*undercomp + 0.5*overcomp",
        "4. RMSE Risk: sqrt(mean((Actual_Loss - Payout)Â²))",
        "",
        "Key Findings:"
    ]
    
    # Add top performers for each metric
    for metric in risk_metrics:
        if metric in results_df.columns and not results_df[metric].isna().all():
            best_product = results_df.loc[results_df[metric].idxmin()]
            best_value = results_df[metric].min()
            report_lines.append(f"- Best {metric.replace('_', ' ').title()}: {best_product['product_id']} (Value: {best_value:.6f})")
    
    report_text = "\n".join(report_lines)
    with open(f"{output_dir}/analysis_report.txt", 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print(f"ğŸ“„ Analysis report saved to: {output_dir}/analysis_report.txt")
    
    print(f"\nğŸ‰ å‚³çµ±åŸºå·®é¢¨éšªåˆ†æå®Œæˆï¼")
    print("   ä½¿ç”¨çš„æ–¹æ³• (æ•´åˆä¾†è‡ª 07_relative_basis_risk_analysis.py):")
    print("   â€¢ çµ•å°åŸºå·®é¢¨éšªè¨ˆç®— (å°ç¨±æ‡²ç½°)")
    print("   â€¢ ä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (åªæ‡²ç½°è³ ä»˜ä¸è¶³)")
    print("   â€¢ åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (æ¬Šé‡åŒ–æ‡²ç½°)")
    print("   â€¢ å‚³çµ±RMSEé¢¨éšªè¨ˆç®—")
    print("   â€¢ ç›¸å°çµ•å°åŸºå·®é¢¨éšªè¨ˆç®— (æ¨™æº–åŒ–é¿å…æ¥µç«¯äº‹ä»¶ä¸»å°)")
    print("   â€¢ ç›¸å°åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (çµåˆæ¨™æº–åŒ–èˆ‡æ¬Šé‡)")
    print("   â€¢ Skill Scoreå¤šé‡è©•ä¼°æ¶æ§‹")
    print("   â€¢ çµ•å° vs ç›¸å°åŸºå·®é¢¨éšªå°æ¯”åˆ†æ")
    
    return results

# %%
if __name__ == "__main__":
    results = main()
# %%
