#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
04_traditional_parm_insurance.py
=================================
Traditional Parametric Insurance Analysis using existing framework

Simply configures and runs the existing analysis components for 
traditional RMSE-based basis risk evaluation.
"""
# %%
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pickle
from pathlib import Path

# Import hospital-based configuration
from config.hospital_based_payout_config import HospitalPayoutConfig, create_hospital_based_config

# %%
def main():
    """
    Main program: Traditional basis risk analysis using existing framework
    """
    print("=" * 80)
    print("Traditional Parametric Insurance Analysis")
    print("Using existing insurance_analysis_refactored framework")
    print("RMSE-based deterministic evaluation")
    print("=" * 80)
    
    # Load required data
    print("\nğŸ“‚ Loading data...")
    
    # Load products
    with open("results/insurance_products/products.pkl", 'rb') as f:
        products = pickle.load(f)
    print(f"âœ… Loaded {len(products)} insurance products")
    
    # é…ç½®åŸºæ–¼é†«é™¢çš„è³ ä»˜
    print("\nğŸ¥ Configuring hospital-based payouts...")
    hospital_config = create_hospital_based_config(
        n_hospitals=20,  # é è¨­20å®¶é†«é™¢
        base_value_per_hospital=1e7  # æ¯å®¶é†«é™¢$10M USD
    )
    
    # æ ¹æ“šç”¢å“é¡å‹æ›´æ–°æœ€å¤§è³ ä»˜
    total_exposure = hospital_config.calculate_total_exposure()
    print(f"   ğŸ’° ç¸½æ›éšªå€¼: ${total_exposure:,.0f}")
    
    # ç²å–ä¸åŒç”¢å“é¡å‹çš„æœ€å¤§è³ ä»˜ï¼ˆä½¿ç”¨50kmæ¨™æº–åŠå¾‘ï¼‰
    max_payouts = hospital_config.get_max_payout_amounts(total_exposure, radius_km=50)
    print(f"   ğŸ“Š æœ€å¤§è³ ä»˜é…ç½®:")
    for ptype, amount in max_payouts.items():
        print(f"      - {ptype}: ${amount:,.0f}")
    
    # æ›´æ–°ç”¢å“çš„æœ€å¤§è³ ä»˜å€¼
    for product in products:
        # æ ¹æ“šç”¢å“çµæ§‹é¡å‹è¨­å®šæœ€å¤§è³ ä»˜
        structure_type = product.get('structure_type', 'single')
        if structure_type in max_payouts:
            original_payout = product['max_payout']
            product['max_payout'] = max_payouts[structure_type]
            # èª¿æ•´è³ ä»˜æ¯”ä¾‹ä»¥ä¿æŒç›¸å°é—œä¿‚
            if original_payout > 0:
                scale_factor = max_payouts[structure_type] / original_payout
                # å¦‚æœéœ€è¦ï¼Œä¹Ÿå¯ä»¥èª¿æ•´è³ ä»˜æ¯”ä¾‹
                # product['payout_ratios'] = [r * scale_factor for r in product['payout_ratios']]
    
    print(f"   âœ… å·²æ›´æ–° {len(products)} å€‹ç”¢å“çš„æœ€å¤§è³ ä»˜å€¼")
    
    # Load spatial analysis results  
    with open("results/spatial_analysis/cat_in_circle_results.pkl", 'rb') as f:
        spatial_results = pickle.load(f)
    wind_indices_dict = spatial_results['indices']
    print("âœ… Loaded spatial analysis results")
    print("ğŸŒªï¸  Available Cat-in-Circle indices:")
    for key in wind_indices_dict.keys():
        print(f"   â€¢ {key}: {len(wind_indices_dict[key])} events")
    
    # æ³¨æ„ï¼šç”¢å“å·²ç¶“åŒ…å«ä¸åŒåŠå¾‘çš„é…ç½®ï¼Œéœ€è¦æ ¹æ“šæ¯å€‹ç”¢å“çš„åŠå¾‘é¸æ“‡å°æ‡‰çš„é¢¨é€Ÿæ•¸æ“š
    # é€™è£¡æˆ‘å€‘å…ˆè¼‰å…¥æ‰€æœ‰åŠå¾‘çš„æ•¸æ“šä»¥ä¾›å¾ŒçºŒä½¿ç”¨
    print("\nğŸ“ æº–å‚™å¤šåŠå¾‘é¢¨é€Ÿæ•¸æ“š...")
    radius_wind_indices = {}
    for radius in [15, 30, 50, 75, 100]:
        key = f'cat_in_circle_{radius}km_max'
        if key in wind_indices_dict:
            radius_wind_indices[radius] = wind_indices_dict[key]
            print(f"   âœ… {radius}kmåŠå¾‘: {len(wind_indices_dict[key])} events")
        else:
            print(f"   âš ï¸ {radius}kmåŠå¾‘æ•¸æ“šä¸å¯ç”¨")
    
    # ä½¿ç”¨50kmä½œç‚ºé è¨­ï¼ˆç”¨æ–¼æ•¸æ“šå°é½Šæª¢æŸ¥ï¼‰
    default_wind_indices = radius_wind_indices.get(50, 
                          radius_wind_indices.get(30, 
                          list(radius_wind_indices.values())[0] if radius_wind_indices else np.array([])))
    
    # è¼‰å…¥CLIMADAæ•¸æ“š
    print("ğŸ“‚ Loading CLIMADA data...")
    
    # ç›´æ¥è¼‰å…¥CLIMADAæ•¸æ“š
    with open("results/climada_data/climada_complete_data.pkl", 'rb') as f:
        climada_data = pickle.load(f)
    
    print("âœ… Successfully loaded CLIMADA data")
    
    # æå–impactæ•¸æ“š
    impact_obj = climada_data['impact']
    observed_losses = impact_obj.at_event
    print(f"   âœ… CLIMADAæå¤±æ•¸æ“š: {len(observed_losses)} events")
    print(f"   æå¤±ç¯„åœ: ${np.min(observed_losses):,.0f} - ${np.max(observed_losses):,.0f}")
    print(f"   å¹³å‡æå¤±: ${np.mean(observed_losses):,.0f}")
    
    # å°‡CLIMADAæå¤±è§£é‡‹ç‚ºé†«é™¢èšåˆæå¤±
    print("ğŸ¥ å°‡CLIMADAæå¤±è§£é‡‹ç‚ºé†«é™¢èšåˆæå¤±...")
    
    # ä½¿ç”¨èˆ‡02ç›¸åŒçš„æ–¹æ³•ç²å–é†«é™¢æ•¸æ“šï¼ˆç”¨æ–¼è¨ˆæ•¸å’Œé…ç½®ï¼‰
    from exposure_modeling.hospital_osm_extraction import get_nc_hospitals
    
    # ä½¿ç”¨æ¨¡æ“¬é†«é™¢æ•¸æ“šï¼ˆèˆ‡02ä¿æŒä¸€è‡´ï¼‰
    gdf_hospitals_calc, _ = get_nc_hospitals(
        use_mock=True,  # èˆ‡02_spatial_analysisä¸€è‡´ä½¿ç”¨mockæ•¸æ“š
        create_exposures=False,
        visualize=False
    )
    print(f"   âœ… é†«é™¢æ•¸é‡: {len(gdf_hospitals_calc)}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ›éšªæ•¸æ“šå¯ç”¨æ–¼ç©ºé–“åˆ†é…
    if 'exposures' in climada_data and hasattr(climada_data['exposures'], 'gdf'):
        exposure_gdf = climada_data['exposures'].gdf
        print(f"   âœ… æ›éšªé»æ•¸é‡: {len(exposure_gdf)}")
    
    # CLIMADAæå¤±æœ¬èº«å°±ä»£è¡¨å€åŸŸå…§æ‰€æœ‰è³‡ç”¢ï¼ˆåŒ…æ‹¬é†«é™¢ï¼‰çš„ç¸½æå¤±
    print(f"   âœ… CLIMADAæå¤±ä»£è¡¨ {len(gdf_hospitals_calc)} å®¶é†«é™¢çš„èšåˆæå¤±")
    
    # Ensure data arrays have matching lengths
    observed_losses = climada_data.get('impact').at_event if 'impact' in climada_data else np.array([])
    
    # ä½¿ç”¨é è¨­é¢¨é€Ÿæ•¸æ“šæª¢æŸ¥é•·åº¦å°é½Š
    min_length = min(len(default_wind_indices), len(observed_losses))
    if min_length > 0:
        # å°æ‰€æœ‰åŠå¾‘çš„é¢¨é€Ÿæ•¸æ“šé€²è¡Œæˆªæ–·ä»¥ç¢ºä¿ä¸€è‡´æ€§
        for radius in radius_wind_indices:
            radius_wind_indices[radius] = radius_wind_indices[radius][:min_length]
        observed_losses = observed_losses[:min_length]
        print(f"   Aligned all radius data to {min_length} events")
    else:
        print("âŒ No valid data found")
        return
    
    print("\nğŸ¥ åŸ·è¡Œé†«é™¢å°å‘çš„åŸºå·®é¢¨éšªåˆ†æ...")
    print("   â€¢ ç›®æ¨™: å°‡è§¸ç™¼å™¨è³ ä»˜èˆ‡é†«é™¢ç¸½æå¤±åŒ¹é…")
    print("   â€¢ æå¤±è¨ˆç®—: æ¯å®¶é†«é™¢å€‹åˆ¥æå¤±çš„ç¸½å’Œ")
    print("   â€¢ æ–¹æ³•: å¤šç¨®åŸºå·®é¢¨éšªå®šç¾© + å¤šæ°´å¹³æœ€å¤§è³ ä»˜æ¸¬è©¦")
    print(f"   â€¢ ä½¿ç”¨é ç”Ÿæˆç”¢å“: {len(products)} å€‹")
    print(f"   â€¢ æ¸¬è©¦æœ€å¤§è³ ä»˜æ°´å¹³: 25%, 50%, 75%, 100% ç¸½æ›éšª")
    
    # å¤šæ°´å¹³æœ€å¤§è³ ä»˜æ¸¬è©¦
    total_exposure = hospital_config.calculate_total_exposure()
    payout_levels = [0.25, 0.50, 0.75, 1.00]  # 25%, 50%, 75%, 100% ç¸½æ›éšª
    
    print(f"\nğŸ” æœ€å¤§è³ ä»˜æ°´å¹³æ¸¬è©¦:")
    for level in payout_levels:
        max_payout_value = total_exposure * level
        print(f"   - {level*100:3.0f}% ç¸½æ›éšª: ${max_payout_value:,.0f}")
    
    print(f"\nğŸ“Š é–‹å§‹åˆ†æ...")
    print(f"   åˆ†æç”¢å“æ•¸é‡: {len(products)} (70å€‹é–¾å€¼å‡½æ•¸ Ã— 5å€‹åŠå¾‘)")
    print(f"   äº‹ä»¶æ•¸é‡: {min_length}")
    print(f"   æœ€å¤§è³ ä»˜æ°´å¹³: {len(payout_levels)} å€‹")
    print(f"   ç¸½åˆ†æçµ„åˆ: {len(products) * len(payout_levels)}")
    
    # Import basis risk calculator (ä½¿ç”¨æ•´åˆçš„ skill_scores æ¨¡çµ„)
    from skill_scores.basis_risk_functions import BasisRiskCalculator, BasisRiskType, BasisRiskConfig
    
    # åˆå§‹åŒ–ä¸åŒé¡å‹çš„åŸºå·®é¢¨éšªè¨ˆç®—å™¨ (åŒ…å«ç›¸å°åŸºå·®é¢¨éšª)
    calculators = {
        # å‚³çµ±çµ•å°åŸºå·®é¢¨éšª
        'absolute': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.ABSOLUTE, 
            normalize=False  # é—œé–‰æ¨™æº–åŒ–ä»¥é¡¯ç¤ºå¯¦éš›å·®ç•°
        )),
        'asymmetric': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.ASYMMETRIC,
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),  
        'weighted': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0,  # è³ ä¸å¤ çš„æ‡²ç½°æ¬Šé‡
            w_over=0.5,   # è³ å¤šäº†çš„æ‡²ç½°æ¬Šé‡
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),
        'rmse': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RMSE,
            normalize=False  # é—œé–‰æ¨™æº–åŒ–
        )),
        # æ–°å¢ç›¸å°åŸºå·®é¢¨éšª - ä¾†è‡ª 07_relative_basis_risk_analysis.py
        'relative_absolute': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RELATIVE_ABSOLUTE,
            min_loss_threshold=1e7,  # æœ€å°æå¤±é–¾å€¼ 1åƒè¬
            normalize=False
        )),
        'relative_weighted': BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.RELATIVE_WEIGHTED_ASYMMETRIC,
            w_under=2.0,
            w_over=0.5,
            min_loss_threshold=1e7,  # æœ€å°æå¤±é–¾å€¼ 1åƒè¬
            normalize=False
        ))
    }
    
    # åˆ†æçµæœå„²å­˜
    all_analysis_results = []
    
    # æª¢æŸ¥å‰3å€‹ç”¢å“çš„è¨­ç½® (èª¿è©¦ä¿¡æ¯)
    print(f"\nğŸ” ç”¢å“è¨­ç½®æª¢æŸ¥ (å‰3å€‹):")
    for i in range(min(3, len(products))):
        product = products[i]
        print(f"  {product['product_id']}: é–¾å€¼={product['trigger_thresholds']}")
        print(f"    è³ ä»˜æ¯”ä¾‹={product['payout_ratios']}, æœ€å¤§è³ ä»˜=${product['max_payout']:,.0f}")
    
    # æª¢æŸ¥å„åŠå¾‘é¢¨é€Ÿæ•¸æ“šç¯„åœ
    print(f"\nğŸŒªï¸  å„åŠå¾‘é¢¨é€Ÿæ•¸æ“šæª¢æŸ¥:")
    for radius, wind_data in radius_wind_indices.items():
        print(f"   {radius}kmåŠå¾‘:")
        print(f"      ç¯„åœ: {np.min(wind_data):.2f} - {np.max(wind_data):.2f} mph")
        print(f"      å¹³å‡: {np.mean(wind_data):.2f}, æ¨™æº–å·®: {np.std(wind_data):.2f}")
    
    # ç‚ºæ¯å€‹ç”¢å“æ¸¬è©¦å¤šå€‹æœ€å¤§è³ ä»˜æ°´å¹³
    total_combinations = len(products) * len(payout_levels)
    combination_count = 0
    
    for i, product in enumerate(products):
        # æ ¹æ“šç”¢å“çš„åŠå¾‘é¸æ“‡å°æ‡‰çš„é¢¨é€Ÿæ•¸æ“š
        product_radius = product.get('radius_km', 50)  # é è¨­50km
        if product_radius not in radius_wind_indices:
            print(f"   âš ï¸ è·³éç”¢å“ {product['product_id']}: åŠå¾‘ {product_radius}km æ•¸æ“šä¸å¯ç”¨")
            continue
        
        # ä½¿ç”¨è©²ç”¢å“å°æ‡‰åŠå¾‘çš„é¢¨é€Ÿæ•¸æ“š
        wind_indices = radius_wind_indices[product_radius]
        
        for payout_level in payout_levels:
            combination_count += 1
            if combination_count % 50 == 0:
                print(f"   é€²åº¦: {combination_count}/{total_combinations}")
            
            # ç‚ºé€™å€‹çµ„åˆè¨­å®šæœ€å¤§è³ ä»˜
            current_max_payout = total_exposure * payout_level
        
            # è¨ˆç®—éšæ¢¯å¼è³ ä»˜ (ä½¿ç”¨æ•´åˆçš„ skill_scores æ¨¡çµ„)
            from skill_scores.basis_risk_functions import calculate_step_payouts_batch
            
            payouts = calculate_step_payouts_batch(
                wind_indices,  # ç¾åœ¨ä½¿ç”¨å°æ‡‰åŠå¾‘çš„é¢¨é€Ÿæ•¸æ“š
                product['trigger_thresholds'],
                product['payout_ratios'],
                current_max_payout  # ä½¿ç”¨ç•¶å‰æ°´å¹³çš„æœ€å¤§è³ ä»˜
            )
        
            # èª¿è©¦ï¼šæª¢æŸ¥å‰å¹¾å€‹çµ„åˆçš„è³ ä»˜åˆ†ä½ˆ
            if combination_count <= 6:  # åªé¡¯ç¤ºå‰6å€‹çµ„åˆ
                print(f"    ç”¢å“ {product['product_id']}, æ°´å¹³{payout_level*100:.0f}%: è³ ä»˜ç¯„åœ={np.min(payouts):.2e}-{np.max(payouts):.2e}, è§¸ç™¼ç‡={np.mean(payouts > 0):.3f}")
            
            # è¨ˆç®—å„ç¨®åŸºå·®é¢¨éšªæŒ‡æ¨™
            product_result = {
                'product_id': f"{product['product_id']}_L{payout_level*100:.0f}",  # æ·»åŠ æ°´å¹³æ¨™è­˜
                'base_product_id': product['product_id'],
                'name': product.get('name', 'Unknown'),
                'structure_type': product['structure_type'],
                'radius_km': product.get('radius_km', 30),
                'n_thresholds': len(product['trigger_thresholds']),
                'max_payout': current_max_payout,
                'payout_level': payout_level,
                'payout_level_pct': f"{payout_level*100:.0f}%"
            }
        
            # ä½¿ç”¨ä¸åŒçš„åŸºå·®é¢¨éšªè¨ˆç®—å™¨
            for risk_name, calculator in calculators.items():
                risk_value = calculator.calculate_basis_risk(observed_losses, payouts)
                product_result[f'{risk_name}_risk'] = risk_value
        
            # è¨ˆç®—é¡å¤–çš„å‚³çµ±æŒ‡æ¨™
            product_result['correlation'] = np.corrcoef(observed_losses, payouts)[0,1] if np.std(payouts) > 0 else 0
            product_result['trigger_rate'] = np.mean(payouts > 0)
            product_result['mean_payout'] = np.mean(payouts)
            product_result['coverage_ratio'] = np.sum(payouts) / np.sum(observed_losses) if np.sum(observed_losses) > 0 else 0
            product_result['basis_risk_std'] = np.std(observed_losses - payouts)
            # é†«é™¢å°å‘æŒ‡æ¨™
            product_result['hospital_match_score'] = 1 / (1 + product_result.get('weighted_risk', np.inf))  # è½‰ç‚ºåŒ¹é…åˆ†æ•¸
            
            all_analysis_results.append(product_result)
    
    # å‰µå»ºçµæœDataFrame
    import pandas as pd
    results_df = pd.DataFrame(all_analysis_results)
    
    # å°‡æ¡†æ¶èª¿ç”¨æ›¿æ›ç‚ºæˆ‘å€‘çš„åˆ†æçµæœ
    class TraditionalAnalysisResults:
        def __init__(self, results_df):
            self.results_df = results_df
            self.best_products = self._find_best_products()
            self.summary_statistics = self._generate_summary()
        
        def _find_best_products(self):
            best_products = {}
            metrics = ['absolute_risk', 'asymmetric_risk', 'weighted_risk', 'rmse_risk']
            
            for metric in metrics:
                if metric in self.results_df.columns:
                    best_idx = self.results_df[metric].idxmin()
                    if not pd.isna(best_idx):
                        best_product = self.results_df.iloc[best_idx]
                        # ä½¿ç”¨å­—å…¸è€Œä¸æ˜¯å‹•æ…‹é¡åˆ¥ï¼Œé¿å… pickle å•é¡Œ
                        best_products[f'best_{metric}'] = {
                            'product_id': best_product['product_id'],
                            'name': best_product['name'], 
                            'description': f"{best_product['structure_type']} threshold product"
                        }
            
            return best_products
        
        def _generate_summary(self):
            return {
                'total_products': len(self.results_df),
                'analysis_type': 'Traditional Basis Risk Analysis'
            }
    
    results = TraditionalAnalysisResults(results_df)
    
    # Extract and display results
    print("\nâœ… é†«é™¢å°å‘çš„åŸºå·®é¢¨éšªåˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š åˆ†æäº† {len(products)} å€‹ç”¢å“ Ã— {len(payout_levels)} å€‹è³ ä»˜æ°´å¹³ = {len(results_df)} å€‹çµ„åˆ")
    
    # Display comprehensive basis risk analysis results
    print("\nğŸ“‹ åŸºå·®é¢¨éšªåˆ†ææ‘˜è¦:")
    print("=" * 60)
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f"ç¸½çµ„åˆæ•¸: {len(results_df)}")
    print(f"åŸå§‹ç”¢å“æ•¸: {len(products)}")
    print(f"æ¸¬è©¦è³ ä»˜æ°´å¹³: {len(payout_levels)} å€‹ ({', '.join([f'{l*100:.0f}%' for l in payout_levels])})")
    
    print(f"\nç”¢å“çµæ§‹åˆ†å¸ƒ:")
    structure_counts = results_df['structure_type'].value_counts()
    for structure, count in structure_counts.items():
        print(f"  â€¢ {structure.capitalize()}: {count} çµ„åˆ")
    
    print(f"\nè³ ä»˜æ°´å¹³åˆ†å¸ƒ:")
    payout_counts = results_df['payout_level_pct'].value_counts()
    for level, count in payout_counts.items():
        print(f"  â€¢ {level} ç¸½æ›éšª: {count} çµ„åˆ")
    
    # åŸºå·®é¢¨éšªçµ±è¨ˆæ‘˜è¦ï¼ˆåŒ…å«ç›¸å°åŸºå·®é¢¨éšªï¼‰
    print(f"\nğŸ¯ åŸºå·®é¢¨éšªæŒ‡æ¨™çµ±è¨ˆ:")
    risk_metrics = ['absolute_risk', 'asymmetric_risk', 'weighted_risk', 'rmse_risk', 
                    'relative_absolute_risk', 'relative_weighted_risk']
    
    for metric in risk_metrics:
        if metric in results_df.columns and not results_df[metric].isna().all():
            mean_risk = results_df[metric].mean()
            min_risk = results_df[metric].min()
            max_risk = results_df[metric].max()
            print(f"  â€¢ {metric.replace('_', ' ').title()}:")
            print(f"    å¹³å‡: {mean_risk:.2e}, æœ€å°: {min_risk:.2e}, æœ€å¤§: {max_risk:.2e}")
    
    # é¡¯ç¤ºæœ€ä½³ç”¢å“
    if hasattr(results, 'best_products') and results.best_products:
        print(f"\nğŸ† å„æŒ‡æ¨™æœ€ä½³ç”¢å“:")
        print("-" * 40)
        
        count = 0
        for metric, product in results.best_products.items():
            if count >= 8:  # é™åˆ¶é¡¯ç¤ºæ•¸é‡
                break
            count += 1
            
            metric_name = metric.replace('best_', '').replace('_', ' ').title()
            print(f"{count}. {metric_name}: {product['name']}")
            print(f"   ç”¢å“ID: {product['product_id']}")
            print(f"   æè¿°: {product['description']}")
            
            # é¡¯ç¤ºè©²ç”¢å“çš„å…·é«”é¢¨éšªå€¼
            product_row = results_df[results_df['product_id'] == product['product_id']]
            if not product_row.empty:
                risk_col = metric.replace('best_', '') + '_risk' if not metric.endswith('_risk') else metric.replace('best_', '')
                if risk_col in product_row.columns:
                    risk_value = product_row[risk_col].iloc[0]
                    print(f"   é¢¨éšªå€¼: {risk_value:.6f}")
            print()
    
    # é†«é™¢å°å‘çš„æœ€ä½³ç”¢å“å»ºè­°
    print(f"\nğŸ¥ é†«é™¢ä¿è­·æœ€ä½³Cat-in-Circleç”¢å“å»ºè­°:")
    print("=" * 50)
    
    if 'weighted_risk' in results_df.columns:
        # æ‰¾åˆ°æœ€ä½³çš„é†«é™¢åŒ¹é…ç”¢å“
        best_overall = results_df.loc[results_df['weighted_risk'].idxmin()]
        
        print(f"ğŸ† ç¸½é«”æœ€ä½³ç”¢å“:")
        print(f"   ç”¢å“: {best_overall['base_product_id']} ({best_overall['structure_type']})")
        print(f"   æœ€ä½³è³ ä»˜æ°´å¹³: {best_overall['payout_level_pct']} ç¸½æ›éšª (${best_overall['max_payout']:,.0f})")
        print(f"   åŠ æ¬ŠåŸºå·®é¢¨éšª: {best_overall['weighted_risk']:.2e}")
        print(f"   è§¸ç™¼ç‡: {best_overall['trigger_rate']:.3f}")
        print(f"   è¦†è“‹ç‡: {best_overall['coverage_ratio']:.3f}")
        print(f"   é†«é™¢åŒ¹é…åˆ†æ•¸: {best_overall['hospital_match_score']:.6f}")
        
        # æŒ‰è³ ä»˜æ°´å¹³åˆ†çµ„æ‰¾æœ€ä½³
        print(f"\nğŸ’° å„è³ ä»˜æ°´å¹³æœ€ä½³ç”¢å“:")
        for level in sorted(results_df['payout_level'].unique()):
            level_data = results_df[results_df['payout_level'] == level]
            best_in_level = level_data.loc[level_data['weighted_risk'].idxmin()]
            
            print(f"   â€¢ {level*100:.0f}% ç¸½æ›éšªæ°´å¹³: {best_in_level['base_product_id']}")
            print(f"     é¢¨éšª: {best_in_level['weighted_risk']:.2e}, è§¸ç™¼ç‡: {best_in_level['trigger_rate']:.3f}")
        
        # æŒ‰ç”¢å“çµæ§‹åˆ†çµ„æ‰¾æœ€ä½³
        print(f"\nğŸ”§ å„çµæ§‹é¡å‹æœ€ä½³ç”¢å“:")
        for structure in sorted(results_df['structure_type'].unique()):
            structure_data = results_df[results_df['structure_type'] == structure]
            best_in_structure = structure_data.loc[structure_data['weighted_risk'].idxmin()]
            
            print(f"   â€¢ {structure.capitalize()}: {best_in_structure['product_id']}")
            print(f"     é¢¨éšª: {best_in_structure['weighted_risk']:.2e}, è³ ä»˜æ°´å¹³: {best_in_structure['payout_level_pct']}")
    
    # Top 10 ç¶œåˆæ’å (ä½¿ç”¨åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª)
    print(f"\nğŸ“ˆ Top 10 çµ„åˆæ’å (æŒ‰é†«é™¢åŒ¹é…æ•ˆæœ):")
    print("-" * 40)
    
    if 'weighted_risk' in results_df.columns:
        top_10 = results_df.nsmallest(10, 'weighted_risk')
        
        for i, (_, row) in enumerate(top_10.iterrows(), 1):
            print(f"{i:2d}. {row['product_id']} ({row['structure_type']})")
            print(f"     åŠ æ¬ŠåŸºå·®é¢¨éšª: {row['weighted_risk']:.2e}")
            print(f"     çµ•å°åŸºå·®é¢¨éšª: {row.get('absolute_risk', 'N/A'):.2e}")
            print(f"     ä¸å°ç¨±åŸºå·®é¢¨éšª: {row.get('asymmetric_risk', 'N/A'):.2e}")
            print(f"     RMSEé¢¨éšª: {row.get('rmse_risk', 'N/A'):.2e}")
            print(f"     è§¸ç™¼ç‡: {row.get('trigger_rate', 'N/A'):.3f}")
            print(f"     ç›¸é—œä¿‚æ•¸: {row.get('correlation', 'N/A'):.3f}")
            print()
    
    # é¡å¤–çµ±è¨ˆ
    print(f"\nğŸ“Š é¡å¤–çµ±è¨ˆæŒ‡æ¨™:")
    avg_trigger_rate = results_df['trigger_rate'].mean()
    avg_correlation = results_df['correlation'].mean()
    avg_coverage = results_df['coverage_ratio'].mean()
    
    print(f"  â€¢ å¹³å‡è§¸ç™¼ç‡: {avg_trigger_rate:.3f}")
    print(f"  â€¢ å¹³å‡ç›¸é—œä¿‚æ•¸: {avg_correlation:.3f}")
    print(f"  â€¢ å¹³å‡è¦†è“‹ç‡: {avg_coverage:.3f}")
    
    # Skill Score è©•ä¼°ï¼ˆæ›´æ–°åŒ…å«ç›¸å°åŸºå·®é¢¨éšªï¼‰
    print(f"\nğŸ¯ Skill Score è©•ä¼°:")
    print(f"  åŸºå·®é¢¨éšªåˆ†æä¸­çš„ä¸åŒæå¤±å‡½æ•¸æ¯”è¼ƒ:")
    print(f"  â€¢ çµ•å°åŸºå·®é¢¨éšª: å°ç¨±æ‡²ç½°æ‰€æœ‰åå·®")
    print(f"  â€¢ ä¸å°ç¨±åŸºå·®é¢¨éšª: åªæ‡²ç½°è³ ä»˜ä¸è¶³")
    print(f"  â€¢ åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª: ä¸å°ç¨±æ‡²ç½°ï¼Œæ¬Šé‡åŒ–è€ƒæ…®")
    print(f"  â€¢ RMSEé¢¨éšª: å‚³çµ±çµ±è¨ˆæ–¹æ³•ï¼Œå¹³æ–¹æ‡²ç½°")
    print(f"  â€¢ ç›¸å°çµ•å°åŸºå·®é¢¨éšª: æ¨™æº–åŒ–è™•ç†ï¼Œé¿å…æ¥µç«¯äº‹ä»¶ä¸»å°")
    print(f"  â€¢ ç›¸å°åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšª: çµåˆæ¬Šé‡èˆ‡æ¨™æº–åŒ–çš„å„ªå‹¢")
    
    # ç›¸å° vs çµ•å°åŸºå·®é¢¨éšªå°æ¯”åˆ†æ
    print(f"\nğŸ” ç›¸å° vs çµ•å°åŸºå·®é¢¨éšªå°æ¯”:")
    if 'relative_weighted_risk' in results_df.columns and 'weighted_risk' in results_df.columns:
        abs_risk_max = results_df['weighted_risk'].max()
        rel_risk_max = results_df['relative_weighted_risk'].max()
        abs_risk_dominated = (results_df['weighted_risk'].quantile(0.9) - results_df['weighted_risk'].quantile(0.1)) / results_df['weighted_risk'].mean()
        rel_risk_spread = (results_df['relative_weighted_risk'].quantile(0.9) - results_df['relative_weighted_risk'].quantile(0.1)) / results_df['relative_weighted_risk'].mean()
        
        print(f"  â€¢ çµ•å°é¢¨éšªæœ€å¤§å€¼: {abs_risk_max:.2e}")
        print(f"  â€¢ ç›¸å°é¢¨éšªæœ€å¤§å€¼: {rel_risk_max:.3f}")
        print(f"  â€¢ çµ•å°é¢¨éšªè®Šç•°åº¦: {abs_risk_dominated:.2f}")
        print(f"  â€¢ ç›¸å°é¢¨éšªè®Šç•°åº¦: {rel_risk_spread:.2f}")
        print(f"  â€¢ ç›¸å°åŸºå·®é¢¨éšªæœ‰æ•ˆæ¸›å°‘äº†æ¥µç«¯äº‹ä»¶å°é¢¨éšªè©•ä¼°çš„ä¸»å°æ•ˆæ‡‰")
    
    # Save results
    output_dir = "results/traditional_basis_risk_analysis"
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    # Save detailed DataFrame  
    results_df.to_csv(f"{output_dir}/detailed_results.csv", index=False)
    print(f"ğŸ’¾ Detailed results saved to: {output_dir}/detailed_results.csv")
    
    # Save analysis object
    with open(f"{output_dir}/analysis_results.pkl", 'wb') as f:
        pickle.dump({
            'results_df': results_df,
            'best_products': results.best_products,
            'summary_statistics': results.summary_statistics,
            'analysis_config': {
                'risk_types': list(calculators.keys()),
                'n_products': len(products),
                'n_events': len(wind_indices),
                'undercompensation_weight': 2.0,
                'overcompensation_weight': 0.5,
                'hospital_config': {
                    'n_hospitals': hospital_config.n_hospitals,
                    'base_hospital_value': hospital_config.base_hospital_value,
                    'total_exposure': total_exposure,
                    'max_payouts': max_payouts
                }
            }
        }, f)
    
    print(f"ğŸ’¾ Analysis object saved to: {output_dir}/analysis_results.pkl")
    
    # Generate summary report
    from datetime import datetime
    
    report_lines = [
        "Traditional Basis Risk Analysis Report",
        "=" * 40,
        f"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"Products Analyzed: {len(products)}",
        f"Events Analyzed: {len(wind_indices)}",
        f"Hospital-Based Configuration:",
        f"  - Hospitals: {hospital_config.n_hospitals}",
        f"  - Base Value per Hospital: ${hospital_config.base_hospital_value:,.0f}",
        f"  - Total Exposure: ${total_exposure:,.0f}",
        "",
        "Basis Risk Definitions Used:",
        "1. Absolute Basis Risk: |Actual_Loss - Payout|",
        "2. Asymmetric Basis Risk: max(0, Actual_Loss - Payout)",
        "3. Weighted Asymmetric: 2.0*undercomp + 0.5*overcomp",
        "4. RMSE Risk: sqrt(mean((Actual_Loss - Payout)Â²))",
        "",
        "Key Findings:"
    ]
    
    # Add top performers for each metric
    for metric in risk_metrics:
        if metric in results_df.columns and not results_df[metric].isna().all():
            best_product = results_df.loc[results_df[metric].idxmin()]
            best_value = results_df[metric].min()
            report_lines.append(f"- Best {metric.replace('_', ' ').title()}: {best_product['product_id']} (Value: {best_value:.6f})")
    
    report_text = "\n".join(report_lines)
    with open(f"{output_dir}/analysis_report.txt", 'w', encoding='utf-8') as f:
        f.write(report_text)
    
    print(f"ğŸ“„ Analysis report saved to: {output_dir}/analysis_report.txt")
    
    print(f"\nğŸ‰ å‚³çµ±åŸºå·®é¢¨éšªåˆ†æå®Œæˆï¼")
    print("   ä½¿ç”¨çš„æ–¹æ³• (æ•´åˆä¾†è‡ª 07_relative_basis_risk_analysis.py):")
    print("   â€¢ çµ•å°åŸºå·®é¢¨éšªè¨ˆç®— (å°ç¨±æ‡²ç½°)")
    print("   â€¢ ä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (åªæ‡²ç½°è³ ä»˜ä¸è¶³)")
    print("   â€¢ åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (æ¬Šé‡åŒ–æ‡²ç½°)")
    print("   â€¢ å‚³çµ±RMSEé¢¨éšªè¨ˆç®—")
    print("   â€¢ ç›¸å°çµ•å°åŸºå·®é¢¨éšªè¨ˆç®— (æ¨™æº–åŒ–é¿å…æ¥µç«¯äº‹ä»¶ä¸»å°)")
    print("   â€¢ ç›¸å°åŠ æ¬Šä¸å°ç¨±åŸºå·®é¢¨éšªè¨ˆç®— (çµåˆæ¨™æº–åŒ–èˆ‡æ¬Šé‡)")
    print("   â€¢ Skill Scoreå¤šé‡è©•ä¼°æ¶æ§‹")
    print("   â€¢ çµ•å° vs ç›¸å°åŸºå·®é¢¨éšªå°æ¯”åˆ†æ")
    print("\n   ğŸ“ å¤šåŠå¾‘æ¸¬è©¦é…ç½®:")
    print(f"   â€¢ æ¸¬è©¦åŠå¾‘: 15km, 30km, 50km, 75km, 100km")
    print(f"   â€¢ æ¯å€‹ç”¢å“ä½¿ç”¨å…¶å°æ‡‰åŠå¾‘çš„Cat-in-Circleé¢¨é€Ÿæ•¸æ“š")
    print(f"   â€¢ Steinmann 2023æ¨™æº–: 70å€‹é–¾å€¼å‡½æ•¸ Ã— 5å€‹åŠå¾‘ = 350å€‹ç”¢å“")
    print("\n   ğŸ¥ åŸºæ–¼é†«é™¢çš„è³ ä»˜é…ç½®:")
    print(f"   â€¢ é†«é™¢æ•¸é‡: {hospital_config.n_hospitals}")
    print(f"   â€¢ ç¸½æ›éšªå€¼: ${total_exposure:,.0f}")
    print(f"   â€¢ æœ€å¤§è³ ä»˜å·²æ ¹æ“šé†«é™¢æ›éšªèª¿æ•´")
    
    return results

# %%
if __name__ == "__main__":
    results = main()
# %%
