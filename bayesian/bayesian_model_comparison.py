"""
Bayesian Model Comparison Framework (æ–¹æ³•ä¸€)
è²è‘‰æ–¯æ¨¡å‹æ¯”è¼ƒæ¡†æ¶

Implements the two-stage approach from bayesian_implement.md:
Stage 1: Fit multiple candidate models
Stage 2: Evaluate using CRPS and select the best model

This module provides three different model structures:
- Model A: Simple Log-Normal baseline
- Model B: Hierarchical Bayesian model  
- Model C: Alternative model with different predictors
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
import warnings
import sys
import os

# Add parent directory for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import PyMC for Bayesian modeling
try:
    import pymc as pm
    import pytensor.tensor as pt
    HAS_PYMC = True
except ImportError:
    HAS_PYMC = False
    warnings.warn("PyMC not available, using simplified models")

# Import skill scores
try:
    from skill_scores import (
        calculate_crps, calculate_tss, calculate_edi
    )
    HAS_SKILL_SCORES = True
except ImportError:
    HAS_SKILL_SCORES = False
    warnings.warn("skill_scores module not available")

@dataclass
class ModelComparisonResult:
    """æ¨¡å‹æ¯”è¼ƒçµæœ"""
    model_name: str
    model_type: str
    trace: Any  # PyMC trace object
    posterior_predictive: np.ndarray
    crps_score: float
    tss_score: float
    edi_score: float
    log_likelihood: float
    convergence_diagnostics: Dict[str, Any]

class BayesianModelComparison:
    """
    è²è‘‰æ–¯æ¨¡å‹æ¯”è¼ƒæ¡†æ¶
    
    å¯¦ç¾æ–¹æ³•ä¸€ï¼šå»ºç«‹å¤šå€‹å€™é¸æ¨¡å‹ä¸¦ç”¨ Skill Scores è©•ä¼°
    """
    
    def __init__(self,
                 n_samples: int = 2000,
                 n_chains: int = 4,
                 random_seed: int = 42):
        """
        åˆå§‹åŒ–æ¨¡å‹æ¯”è¼ƒæ¡†æ¶
        
        Parameters:
        -----------
        n_samples : int
            MCMC æ¡æ¨£æ•¸
        n_chains : int
            MCMC éˆæ•¸
        random_seed : int
            éš¨æ©Ÿç¨®å­
        """
        self.n_samples = n_samples
        self.n_chains = n_chains
        self.random_seed = random_seed
        
        # å­˜å„²çµæœ
        self.models = {}
        self.traces = {}
        self.posterior_predictives = {}
        self.comparison_results = []
        
    def build_model_A_simple_lognormal(self, 
                                       observations: np.ndarray,
                                       covariates: Optional[np.ndarray] = None) -> Any:
        """
        æ¨¡å‹ A: ç°¡å–®çš„å°æ•¸æ­£æ…‹åˆ†ä½ˆåŸºæº–æ¨¡å‹
        
        é€™æ˜¯æœ€åŸºç¤çš„æ¨¡å‹ï¼Œå‡è¨­æå¤±éµå¾ªå°æ•¸æ­£æ…‹åˆ†ä½ˆ
        
        Parameters:
        -----------
        observations : np.ndarray
            è§€æ¸¬æå¤±æ•¸æ“š
        covariates : np.ndarray, optional
            å”è®Šé‡ï¼ˆå¦‚é¢¨é€Ÿã€é™é›¨ç­‰ï¼‰
            
        Returns:
        --------
        PyMC model object
        """
        
        if not HAS_PYMC:
            warnings.warn("PyMC not available, returning None")
            return None
            
        print("ğŸ“Š å»ºç«‹æ¨¡å‹ A: ç°¡å–®å°æ•¸æ­£æ…‹åŸºæº–æ¨¡å‹")
        
        with pm.Model() as model_A:
            # æ•¸æ“šè½‰æ› - é¿å…é›¶å€¼
            obs_positive = np.maximum(observations, 1e-6)
            log_obs = np.log(obs_positive)
            
            # ç°¡å–®çš„å…ˆé©—
            mu = pm.Normal('mu', mu=np.mean(log_obs), sigma=2)
            sigma = pm.HalfNormal('sigma', sigma=1)
            
            # å¦‚æœæœ‰å”è®Šé‡ï¼ŒåŠ å…¥ç°¡å–®çš„ç·šæ€§é—œä¿‚
            if covariates is not None:
                beta = pm.Normal('beta', mu=0, sigma=1, shape=covariates.shape[1])
                mu_obs = mu + pm.math.dot(covariates, beta)
            else:
                mu_obs = mu
            
            # Likelihood - å°æ•¸æ­£æ…‹åˆ†ä½ˆ
            y_obs = pm.LogNormal('y_obs', mu=mu_obs, sigma=sigma, observed=observations)
            
        self.models['A_simple_lognormal'] = model_A
        return model_A
    
    def build_model_B_hierarchical(self,
                                   observations: np.ndarray,
                                   groups: Optional[np.ndarray] = None,
                                   covariates: Optional[np.ndarray] = None) -> Any:
        """
        æ¨¡å‹ B: éšå±¤è²è‘‰æ–¯æ¨¡å‹ï¼ˆæ”¹é€²ç‰ˆï¼‰
        
        åŒ…å«4å±¤éšå±¤çµæ§‹ï¼Œè™•ç†ç¾¤çµ„æ•ˆæ‡‰
        
        Parameters:
        -----------
        observations : np.ndarray
            è§€æ¸¬æå¤±æ•¸æ“š
        groups : np.ndarray, optional
            ç¾¤çµ„æ¨™ç±¤ï¼ˆå¦‚åœ°å€ã€äº‹ä»¶é¡å‹ï¼‰
        covariates : np.ndarray, optional
            å”è®Šé‡
            
        Returns:
        --------
        PyMC model object
        """
        
        if not HAS_PYMC:
            warnings.warn("PyMC not available, returning None")
            return None
            
        print("ğŸ“Š å»ºç«‹æ¨¡å‹ B: éšå±¤è²è‘‰æ–¯æ¨¡å‹")
        
        with pm.Model() as model_B:
            # æ•¸æ“šæº–å‚™
            obs_positive = np.maximum(observations, 1e-6)
            log_obs = np.log(obs_positive)
            
            # Level 4: Hyperpriors (è¶…åƒæ•¸)
            mu_alpha = pm.Normal('mu_alpha', mu=np.mean(log_obs), sigma=3)
            sigma_alpha = pm.HalfNormal('sigma_alpha', sigma=1)
            
            # Level 3: Group-level parameters (ç¾¤çµ„åƒæ•¸)
            if groups is not None:
                n_groups = len(np.unique(groups))
                alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha, shape=n_groups)
                
                # Map groups to alpha values
                group_idx = pm.ConstantData('group_idx', groups)
                mu_group = alpha[group_idx]
            else:
                alpha = pm.Normal('alpha', mu=mu_alpha, sigma=sigma_alpha)
                mu_group = alpha
            
            # Level 2: Individual-level parameters (å€‹é«”åƒæ•¸)
            if covariates is not None:
                beta = pm.Normal('beta', mu=0, sigma=1, shape=covariates.shape[1])
                mu_individual = mu_group + pm.math.dot(covariates, beta)
            else:
                mu_individual = mu_group
            
            # Level 1: Observation model (è§€æ¸¬æ¨¡å‹)
            sigma_obs = pm.HalfNormal('sigma_obs', sigma=1)
            
            # ä½¿ç”¨ Gamma åˆ†ä½ˆä½œç‚º likelihood (æ›´é©åˆæå¤±æ•¸æ“š)
            # è½‰æ›åƒæ•¸åˆ° Gamma åˆ†ä½ˆçš„ alpha å’Œ beta
            mu_exp = pm.math.exp(mu_individual)
            alpha_gamma = mu_exp**2 / sigma_obs**2
            beta_gamma = mu_exp / sigma_obs**2
            
            y_obs = pm.Gamma('y_obs', alpha=alpha_gamma, beta=beta_gamma, observed=observations)
            
        self.models['B_hierarchical'] = model_B
        return model_B
    
    def build_model_C_alternative(self,
                                  observations: np.ndarray,
                                  wind_speed: Optional[np.ndarray] = None,
                                  rainfall: Optional[np.ndarray] = None,
                                  storm_surge: Optional[np.ndarray] = None) -> Any:
        """
        æ¨¡å‹ C: åŒ…å«ä¸åŒé æ¸¬è®Šæ•¸çš„æ›¿ä»£æ¨¡å‹
        
        ä½¿ç”¨ç‰¹å®šçš„æ°£è±¡è®Šæ•¸ä½œç‚ºé æ¸¬å› å­
        
        Parameters:
        -----------
        observations : np.ndarray
            è§€æ¸¬æå¤±æ•¸æ“š
        wind_speed : np.ndarray, optional
            é¢¨é€Ÿæ•¸æ“š
        rainfall : np.ndarray, optional
            é™é›¨æ•¸æ“š
        storm_surge : np.ndarray, optional
            é¢¨æš´æ½®æ•¸æ“š
            
        Returns:
        --------
        PyMC model object
        """
        
        if not HAS_PYMC:
            warnings.warn("PyMC not available, returning None")
            return None
            
        print("ğŸ“Š å»ºç«‹æ¨¡å‹ C: æ›¿ä»£é æ¸¬è®Šæ•¸æ¨¡å‹")
        
        with pm.Model() as model_C:
            # æ•¸æ“šæº–å‚™
            obs_positive = np.maximum(observations, 1e-6)
            
            # åŸºç¤æˆªè·
            intercept = pm.Normal('intercept', mu=np.log(np.mean(obs_positive)), sigma=2)
            
            # é æ¸¬è®Šæ•¸æ•ˆæ‡‰
            mu = intercept
            
            if wind_speed is not None:
                # é¢¨é€Ÿçš„éç·šæ€§æ•ˆæ‡‰ (å¹³æ–¹é …)
                beta_wind = pm.Normal('beta_wind', mu=0.1, sigma=0.05)
                beta_wind_sq = pm.Normal('beta_wind_sq', mu=0.01, sigma=0.005)
                wind_normalized = (wind_speed - np.mean(wind_speed)) / np.std(wind_speed)
                mu = mu + beta_wind * wind_normalized + beta_wind_sq * wind_normalized**2
            
            if rainfall is not None:
                # é™é›¨çš„å°æ•¸æ•ˆæ‡‰
                beta_rain = pm.Normal('beta_rain', mu=0.05, sigma=0.02)
                rain_log = np.log(rainfall + 1)  # åŠ 1é¿å…log(0)
                rain_normalized = (rain_log - np.mean(rain_log)) / np.std(rain_log)
                mu = mu + beta_rain * rain_normalized
            
            if storm_surge is not None:
                # é¢¨æš´æ½®çš„é–¾å€¼æ•ˆæ‡‰
                beta_surge = pm.Normal('beta_surge', mu=0.2, sigma=0.1)
                surge_threshold = pm.Normal('surge_threshold', mu=2, sigma=0.5)
                surge_effect = pm.math.switch(storm_surge > surge_threshold, 
                                             beta_surge * (storm_surge - surge_threshold), 
                                             0)
                mu = mu + surge_effect
            
            # ä½¿ç”¨ Tweedie åˆ†ä½ˆ (é©åˆåŒ…å«é›¶çš„æå¤±æ•¸æ“š)
            # ç°¡åŒ–ç‚º Gamma + é›¶è†¨è„¹
            p_zero = pm.Beta('p_zero', alpha=1, beta=9)  # ç´„10%é›¶æå¤±çš„å…ˆé©—
            
            # éé›¶æå¤±çš„ Gamma åˆ†ä½ˆ
            mu_positive = pm.math.exp(mu)
            dispersion = pm.HalfNormal('dispersion', sigma=1)
            
            # Zero-inflated Gamma
            # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰ä½¿ç”¨ Mixture æˆ– ZeroInflatedGamma
            y_obs = pm.Gamma('y_obs', 
                            alpha=mu_positive/dispersion, 
                            beta=1/dispersion,
                            observed=observations)
            
        self.models['C_alternative'] = model_C
        return model_C
    
    def fit_all_models(self,
                       train_data: np.ndarray,
                       validation_data: np.ndarray,
                       **model_kwargs) -> List[ModelComparisonResult]:
        """
        æ“¬åˆæ‰€æœ‰å€™é¸æ¨¡å‹ä¸¦è©•ä¼°
        
        Parameters:
        -----------
        train_data : np.ndarray
            è¨“ç·´æ•¸æ“š
        validation_data : np.ndarray
            é©—è­‰æ•¸æ“š
        **model_kwargs : dict
            å‚³éçµ¦æ¨¡å‹å»ºæ§‹å‡½æ•¸çš„é¡å¤–åƒæ•¸
            
        Returns:
        --------
        List[ModelComparisonResult]
            æ¨¡å‹æ¯”è¼ƒçµæœåˆ—è¡¨
        """
        
        print("ğŸš€ é–‹å§‹æ–¹æ³•ä¸€ï¼šæ¨¡å‹æ“¬åˆèˆ‡æ¯”è¼ƒ")
        print("=" * 80)
        
        # Step 1: å»ºç«‹å€™é¸æ¨¡å‹
        print("\nğŸ“¦ Step 1: å»ºç«‹å€™é¸æ¨¡å‹")
        model_A = self.build_model_A_simple_lognormal(train_data, 
                                                      model_kwargs.get('covariates'))
        model_B = self.build_model_B_hierarchical(train_data,
                                                  model_kwargs.get('groups'),
                                                  model_kwargs.get('covariates'))
        model_C = self.build_model_C_alternative(train_data,
                                                 model_kwargs.get('wind_speed'),
                                                 model_kwargs.get('rainfall'),
                                                 model_kwargs.get('storm_surge'))
        
        models = {
            'A_simple_lognormal': model_A,
            'B_hierarchical': model_B,
            'C_alternative': model_C
        }
        
        # Step 2: æ“¬åˆæ‰€æœ‰æ¨¡å‹
        print("\nâš™ï¸ Step 2: ä½¿ç”¨ MCMC æ“¬åˆæ‰€æœ‰æ¨¡å‹")
        
        for name, model in models.items():
            if model is None:
                continue
                
            print(f"\n  æ“¬åˆ {name}...")
            
            try:
                with model:
                    # MCMC æ¡æ¨£
                    trace = pm.sample(
                        draws=self.n_samples,
                        chains=self.n_chains,
                        random_seed=self.random_seed,
                        progressbar=True
                    )
                    
                    self.traces[name] = trace
                    
                    # Step 3: ç”Ÿæˆå¾Œé©—é æ¸¬åˆ†ä½ˆ
                    print(f"  ç”Ÿæˆå¾Œé©—é æ¸¬åˆ†ä½ˆ...")
                    posterior_predictive = pm.sample_posterior_predictive(
                        trace,
                        random_seed=self.random_seed
                    )
                    
                    self.posterior_predictives[name] = posterior_predictive
                    
            except Exception as e:
                print(f"  âŒ æ¨¡å‹ {name} æ“¬åˆå¤±æ•—: {e}")
                continue
        
        # Step 4: è¨ˆç®— Skill Scores
        print("\nğŸ“Š Step 4: è¨ˆç®—ä¸¦æ¯”è¼ƒ Skill Scores")
        
        results = []
        
        for name in self.traces.keys():
            trace = self.traces[name]
            post_pred = self.posterior_predictives[name]
            
            # æå–é æ¸¬æ¨£æœ¬
            if 'y_obs' in post_pred.posterior_predictive:
                pred_samples = post_pred.posterior_predictive['y_obs'].values.flatten()
            else:
                print(f"  âš ï¸ æ¨¡å‹ {name} ç¼ºå°‘é æ¸¬æ¨£æœ¬")
                continue
            
            # è¨ˆç®— CRPS
            if HAS_SKILL_SCORES:
                # ç‚ºæ¯å€‹é©—è­‰é»ç”Ÿæˆé æ¸¬é›†åˆ
                n_val = len(validation_data)
                n_samples = len(pred_samples) // n_val if len(pred_samples) >= n_val else len(pred_samples)
                
                if n_samples > 0:
                    pred_ensemble = pred_samples[:n_val*n_samples].reshape(n_val, n_samples)
                    crps = calculate_crps(validation_data, forecasts_ensemble=pred_ensemble)
                    
                    # è¨ˆç®— TSS (éœ€è¦äºŒå…ƒåŒ–)
                    threshold = np.median(validation_data)
                    obs_binary = validation_data > threshold
                    pred_prob = np.mean(pred_ensemble > threshold, axis=1)
                    tss = calculate_tss(obs_binary, pred_prob)
                    
                    # è¨ˆç®— EDI
                    edi = calculate_edi(validation_data, pred_ensemble)
                else:
                    crps = float('inf')
                    tss = -1
                    edi = 0
            else:
                # ç°¡åŒ–è¨ˆç®—
                crps = np.mean(np.abs(pred_samples[:len(validation_data)] - validation_data))
                tss = 0
                edi = 0
            
            # æ”¶é›†è¨ºæ–·ä¿¡æ¯
            diagnostics = self._get_convergence_diagnostics(trace)
            
            result = ModelComparisonResult(
                model_name=name,
                model_type=name.split('_')[1],
                trace=trace,
                posterior_predictive=pred_samples,
                crps_score=float(crps),
                tss_score=float(tss),
                edi_score=float(edi),
                log_likelihood=self._calculate_log_likelihood(trace),
                convergence_diagnostics=diagnostics
            )
            
            results.append(result)
            self.comparison_results.append(result)
        
        # Step 5: é¸æ“‡æœ€ä½³æ¨¡å‹
        print("\nğŸ† Step 5: æ ¹æ“š Skill Scores é¸æ“‡æœ€ä½³æ¨¡å‹")
        self._print_comparison_table(results)
        
        if results:
            best_model = min(results, key=lambda x: x.crps_score)
            print(f"\nâœ… æœ€ä½³æ¨¡å‹: {best_model.model_name}")
            print(f"   CRPS: {best_model.crps_score:.2e}")
            print(f"   TSS: {best_model.tss_score:.3f}")
            
        return results
    
    def _get_convergence_diagnostics(self, trace) -> Dict[str, Any]:
        """ç²å–æ”¶æ–‚è¨ºæ–·"""
        diagnostics = {}
        
        try:
            import arviz as az
            
            # R-hat
            rhat = az.rhat(trace)
            diagnostics['rhat'] = {var: float(rhat[var].max()) for var in rhat.data_vars}
            
            # ESS
            ess = az.ess(trace)
            diagnostics['ess'] = {var: float(ess[var].min()) for var in ess.data_vars}
            
        except:
            diagnostics['rhat'] = {}
            diagnostics['ess'] = {}
        
        return diagnostics
    
    def _calculate_log_likelihood(self, trace) -> float:
        """è¨ˆç®—å°æ•¸ä¼¼ç„¶"""
        try:
            import arviz as az
            loo = az.loo(trace)
            return float(loo.elpd_loo)
        except:
            return -np.inf
    
    def _print_comparison_table(self, results: List[ModelComparisonResult]):
        """åˆ—å°æ¯”è¼ƒè¡¨æ ¼"""
        
        if not results:
            print("æ²’æœ‰å¯æ¯”è¼ƒçš„çµæœ")
            return
        
        # å‰µå»ºæ¯”è¼ƒè¡¨
        comparison_data = []
        for r in results:
            comparison_data.append({
                'æ¨¡å‹': r.model_name,
                'CRPS (è¶Šä½è¶Šå¥½)': f"{r.crps_score:.2e}",
                'TSS (è¶Šé«˜è¶Šå¥½)': f"{r.tss_score:.3f}",
                'EDI': f"{r.edi_score:.3f}"
            })
        
        df = pd.DataFrame(comparison_data)
        print("\næ¨¡å‹æ¯”è¼ƒçµæœ:")
        print(df.to_string(index=False))
    
    def get_best_model(self) -> Optional[ModelComparisonResult]:
        """ç²å–æœ€ä½³æ¨¡å‹"""
        if not self.comparison_results:
            return None
        
        return min(self.comparison_results, key=lambda x: x.crps_score)