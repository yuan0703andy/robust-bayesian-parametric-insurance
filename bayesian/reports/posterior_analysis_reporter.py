"""
Posterior Analysis Reporter Module
å¾Œé©—åˆ†æå ±å‘Šæ¨¡çµ„

æä¾›å¾Œé©—åˆ†å¸ƒçš„æ·±åº¦åˆ†æï¼ŒåŒ…æ‹¬ Prior vs Posterior æ¯”è¼ƒã€
åˆ†å¸ƒç‰¹å¾µåˆ†æã€åƒæ•¸ç›¸é—œæ€§ã€é æ¸¬åˆ†å¸ƒè©•ä¼°ç­‰ã€‚

Key Features:
- Prior vs Posterior åˆ†å¸ƒæ¯”è¼ƒ
- å¾Œé©—åˆ†å¸ƒç‰¹å¾µåˆ†æ (ååº¦ã€å³°åº¦ã€å¤šæ¨¡æ…‹)
- åƒæ•¸é–“ç›¸é—œæ€§åˆ†æ
- é æ¸¬åˆ†å¸ƒè©•ä¼°
- å¾Œé©—é æ¸¬æª¢é©—
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Optional, Tuple, Callable
from dataclasses import dataclass
from enum import Enum
import warnings
from scipy import stats
from scipy.stats import kstest, jarque_bera, shapiro
from sklearn.mixture import GaussianMixture
import sys
import os

# Import parent bayesian modules - use relative imports
try:
    from ..hierarchical_bayesian_model import HierarchicalModelResult, MixedPredictiveEstimation
except ImportError:
    # Fallback for direct execution
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from hierarchical_bayesian_model import HierarchicalModelResult, MixedPredictiveEstimation

class DistributionType(Enum):
    """åˆ†å¸ƒé¡å‹"""
    NORMAL = "normal"
    SKEWED = "skewed"
    HEAVY_TAILED = "heavy_tailed"
    BIMODAL = "bimodal"
    MULTIMODAL = "multimodal"
    UNKNOWN = "unknown"

class LearningEffectiveness(Enum):
    """å­¸ç¿’æ•ˆæœ"""
    MINIMAL = "minimal"         # < 10% æ”¹è®Š
    MODERATE = "moderate"       # 10-30% æ”¹è®Š
    SUBSTANTIAL = "substantial" # 30-70% æ”¹è®Š
    DRAMATIC = "dramatic"       # > 70% æ”¹è®Š

@dataclass
class DistributionCharacteristics:
    """åˆ†å¸ƒç‰¹å¾µ"""
    mean: float
    std: float
    skewness: float
    kurtosis: float
    distribution_type: DistributionType
    normality_p_value: float
    is_normal: bool
    confidence_intervals: Dict[str, Tuple[float, float]]

@dataclass
class PriorPosteriorComparison:
    """å…ˆé©—å¾Œé©—æ¯”è¼ƒ"""
    parameter_name: str
    prior_characteristics: DistributionCharacteristics
    posterior_characteristics: DistributionCharacteristics
    kl_divergence: float
    wasserstein_distance: float
    learning_effectiveness: LearningEffectiveness
    shift_magnitude: float

@dataclass
class ParameterCorrelation:
    """åƒæ•¸ç›¸é—œæ€§"""
    param1: str
    param2: str
    correlation: float
    mutual_information: float
    rank_correlation: float
    significance_p_value: float

@dataclass
class PosteriorPredictiveCheck:
    """å¾Œé©—é æ¸¬æª¢é©—"""
    observed_statistic: float
    predicted_statistics: np.ndarray
    p_value: float
    extreme_probability: float
    check_type: str

@dataclass
class PosteriorAnalysisReport:
    """å¾Œé©—åˆ†æå ±å‘Š"""
    prior_posterior_comparisons: List[PriorPosteriorComparison]
    parameter_correlations: List[ParameterCorrelation]
    posterior_predictive_checks: List[PosteriorPredictiveCheck]
    mixed_predictive_estimation: Dict[str, Any]
    summary_statistics: Dict[str, Any]
    recommendations: List[str]

class PosteriorAnalysisReporter:
    """
    å¾Œé©—åˆ†æå ±å‘Šå™¨
    
    æä¾›å¾Œé©—åˆ†å¸ƒçš„å…¨é¢åˆ†æå’Œè©•ä¼°
    """
    
    def __init__(self, 
                 confidence_levels: List[float] = [0.5, 0.8, 0.9, 0.95],
                 n_posterior_predictive_samples: int = 1000,
                 correlation_threshold: float = 0.3):
        """
        åˆå§‹åŒ–å¾Œé©—åˆ†æå ±å‘Šå™¨
        
        Parameters:
        -----------
        confidence_levels : List[float]
            ä¿¡è³´å€é–“æ°´æº–
        n_posterior_predictive_samples : int
            å¾Œé©—é æ¸¬æ¨£æœ¬æ•¸
        correlation_threshold : float
            ç›¸é—œæ€§é¡¯è‘—æ€§é–¾å€¼
        """
        self.confidence_levels = confidence_levels
        self.n_pp_samples = n_posterior_predictive_samples
        self.correlation_threshold = correlation_threshold
        
        # è¨­ç½®åœ–è¡¨æ¨£å¼
        plt.style.use('default')
        sns.set_style("whitegrid")
        self.colors = sns.color_palette("Set2", 8)
    
    def analyze_posterior_distributions(self, 
                                      posterior_samples: Dict[str, np.ndarray],
                                      prior_specifications: Optional[Dict[str, Dict]] = None,
                                      observed_data: Optional[np.ndarray] = None,
                                      hierarchical_result: Optional[HierarchicalModelResult] = None) -> PosteriorAnalysisReport:
        """
        å…¨é¢çš„å¾Œé©—åˆ†å¸ƒåˆ†æ
        
        Parameters:
        -----------
        posterior_samples : Dict[str, np.ndarray]
            å¾Œé©—æ¨£æœ¬
        prior_specifications : Dict[str, Dict], optional
            å…ˆé©—è¦æ ¼ {param: {'distribution': 'normal', 'params': {...}}}
        observed_data : np.ndarray, optional
            è§€æ¸¬è³‡æ–™
        hierarchical_result : HierarchicalModelResult, optional
            éšå±¤æ¨¡å‹çµæœ
            
        Returns:
        --------
        PosteriorAnalysisReport
            å®Œæ•´çš„å¾Œé©—åˆ†æå ±å‘Š
        """
        
        print("ğŸ“Š é–‹å§‹å¾Œé©—åˆ†å¸ƒåˆ†æ...")
        
        # 1. å…ˆé©—èˆ‡å¾Œé©—æ¯”è¼ƒ
        print("  ğŸ”„ å…ˆé©— vs å¾Œé©—æ¯”è¼ƒ...")
        prior_posterior_comparisons = self._compare_prior_posterior(
            posterior_samples, prior_specifications
        )
        
        # 2. åƒæ•¸ç›¸é—œæ€§åˆ†æ
        print("  ğŸ”— åƒæ•¸ç›¸é—œæ€§åˆ†æ...")
        parameter_correlations = self._analyze_parameter_correlations(posterior_samples)
        
        # 3. å¾Œé©—é æ¸¬æª¢é©—
        print("  âœ… å¾Œé©—é æ¸¬æª¢é©—...")
        posterior_predictive_checks = []
        if observed_data is not None:
            posterior_predictive_checks = self._perform_posterior_predictive_checks(
                posterior_samples, observed_data
            )
        
        # 4. MPE åˆ†æ
        print("  ğŸ”„ æ··åˆé æ¸¬ä¼°è¨ˆåˆ†æ...")
        mpe_analysis = self._analyze_mixed_predictive_estimation(
            posterior_samples, hierarchical_result
        )
        
        # 5. æ‘˜è¦çµ±è¨ˆ
        summary_statistics = self._calculate_posterior_summary_statistics(
            posterior_samples, prior_posterior_comparisons, parameter_correlations
        )
        
        # 6. ç”Ÿæˆå»ºè­°
        recommendations = self._generate_posterior_recommendations(
            prior_posterior_comparisons, parameter_correlations, 
            posterior_predictive_checks, summary_statistics
        )
        
        report = PosteriorAnalysisReport(
            prior_posterior_comparisons=prior_posterior_comparisons,
            parameter_correlations=parameter_correlations,
            posterior_predictive_checks=posterior_predictive_checks,
            mixed_predictive_estimation=mpe_analysis,
            summary_statistics=summary_statistics,
            recommendations=recommendations
        )
        
        print("âœ… å¾Œé©—åˆ†å¸ƒåˆ†æå®Œæˆ")
        return report
    
    def _analyze_distribution_characteristics(self, 
                                            samples: np.ndarray) -> DistributionCharacteristics:
        """åˆ†æåˆ†å¸ƒç‰¹å¾µ"""
        
        if len(samples) == 0:
            return DistributionCharacteristics(
                mean=0, std=0, skewness=0, kurtosis=0,
                distribution_type=DistributionType.UNKNOWN,
                normality_p_value=0, is_normal=False,
                confidence_intervals={}
            )
        
        # åŸºæœ¬çµ±è¨ˆé‡
        mean = np.mean(samples)
        std = np.std(samples, ddof=1)
        skewness = stats.skew(samples)
        kurtosis = stats.kurtosis(samples)
        
        # å¸¸æ…‹æ€§æª¢å®š
        if len(samples) >= 8:
            try:
                _, normality_p = shapiro(samples) if len(samples) <= 5000 else jarque_bera(samples)[1]
            except:
                normality_p = 0.0
        else:
            normality_p = 0.0
        
        is_normal = normality_p > 0.05
        
        # åˆ†å¸ƒé¡å‹åˆ¤æ–·
        distribution_type = self._classify_distribution_type(
            samples, skewness, kurtosis, is_normal
        )
        
        # ä¿¡è³´å€é–“
        confidence_intervals = {}
        for level in self.confidence_levels:
            alpha = 1 - level
            lower = np.percentile(samples, 100 * alpha / 2)
            upper = np.percentile(samples, 100 * (1 - alpha / 2))
            confidence_intervals[f'{level:.0%}'] = (lower, upper)
        
        return DistributionCharacteristics(
            mean=mean,
            std=std,
            skewness=skewness,
            kurtosis=kurtosis,
            distribution_type=distribution_type,
            normality_p_value=normality_p,
            is_normal=is_normal,
            confidence_intervals=confidence_intervals
        )
    
    def _classify_distribution_type(self, 
                                  samples: np.ndarray, 
                                  skewness: float, 
                                  kurtosis: float, 
                                  is_normal: bool) -> DistributionType:
        """åˆ†é¡åˆ†å¸ƒé¡å‹"""
        
        # æª¢æŸ¥å¤šæ¨¡æ…‹
        if len(samples) > 50:
            try:
                # ä½¿ç”¨é«˜æ–¯æ··åˆæ¨¡å‹æª¢æ¸¬æ¨¡æ…‹æ•¸
                n_components_range = range(1, min(6, len(samples) // 10))
                best_n_components = 1
                best_bic = np.inf
                
                for n_comp in n_components_range:
                    gm = GaussianMixture(n_components=n_comp, random_state=42)
                    gm.fit(samples.reshape(-1, 1))
                    bic = gm.bic(samples.reshape(-1, 1))
                    if bic < best_bic:
                        best_bic = bic
                        best_n_components = n_comp
                
                if best_n_components > 2:
                    return DistributionType.MULTIMODAL
                elif best_n_components == 2:
                    return DistributionType.BIMODAL
            except:
                pass
        
        # å–®æ¨¡æ…‹åˆ†é¡ - ç¢ºä¿ä½¿ç”¨æ¨™é‡å€¼
        skewness_val = float(skewness) if hasattr(skewness, 'item') else skewness
        kurtosis_val = float(kurtosis) if hasattr(kurtosis, 'item') else kurtosis
        
        if is_normal and abs(skewness_val) < 0.5 and abs(kurtosis_val) < 1:
            return DistributionType.NORMAL
        elif abs(skewness_val) > 1:
            return DistributionType.SKEWED
        elif abs(kurtosis_val) > 2:
            return DistributionType.HEAVY_TAILED
        else:
            return DistributionType.NORMAL
    
    def _compare_prior_posterior(self, 
                               posterior_samples: Dict[str, np.ndarray],
                               prior_specifications: Optional[Dict[str, Dict]]) -> List[PriorPosteriorComparison]:
        """æ¯”è¼ƒå…ˆé©—èˆ‡å¾Œé©—åˆ†å¸ƒ"""
        
        comparisons = []
        
        for param_name, post_samples in posterior_samples.items():
            if post_samples.ndim == 1 and len(post_samples) > 0:
                # å¾Œé©—ç‰¹å¾µ
                posterior_chars = self._analyze_distribution_characteristics(post_samples)
                
                # å…ˆé©—ç‰¹å¾µ (å¦‚æœæä¾›)
                if prior_specifications and param_name in prior_specifications:
                    prior_chars = self._get_prior_characteristics(
                        prior_specifications[param_name], post_samples
                    )
                else:
                    # ä½¿ç”¨å¼±ä¿¡æ¯å…ˆé©—ä½œç‚ºåƒè€ƒ
                    prior_chars = self._create_default_prior_characteristics(post_samples)
                
                # è¨ˆç®—è·é›¢æ¸¬åº¦
                kl_div = self._calculate_kl_divergence(prior_chars, posterior_chars)
                wasserstein_dist = self._calculate_wasserstein_distance(prior_chars, posterior_chars)
                
                # è©•ä¼°å­¸ç¿’æ•ˆæœ
                learning_effect = self._assess_learning_effectiveness(prior_chars, posterior_chars)
                
                # è¨ˆç®—è®ŠåŒ–å¹…åº¦
                shift_magnitude = abs(posterior_chars.mean - prior_chars.mean) / prior_chars.std if prior_chars.std > 0 else 0
                
                comparison = PriorPosteriorComparison(
                    parameter_name=param_name,
                    prior_characteristics=prior_chars,
                    posterior_characteristics=posterior_chars,
                    kl_divergence=kl_div,
                    wasserstein_distance=wasserstein_dist,
                    learning_effectiveness=learning_effect,
                    shift_magnitude=shift_magnitude
                )
                
                comparisons.append(comparison)
        
        return comparisons
    
    def _get_prior_characteristics(self, 
                                 prior_spec: Dict, 
                                 reference_samples: np.ndarray) -> DistributionCharacteristics:
        """å¾å…ˆé©—è¦æ ¼ç²å–å…ˆé©—ç‰¹å¾µ"""
        
        # ç”Ÿæˆå…ˆé©—æ¨£æœ¬
        n_samples = len(reference_samples)
        
        if prior_spec['distribution'] == 'normal':
            params = prior_spec['params']
            prior_samples = np.random.normal(
                params['loc'], params['scale'], n_samples
            )
        elif prior_spec['distribution'] == 'gamma':
            params = prior_spec['params']
            prior_samples = np.random.gamma(
                params['a'], params['scale'], n_samples
            )
        elif prior_spec['distribution'] == 'uniform':
            params = prior_spec['params']
            prior_samples = np.random.uniform(
                params['low'], params['high'], n_samples
            )
        else:
            # å›é€€åˆ°å¼±ä¿¡æ¯å…ˆé©—
            return self._create_default_prior_characteristics(reference_samples)
        
        return self._analyze_distribution_characteristics(prior_samples)
    
    def _create_default_prior_characteristics(self, 
                                            reference_samples: np.ndarray) -> DistributionCharacteristics:
        """å‰µå»ºé è¨­å…ˆé©—ç‰¹å¾µ (å¼±ä¿¡æ¯)"""
        
        # ä½¿ç”¨å¾Œé©—çš„ç¯„åœå‰µå»ºå¼±ä¿¡æ¯å…ˆé©—
        post_mean = np.mean(reference_samples)
        post_std = np.std(reference_samples)
        
        # å¼±ä¿¡æ¯å…ˆé©—ï¼šå‡å€¼ç›¸åŒï¼Œä½†æ¨™æº–å·®å¤§5å€
        prior_std = post_std * 5
        
        return DistributionCharacteristics(
            mean=post_mean,
            std=prior_std,
            skewness=0,  # å‡è¨­å°ç¨±
            kurtosis=0,  # å‡è¨­å¸¸æ…‹
            distribution_type=DistributionType.NORMAL,
            normality_p_value=1.0,
            is_normal=True,
            confidence_intervals={}
        )
    
    def _calculate_kl_divergence(self, 
                               prior_chars: DistributionCharacteristics,
                               posterior_chars: DistributionCharacteristics) -> float:
        """è¨ˆç®— KL æ•£åº¦ (ç°¡åŒ–ç‰ˆ)"""
        
        # å‡è¨­å¸¸æ…‹åˆ†å¸ƒçš„ KL æ•£åº¦
        mu1, sig1 = prior_chars.mean, prior_chars.std
        mu2, sig2 = posterior_chars.mean, posterior_chars.std
        
        if sig1 <= 0 or sig2 <= 0:
            return np.inf
        
        kl = np.log(sig2 / sig1) + (sig1**2 + (mu1 - mu2)**2) / (2 * sig2**2) - 0.5
        
        return max(0, kl)
    
    def _calculate_wasserstein_distance(self, 
                                      prior_chars: DistributionCharacteristics,
                                      posterior_chars: DistributionCharacteristics) -> float:
        """è¨ˆç®— Wasserstein è·é›¢ (ç°¡åŒ–ç‰ˆ)"""
        
        # å°æ–¼å¸¸æ…‹åˆ†å¸ƒçš„ Wasserstein è·é›¢
        mu1, sig1 = prior_chars.mean, prior_chars.std
        mu2, sig2 = posterior_chars.mean, posterior_chars.std
        
        wasserstein = np.sqrt((mu1 - mu2)**2 + (sig1 - sig2)**2)
        
        return wasserstein
    
    def _assess_learning_effectiveness(self, 
                                     prior_chars: DistributionCharacteristics,
                                     posterior_chars: DistributionCharacteristics) -> LearningEffectiveness:
        """è©•ä¼°å­¸ç¿’æ•ˆæœ"""
        
        # åŸºæ–¼æ¨™æº–å·®çš„æ¸›å°‘æ¯”ä¾‹
        if prior_chars.std <= 0:
            return LearningEffectiveness.MINIMAL
        
        variance_reduction = 1 - (posterior_chars.std / prior_chars.std)
        
        if variance_reduction < 0.1:
            return LearningEffectiveness.MINIMAL
        elif variance_reduction < 0.3:
            return LearningEffectiveness.MODERATE
        elif variance_reduction < 0.7:
            return LearningEffectiveness.SUBSTANTIAL
        else:
            return LearningEffectiveness.DRAMATIC
    
    def _analyze_parameter_correlations(self, 
                                      posterior_samples: Dict[str, np.ndarray]) -> List[ParameterCorrelation]:
        """åˆ†æåƒæ•¸ç›¸é—œæ€§"""
        
        correlations = []
        param_names = [name for name, samples in posterior_samples.items() 
                      if samples.ndim == 1 and len(samples) > 0]
        
        for i, param1 in enumerate(param_names):
            for j, param2 in enumerate(param_names[i+1:], i+1):
                samples1 = posterior_samples[param1]
                samples2 = posterior_samples[param2]
                
                # ç¢ºä¿æ¨£æœ¬é•·åº¦ç›¸åŒ
                min_len = min(len(samples1), len(samples2))
                samples1 = samples1[:min_len]
                samples2 = samples2[:min_len]
                
                if min_len > 3:
                    # Pearson ç›¸é—œä¿‚æ•¸
                    corr_coef, p_value = stats.pearsonr(samples1, samples2)
                    
                    # Spearman ç­‰ç´šç›¸é—œ
                    rank_corr, _ = stats.spearmanr(samples1, samples2)
                    
                    # äº’ä¿¡æ¯ (ç°¡åŒ–ç‰ˆ)
                    mutual_info = self._calculate_mutual_information(samples1, samples2)
                    
                    correlation = ParameterCorrelation(
                        param1=param1,
                        param2=param2,
                        correlation=corr_coef,
                        mutual_information=mutual_info,
                        rank_correlation=rank_corr,
                        significance_p_value=p_value
                    )
                    
                    correlations.append(correlation)
        
        return correlations
    
    def _calculate_mutual_information(self, 
                                    samples1: np.ndarray, 
                                    samples2: np.ndarray,
                                    bins: int = 20) -> float:
        """è¨ˆç®—äº’ä¿¡æ¯ (ç°¡åŒ–ç‰ˆ)"""
        
        try:
            # é›¢æ•£åŒ–
            hist_2d, x_edges, y_edges = np.histogram2d(samples1, samples2, bins=bins)
            hist_1d_x = np.histogram(samples1, bins=x_edges)[0]
            hist_1d_y = np.histogram(samples2, bins=y_edges)[0]
            
            # æ­¸ä¸€åŒ–
            p_xy = hist_2d / np.sum(hist_2d)
            p_x = hist_1d_x / np.sum(hist_1d_x)
            p_y = hist_1d_y / np.sum(hist_1d_y)
            
            # è¨ˆç®—äº’ä¿¡æ¯
            mi = 0
            for i in range(len(p_x)):
                for j in range(len(p_y)):
                    # ç¢ºä¿æ‰€æœ‰å€¼éƒ½æ˜¯æ¨™é‡é€²è¡Œæ¯”è¼ƒ
                    pxy_val = float(p_xy[i, j]) if hasattr(p_xy[i, j], 'item') else p_xy[i, j]
                    px_val = float(p_x[i]) if hasattr(p_x[i], 'item') else p_x[i]
                    py_val = float(p_y[j]) if hasattr(p_y[j], 'item') else p_y[j]
                    
                    if pxy_val > 0 and px_val > 0 and py_val > 0:
                        mi += p_xy[i, j] * np.log(p_xy[i, j] / (p_x[i] * p_y[j]))
            
            return max(0, mi)
            
        except:
            return 0.0
    
    def _perform_posterior_predictive_checks(self, 
                                           posterior_samples: Dict[str, np.ndarray],
                                           observed_data: np.ndarray) -> List[PosteriorPredictiveCheck]:
        """åŸ·è¡Œå¾Œé©—é æ¸¬æª¢é©—"""
        
        checks = []
        
        # æª¢é©—é …ç›®
        check_functions = {
            'mean': lambda x: np.mean(x),
            'std': lambda x: np.std(x),
            'min': lambda x: np.min(x),
            'max': lambda x: np.max(x),
            'skewness': lambda x: stats.skew(x) if len(x) > 2 else 0,
            'kurtosis': lambda x: stats.kurtosis(x) if len(x) > 2 else 0
        }
        
        # è§€æ¸¬çµ±è¨ˆé‡
        observed_stats = {name: func(observed_data) 
                         for name, func in check_functions.items()}
        
        # ç”Ÿæˆå¾Œé©—é æ¸¬æ¨£æœ¬
        predicted_stats = {name: [] for name in check_functions.keys()}
        
        for _ in range(self.n_pp_samples):
            # ç°¡åŒ–çš„é æ¸¬è³‡æ–™ç”Ÿæˆ
            if 'mu' in posterior_samples and 'sigma' in posterior_samples:
                # å¾å¾Œé©—æ¨£æœ¬ä¸­éš¨æ©Ÿé¸æ“‡åƒæ•¸
                idx = np.random.randint(len(posterior_samples['mu']))
                mu = posterior_samples['mu'][idx]
                sigma = posterior_samples['sigma'][idx] if 'sigma' in posterior_samples else np.std(observed_data)
                
                # ç”Ÿæˆé æ¸¬è³‡æ–™
                predicted_data = np.random.normal(mu, sigma, len(observed_data))
            else:
                # å›é€€ï¼šä½¿ç”¨è§€æ¸¬è³‡æ–™çš„ bootstrap
                predicted_data = np.random.choice(observed_data, len(observed_data), replace=True)
            
            # è¨ˆç®—é æ¸¬çµ±è¨ˆé‡
            for name, func in check_functions.items():
                try:
                    stat_value = func(predicted_data)
                    predicted_stats[name].append(stat_value)
                except:
                    predicted_stats[name].append(np.nan)
        
        # å‰µå»ºæª¢é©—çµæœ
        for check_name in check_functions.keys():
            pred_array = np.array(predicted_stats[check_name])
            pred_array = pred_array[~np.isnan(pred_array)]
            
            if len(pred_array) > 0:
                obs_stat = observed_stats[check_name]
                
                # è¨ˆç®— p å€¼
                p_value = np.mean(pred_array >= obs_stat) if not np.isnan(obs_stat) else 0.5
                p_value = min(p_value, 1 - p_value) * 2  # é›™é‚Šæª¢é©—
                
                # æ¥µç«¯æ©Ÿç‡
                extreme_prob = min(np.mean(pred_array <= obs_stat), np.mean(pred_array >= obs_stat))
                
                check = PosteriorPredictiveCheck(
                    observed_statistic=obs_stat,
                    predicted_statistics=pred_array,
                    p_value=p_value,
                    extreme_probability=extreme_prob,
                    check_type=check_name
                )
                
                checks.append(check)
        
        return checks
    
    def _analyze_mixed_predictive_estimation(self, 
                                           posterior_samples: Dict[str, np.ndarray],
                                           hierarchical_result: Optional[HierarchicalModelResult]) -> Dict[str, Any]:
        """åˆ†ææ··åˆé æ¸¬ä¼°è¨ˆ"""
        
        mpe_analysis = {}
        
        if hierarchical_result and hierarchical_result.mpe_components:
            mpe_analysis['available'] = True
            mpe_analysis['components'] = hierarchical_result.mpe_components
            
            # åˆ†ææ··åˆæˆåˆ†
            for param_name, mpe_result in hierarchical_result.mpe_components.items():
                if isinstance(mpe_result, dict) and 'mixture_weights' in mpe_result:
                    weights = mpe_result['mixture_weights']
                    n_components = len(weights)
                    
                    mpe_analysis[f'{param_name}_n_components'] = n_components
                    mpe_analysis[f'{param_name}_weights'] = weights
                    mpe_analysis[f'{param_name}_effective_components'] = np.sum(np.array(weights) > 0.05)
        else:
            # æ‰‹å‹•åŸ·è¡Œ MPE
            mpe_analysis['available'] = False
            mpe_analysis['manual_mpe'] = {}
            
            mpe = MixedPredictiveEstimation(n_components=3)
            
            for param_name, samples in posterior_samples.items():
                if samples.ndim == 1 and len(samples) > 10:
                    try:
                        mpe_result = mpe.fit_mixture(samples, "normal")
                        mpe_analysis['manual_mpe'][param_name] = mpe_result
                    except:
                        pass
        
        return mpe_analysis
    
    def _calculate_posterior_summary_statistics(self, 
                                              posterior_samples: Dict[str, np.ndarray],
                                              prior_posterior_comparisons: List[PriorPosteriorComparison],
                                              parameter_correlations: List[ParameterCorrelation]) -> Dict[str, Any]:
        """è¨ˆç®—å¾Œé©—æ‘˜è¦çµ±è¨ˆ"""
        
        summary = {
            'n_parameters': len([samples for samples in posterior_samples.values() 
                               if samples.ndim == 1]),
            'total_samples': sum(len(samples) for samples in posterior_samples.values() 
                               if samples.ndim == 1),
            'parameter_names': [name for name, samples in posterior_samples.items() 
                              if samples.ndim == 1]
        }
        
        # å­¸ç¿’æ•ˆæœçµ±è¨ˆ
        if prior_posterior_comparisons:
            learning_effects = [comp.learning_effectiveness for comp in prior_posterior_comparisons]
            summary['learning_effects'] = {
                'minimal': sum(1 for le in learning_effects if le == LearningEffectiveness.MINIMAL),
                'moderate': sum(1 for le in learning_effects if le == LearningEffectiveness.MODERATE),
                'substantial': sum(1 for le in learning_effects if le == LearningEffectiveness.SUBSTANTIAL),
                'dramatic': sum(1 for le in learning_effects if le == LearningEffectiveness.DRAMATIC)
            }
            
            summary['mean_kl_divergence'] = np.mean([comp.kl_divergence for comp in prior_posterior_comparisons])
        
        # ç›¸é—œæ€§çµ±è¨ˆ
        if parameter_correlations:
            high_correlations = [corr for corr in parameter_correlations 
                               if abs(corr.correlation) > self.correlation_threshold]
            
            summary['n_correlations'] = len(parameter_correlations)
            summary['n_high_correlations'] = len(high_correlations)
            summary['max_correlation'] = max(abs(corr.correlation) for corr in parameter_correlations)
        
        return summary
    
    def _generate_posterior_recommendations(self, 
                                          prior_posterior_comparisons: List[PriorPosteriorComparison],
                                          parameter_correlations: List[ParameterCorrelation],
                                          posterior_predictive_checks: List[PosteriorPredictiveCheck],
                                          summary_statistics: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆå¾Œé©—åˆ†æå»ºè­°"""
        
        recommendations = []
        
        # å­¸ç¿’æ•ˆæœå»ºè­°
        if 'learning_effects' in summary_statistics:
            effects = summary_statistics['learning_effects']
            
            if effects['minimal'] > effects['substantial'] + effects['dramatic']:
                recommendations.append("âš ï¸ å¤šæ•¸åƒæ•¸å­¸ç¿’æ•ˆæœæœ‰é™ï¼Œè€ƒæ…®:")
                recommendations.append("â€¢ å¢åŠ è³‡æ–™é‡")
                recommendations.append("â€¢ ä½¿ç”¨æ›´ä¿¡æ¯æ€§çš„å…ˆé©—")
                recommendations.append("â€¢ æª¢æŸ¥æ¨¡å‹è¦æ ¼")
            
            elif effects['dramatic'] > 0:
                recommendations.append(f"ğŸ“ˆ {effects['dramatic']} å€‹åƒæ•¸æœ‰é¡¯è‘—å­¸ç¿’æ•ˆæœ")
                recommendations.append("â€¢ è³‡æ–™å°é€™äº›åƒæ•¸æä¾›äº†è±å¯Œä¿¡æ¯")
        
        # åƒæ•¸ç›¸é—œæ€§å»ºè­°
        if 'n_high_correlations' in summary_statistics and summary_statistics['n_high_correlations'] > 0:
            n_high = summary_statistics['n_high_correlations']
            recommendations.append(f"ğŸ”— ç™¼ç¾ {n_high} çµ„é«˜ç›¸é—œåƒæ•¸")
            
            if summary_statistics['max_correlation'] > 0.8:
                recommendations.append("â€¢ è€ƒæ…®åƒæ•¸é‡æ–°åƒæ•¸åŒ–")
                recommendations.append("â€¢ æ³¨æ„å¤šé‡å…±ç·šæ€§å•é¡Œ")
        
        # å¾Œé©—é æ¸¬æª¢é©—å»ºè­°
        failed_checks = [check for check in posterior_predictive_checks if check.p_value < 0.05]
        
        if len(failed_checks) > len(posterior_predictive_checks) * 0.3:
            recommendations.append("âŒ å¤šé …å¾Œé©—é æ¸¬æª¢é©—æœªé€šé")
            recommendations.append("â€¢ æ¨¡å‹å¯èƒ½ä¸é©åˆè³‡æ–™")
            recommendations.append("â€¢ è€ƒæ…®ä¿®æ”¹æ¨¡å‹è¦æ ¼")
        elif len(failed_checks) > 0:
            check_names = [check.check_type for check in failed_checks]
            recommendations.append(f"âš ï¸ æª¢é©—é …ç›®ç•°å¸¸: {', '.join(check_names[:3])}")
        else:
            recommendations.append("âœ… å¾Œé©—é æ¸¬æª¢é©—é€šé")
        
        # åˆ†å¸ƒé¡å‹å»ºè­°
        non_normal_params = [comp.parameter_name for comp in prior_posterior_comparisons 
                           if comp.posterior_characteristics.distribution_type != DistributionType.NORMAL]
        
        if len(non_normal_params) > 0:
            recommendations.append(f"ğŸ“Š éå¸¸æ…‹åƒæ•¸: {', '.join(non_normal_params[:3])}")
            recommendations.append("â€¢ è€ƒæ…®è®Šæ›æˆ–ä½¿ç”¨éå¸¸æ…‹æ¨¡å‹")
        
        return recommendations
    
    def plot_posterior_analysis(self, 
                              posterior_report: PosteriorAnalysisReport,
                              posterior_samples: Dict[str, np.ndarray],
                              save_path: Optional[str] = None,
                              figsize: Tuple[int, int] = (16, 12)) -> plt.Figure:
        """ç¹ªè£½å¾Œé©—åˆ†æåœ–è¡¨"""
        
        n_params = len([name for name, samples in posterior_samples.items() 
                       if samples.ndim == 1])
        
        if n_params == 0:
            print("æ²’æœ‰åƒæ•¸å¯ç¹ªåœ–")
            return None
        
        # å‹•æ…‹è¨ˆç®—å­åœ–æ•¸é‡
        n_plots = min(6, n_params + 2)  # åƒæ•¸åœ– + ç›¸é—œæ€§ + é æ¸¬æª¢é©—
        n_cols = 3
        n_rows = (n_plots + n_cols - 1) // n_cols
        
        fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)
        if n_rows == 1:
            axes = axes.reshape(1, -1)
        elif n_cols == 1:
            axes = axes.reshape(-1, 1)
        
        fig.suptitle('å¾Œé©—åˆ†å¸ƒåˆ†æ', fontsize=16, fontweight='bold')
        
        plot_idx = 0
        
        # 1. åƒæ•¸å¾Œé©—åˆ†å¸ƒ (å‰4å€‹åƒæ•¸)
        param_names = [name for name, samples in posterior_samples.items() 
                      if samples.ndim == 1][:4]
        
        for i, param_name in enumerate(param_names):
            if plot_idx >= n_plots:
                break
                
            row = plot_idx // n_cols
            col = plot_idx % n_cols
            ax = axes[row, col]
            
            samples = posterior_samples[param_name]
            
            # ç¹ªè£½å¾Œé©—åˆ†å¸ƒ
            ax.hist(samples, bins=50, alpha=0.7, color=self.colors[i], 
                   density=True, label='Posterior')
            
            # æ·»åŠ çµ±è¨ˆç·š
            mean_val = np.mean(samples)
            ax.axvline(mean_val, color='red', linestyle='--', label=f'Mean: {mean_val:.3f}')
            
            # ä¿¡è³´å€é–“
            ci_95 = np.percentile(samples, [2.5, 97.5])
            ax.axvspan(ci_95[0], ci_95[1], alpha=0.2, color=self.colors[i], label='95% CI')
            
            ax.set_title(f'{param_name}')
            ax.set_xlabel('Value')
            ax.set_ylabel('Density')
            ax.legend()
            
            plot_idx += 1
        
        # 2. åƒæ•¸ç›¸é—œæ€§ç†±åœ–
        if plot_idx < n_plots and posterior_report.parameter_correlations:
            row = plot_idx // n_cols
            col = plot_idx % n_cols
            ax = axes[row, col]
            
            # å‰µå»ºç›¸é—œæ€§çŸ©é™£
            unique_params = list(set([corr.param1 for corr in posterior_report.parameter_correlations] +
                                   [corr.param2 for corr in posterior_report.parameter_correlations]))
            
            n_unique = len(unique_params)
            corr_matrix = np.eye(n_unique)
            
            for corr in posterior_report.parameter_correlations:
                i = unique_params.index(corr.param1)
                j = unique_params.index(corr.param2)
                corr_matrix[i, j] = corr.correlation
                corr_matrix[j, i] = corr.correlation
            
            im = ax.imshow(corr_matrix, cmap='RdBu_r', vmin=-1, vmax=1)
            ax.set_xticks(range(n_unique))
            ax.set_yticks(range(n_unique))
            ax.set_xticklabels(unique_params, rotation=45)
            ax.set_yticklabels(unique_params)
            ax.set_title('åƒæ•¸ç›¸é—œæ€§')
            
            # æ·»åŠ æ•¸å€¼æ¨™è¨»
            for i in range(n_unique):
                for j in range(n_unique):
                    text = ax.text(j, i, f'{corr_matrix[i, j]:.2f}',
                                 ha="center", va="center", color="black", fontsize=8)
            
            plt.colorbar(im, ax=ax, shrink=0.8)
            plot_idx += 1
        
        # 3. å¾Œé©—é æ¸¬æª¢é©—
        if plot_idx < n_plots and posterior_report.posterior_predictive_checks:
            row = plot_idx // n_cols
            col = plot_idx % n_cols
            ax = axes[row, col]
            
            check_names = [check.check_type for check in posterior_report.posterior_predictive_checks]
            p_values = [check.p_value for check in posterior_report.posterior_predictive_checks]
            
            bars = ax.bar(range(len(check_names)), p_values, 
                         color=['red' if p < 0.05 else 'green' for p in p_values],
                         alpha=0.7)
            
            ax.axhline(0.05, color='red', linestyle='--', label='Î± = 0.05')
            ax.set_xlabel('æª¢é©—é …ç›®')
            ax.set_ylabel('p-value')
            ax.set_title('å¾Œé©—é æ¸¬æª¢é©—')
            ax.set_xticks(range(len(check_names)))
            ax.set_xticklabels(check_names, rotation=45)
            ax.legend()
            
            plot_idx += 1
        
        # éš±è—å¤šé¤˜çš„å­åœ–
        for i in range(plot_idx, n_rows * n_cols):
            row = i // n_cols
            col = i % n_cols
            axes[row, col].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        
        return fig
    
    def generate_posterior_report(self, 
                                posterior_report: PosteriorAnalysisReport,
                                include_details: bool = True) -> str:
        """ç”Ÿæˆå¾Œé©—åˆ†æå ±å‘Š"""
        
        report = []
        report.append("=" * 80)
        report.append("                    å¾Œé©—åˆ†å¸ƒåˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # æ•´é«”æ‘˜è¦
        report.append("ğŸ“Š åˆ†ææ‘˜è¦")
        report.append("-" * 40)
        
        summary = posterior_report.summary_statistics
        report.append(f"ğŸ“ˆ åˆ†æåƒæ•¸æ•¸: {summary.get('n_parameters', 0)}")
        report.append(f"ğŸ“Š ç¸½æ¨£æœ¬æ•¸: {summary.get('total_samples', 0)}")
        
        if 'learning_effects' in summary:
            effects = summary['learning_effects']
            report.append(f"ğŸ“š å­¸ç¿’æ•ˆæœåˆ†å¸ƒ:")
            report.append(f"    é¡¯è‘—: {effects.get('dramatic', 0)} å€‹")
            report.append(f"    å¯¦è³ª: {effects.get('substantial', 0)} å€‹")
            report.append(f"    ä¸­ç­‰: {effects.get('moderate', 0)} å€‹")
            report.append(f"    å¾®å¼±: {effects.get('minimal', 0)} å€‹")
        
        report.append("")
        
        # å…ˆé©—å¾Œé©—æ¯”è¼ƒ
        if include_details and posterior_report.prior_posterior_comparisons:
            report.append("ğŸ”„ å…ˆé©— vs å¾Œé©—æ¯”è¼ƒ")
            report.append("-" * 40)
            
            for comp in posterior_report.prior_posterior_comparisons[:5]:  # å‰5å€‹
                learning_icons = {
                    LearningEffectiveness.DRAMATIC: "ğŸš€",
                    LearningEffectiveness.SUBSTANTIAL: "ğŸ“ˆ",
                    LearningEffectiveness.MODERATE: "ğŸ“Š",
                    LearningEffectiveness.MINIMAL: "ğŸ“‰"
                }
                
                icon = learning_icons.get(comp.learning_effectiveness, "ğŸ“Š")
                report.append(f"{icon} {comp.parameter_name}:")
                report.append(f"    å¾Œé©—å‡å€¼: {comp.posterior_characteristics.mean:.3f}")
                report.append(f"    å¾Œé©—æ¨™æº–å·®: {comp.posterior_characteristics.std:.3f}")
                report.append(f"    å­¸ç¿’æ•ˆæœ: {comp.learning_effectiveness.value}")
                report.append(f"    KL æ•£åº¦: {comp.kl_divergence:.3f}")
                report.append("")
        
        # åƒæ•¸ç›¸é—œæ€§
        if posterior_report.parameter_correlations:
            report.append("ğŸ”— åƒæ•¸ç›¸é—œæ€§åˆ†æ")
            report.append("-" * 40)
            
            high_corr = [corr for corr in posterior_report.parameter_correlations 
                        if abs(corr.correlation) > self.correlation_threshold]
            
            report.append(f"ğŸ“Š é«˜ç›¸é—œåƒæ•¸å°: {len(high_corr)}")
            
            if include_details:
                for corr in high_corr[:5]:  # å‰5å€‹é«˜ç›¸é—œ
                    report.append(f"â€¢ {corr.param1} - {corr.param2}: {corr.correlation:.3f}")
            report.append("")
        
        # å¾Œé©—é æ¸¬æª¢é©—
        if posterior_report.posterior_predictive_checks:
            report.append("âœ… å¾Œé©—é æ¸¬æª¢é©—")
            report.append("-" * 40)
            
            failed_checks = [check for check in posterior_report.posterior_predictive_checks 
                           if check.p_value < 0.05]
            
            report.append(f"ğŸ“Š æª¢é©—é …ç›®æ•¸: {len(posterior_report.posterior_predictive_checks)}")
            report.append(f"âŒ æœªé€šéæª¢é©—: {len(failed_checks)}")
            
            if failed_checks and include_details:
                report.append("æœªé€šéçš„æª¢é©—:")
                for check in failed_checks:
                    report.append(f"â€¢ {check.check_type}: p = {check.p_value:.3f}")
            report.append("")
        
        # å»ºè­°
        report.append("ğŸ’¡ åˆ†æå»ºè­°")
        report.append("-" * 40)
        for recommendation in posterior_report.recommendations:
            report.append(recommendation)
        
        return "\n".join(report)