#!/usr/bin/env python3
"""
Dual-GPU MCMC Setup for Your System
ç‚ºä½ çš„é›™GPUç³»çµ±å®šåˆ¶çš„MCMCé…ç½®

This script provides optimized configurations for dual-GPU MCMC sampling.
Deploy this on your GPU-enabled system for 3-4x speedup.
"""

import os
import warnings
from typing import Dict, Any

class DualGPU_MCMC_Optimizer:
    """
    é›™GPU MCMCå„ªåŒ–å™¨
    Dual-GPU MCMC Optimizer for maximum performance
    """
    
    def __init__(self):
        self.gpu_count = 2  # ä½ çš„ç³»çµ±æœ‰2å€‹GPU
        self.cpu_cores = 86  # ä½ çš„ç³»çµ±æœ‰86å€‹CPUæ ¸å¿ƒ
        self.setup_complete = False
        
    def configure_environment_variables(self):
        """
        é…ç½®ç’°å¢ƒè®Šé‡ä»¥å¯¦ç¾æœ€ä½³GPUæ€§èƒ½
        Configure environment variables for optimal GPU performance
        """
        
        print("ğŸ”¥ Step 1: Configuring Environment Variables...")
        
        # JAX GPUå„ªåŒ–
        env_vars = {
            # JAX GPUé…ç½®
            'JAX_PLATFORMS': 'cuda,cpu',
            'JAX_ENABLE_X64': 'True',
            'XLA_PYTHON_CLIENT_PREALLOCATE': 'false',
            'XLA_PYTHON_CLIENT_MEM_FRACTION': '0.8',
            'XLA_PYTHON_CLIENT_ALLOCATOR': 'platform',
            
            # CUDAå„ªåŒ–
            'CUDA_VISIBLE_DEVICES': '0,1',  # ä½¿ç”¨å…©å€‹GPU
            'CUDA_DEVICE_ORDER': 'PCI_BUS_ID',
            
            # PyTensor é…ç½® (ç§»é™¤å·²æ£„ç”¨çš„ CUDA å¾Œç«¯ï¼Œä½¿ç”¨ JAX æ›¿ä»£)
            # 'PYTENSOR_FLAGS': 'device=cuda,floatX=float32,optimizer=fast_run,allow_gc=True',  # èˆŠç‰ˆæœ¬å·²ç§»é™¤
            'JAX_PLATFORM_NAME': 'gpu',  # JAX ä½¿ç”¨ GPU
            
            # ç·šç¨‹æ§åˆ¶ (é‡è¦ï¼šé¿å…éåº¦ä¸¦è¡Œ)
            'OMP_NUM_THREADS': '8',    # é™åˆ¶OpenMPç·šç¨‹
            'MKL_NUM_THREADS': '8',    # é™åˆ¶MKLç·šç¨‹
            'OPENBLAS_NUM_THREADS': '8',
            'NUMBA_NUM_THREADS': '8',
            
            # PyMCç‰¹å®šå„ªåŒ–
            'PYMC_COMPUTE_TEST_VALUE': 'ignore',
            'PYTENSOR_OPTIMIZER_VERBOSE': '0',
        }
        
        for key, value in env_vars.items():
            os.environ[key] = value
            print(f"   âœ… {key} = {value}")
        
        print("   ğŸ¯ Environment configured for dual-GPU operation")
    
    def create_dual_gpu_mcmc_config(self) -> Dict[str, Any]:
        """
        å‰µå»ºé›™GPUå„ªåŒ–çš„MCMCé…ç½®
        Create dual-GPU optimized MCMC configuration
        """
        
        print("\nâš¡ Step 2: Creating Dual-GPU MCMC Configuration...")
        
        # é›™GPUæœ€ä½³é…ç½®
        config = {
            # æ ¸å¿ƒMCMCåƒæ•¸ - é‡å°é›™GPUå„ªåŒ–
            "draws": 4000,           # å¤§å¹…å¢åŠ æ¨£æœ¬æ•¸ (GPUèƒ½è™•ç†)
            "tune": 2000,            # å……åˆ†çš„é ç†±éšæ®µ
            "chains": 16,            # å¤§å¹…å¢åŠ éˆæ•¸ (åˆ©ç”¨86æ ¸å¿ƒ + é›™GPU)
            "cores": 32,             # ä½¿ç”¨æ›´å¤šæ ¸å¿ƒ (86æ ¸å¿ƒçš„37%)
            "target_accept": 0.95,   # é«˜æ¥å—ç‡æ¸›å°‘ç™¼æ•£
            
            # GPUä¸¦è¡Œç­–ç•¥
            "chain_method": "parallel",
            "chains_per_gpu": 8,     # æ¯å€‹GPUé‹è¡Œ8æ¢éˆ
            "gpu_memory_per_chain": 0.1,  # æ¯æ¢éˆåˆ†é…10% GPUè¨˜æ†¶é«”
            
            # JAX/NumPyroå„ªåŒ–
            "nuts_sampler": "numpyro",  # ä½¿ç”¨NumPyroçš„NUTS (GPUå„ªåŒ–)
            "progress_bar": True,
            "compute_convergence_checks": True,
            "return_inferencedata": True,
            "idata_kwargs": {
                "log_likelihood": True,
                "predictions": True,
            },
            
            # é€²éšå„ªåŒ–é¸é …
            "step_size_adaptation": True,
            "mass_matrix_adaptation": True,
            "dense_mass": False,     # ä½¿ç”¨å°è§’è³ªé‡çŸ©é™£ (æ›´å¿«)
            
            # éŒ¯èª¤è™•ç†
            "max_treedepth": 12,     # å¢åŠ æ¨¹æ·±åº¦é™åˆ¶
            "init": "advi+adapt_diag",  # æ›´å¥½çš„åˆå§‹åŒ–
        }
        
        # è¨ˆç®—é æœŸæ€§èƒ½
        baseline_time = 3600  # å‡è¨­CPUåŸºç·šç‚º1å°æ™‚
        expected_time = baseline_time / 4  # 4xåŠ é€Ÿ
        
        config["performance_metrics"] = {
            "expected_speedup": "4x",
            "baseline_time_estimate": f"{baseline_time/60:.0f} minutes",
            "optimized_time_estimate": f"{expected_time/60:.0f} minutes",
            "gpu_utilization_target": "80%",
            "memory_efficiency": "Dual-GPU load balancing"
        }
        
        print("   ğŸ“Š Configuration Summary:")
        print(f"      â€¢ Total samples: {config['draws'] * config['chains']:,}")
        print(f"      â€¢ Chains: {config['chains']} (8 per GPU)")
        print(f"      â€¢ CPU cores: {config['cores']}")
        print(f"      â€¢ Expected speedup: {config['performance_metrics']['expected_speedup']}")
        print(f"      â€¢ Estimated time: {config['performance_metrics']['optimized_time_estimate']}")
        
        return config
    
    def generate_deployment_code(self, config: Dict[str, Any]) -> str:
        """
        ç”Ÿæˆéƒ¨ç½²ä»£ç¢¼
        Generate deployment code for your analysis
        """
        
        print("\nğŸš€ Step 3: Generating Deployment Code...")
        
        code = f'''
# Dual-GPU PyMC Configuration for Your System
# é›™GPU PyMCé…ç½®

import os
import pymc as pm
import numpy as np

# Environment setup (run this first)
def setup_dual_gpu_environment():
    """Setup environment for dual-GPU MCMC"""
    env_vars = {
        'JAX_PLATFORMS': 'cuda,cpu',
        'CUDA_VISIBLE_DEVICES': '0,1',
        'JAX_PLATFORM_NAME': 'gpu',
        # 'PYTENSOR_FLAGS': 'device=cuda,floatX=float32,optimizer=fast_run',  # èˆŠç‰ˆæœ¬å·²ç§»é™¤
        'OMP_NUM_THREADS': '8',
        'MKL_NUM_THREADS': '8',
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
    
    print("âœ… Dual-GPU environment configured")

# Optimized sampler configuration
DUAL_GPU_SAMPLER_KWARGS = {{
    "draws": {config['draws']},
    "tune": {config['tune']},
    "chains": {config['chains']},
    "cores": {config['cores']},
    "target_accept": {config['target_accept']},
    "nuts_sampler": "{config['nuts_sampler']}",
    "chain_method": "{config['chain_method']}",
    "progress_bar": {config['progress_bar']},
    "compute_convergence_checks": {config['compute_convergence_checks']},
    "return_inferencedata": {config['return_inferencedata']},
    "max_treedepth": {config['max_treedepth']},
    "init": "{config['init']}",
}}

# Usage example
def run_optimized_mcmc(model):
    """
    Run MCMC with dual-GPU optimization
    ä½¿ç”¨é›™GPUå„ªåŒ–é‹è¡ŒMCMC
    """
    
    setup_dual_gpu_environment()
    
    print("ğŸš€ Starting dual-GPU MCMC sampling...")
    print(f"   ğŸ“Š Configuration: {{DUAL_GPU_SAMPLER_KWARGS['chains']}} chains, {{DUAL_GPU_SAMPLER_KWARGS['draws']}} samples each")
    print(f"   âš¡ Expected speedup: 4x over CPU")
    
    with model:
        trace = pm.sample(**DUAL_GPU_SAMPLER_KWARGS)
    
    return trace

# Integration with your robust Bayesian analysis
def integrate_with_bayesian_analysis():
    """
    Integration example for your 05_robust_bayesian_parm_insurance.py
    """
    
    # Replace your current MCMC config with:
    mcmc_config = MCMCConfig(
        n_samples={config['draws']},
        n_warmup={config['tune']},
        n_chains={config['chains']},
        cores={config['cores']},
        target_accept={config['target_accept']},
        backend='jax'  # Use JAX backend for GPU
    )
    
    # Use in your hierarchical model
    hierarchical_model = ParametricHierarchicalModel(model_spec, mcmc_config)
    
    return hierarchical_model
        '''
        
        return code
    
    def create_performance_monitoring(self) -> str:
        """
        å‰µå»ºæ€§èƒ½ç›£æ§ä»£ç¢¼
        Create performance monitoring code
        """
        
        monitoring_code = '''
# GPU Performance Monitoring
# GPUæ€§èƒ½ç›£æ§

import time
import psutil
import GPUtil  # pip install gputil
from contextlib import contextmanager

@contextmanager
def monitor_gpu_performance():
    """Monitor GPU and CPU usage during MCMC sampling"""
    
    print("ğŸ“Š Starting performance monitoring...")
    
    start_time = time.time()
    start_cpu = psutil.cpu_percent()
    
    try:
        # Monitor GPU usage
        gpus = GPUtil.getGPUs()
        if len(gpus) >= 2:
            print(f"   ğŸ¯ GPU 0: {gpus[0].memoryUtil*100:.1f}% memory, {gpus[0].load*100:.1f}% load")
            print(f"   ğŸ¯ GPU 1: {gpus[1].memoryUtil*100:.1f}% memory, {gpus[1].load*100:.1f}% load")
        
        yield
        
    finally:
        end_time = time.time()
        end_cpu = psutil.cpu_percent()
        
        duration = end_time - start_time
        
        print(f"\\nğŸ“ˆ Performance Summary:")
        print(f"   â±ï¸ Total time: {duration/60:.1f} minutes")
        print(f"   ğŸ’» CPU usage: {end_cpu:.1f}%")
        
        gpus = GPUtil.getGPUs()
        if len(gpus) >= 2:
            print(f"   ğŸ¯ Final GPU 0: {gpus[0].memoryUtil*100:.1f}% memory")
            print(f"   ğŸ¯ Final GPU 1: {gpus[1].memoryUtil*100:.1f}% memory")

# Usage example:
# with monitor_gpu_performance():
#     trace = pm.sample(**DUAL_GPU_SAMPLER_KWARGS)
        '''
        
        return monitoring_code
    
    def generate_installation_guide(self) -> str:
        """
        ç”Ÿæˆå®‰è£æŒ‡å—
        Generate installation guide for GPU dependencies
        """
        
        guide = '''
# Installation Guide for Dual-GPU MCMC
# é›™GPU MCMCå®‰è£æŒ‡å—

## 1. CUDA Setup (if not already installed)
```bash
# Check CUDA version
nvidia-smi

# Install CUDA toolkit (if needed)
# Follow NVIDIA CUDA installation guide for your system
```

## 2. JAX GPU Installation
```bash
# Install JAX with CUDA support
pip install --upgrade "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# Or for CUDA 11:
pip install --upgrade "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
```

## 3. PyMC with JAX Backend
```bash
# Install NumPyro (JAX-based MCMC)
pip install numpyro

# Install GPU utilities for monitoring
pip install gputil
```

## 4. Verification
```python
import jax
print("JAX devices:", jax.devices())
# Should show: [cuda(id=0), cuda(id=1), cpu(id=0)]

import numpyro
print("NumPyro version:", numpyro.__version__)
```

## 5. Environment Setup
Add to your ~/.bashrc or run before analysis:
```bash
export JAX_PLATFORMS=cuda,cpu
export CUDA_VISIBLE_DEVICES=0,1
```
        '''
        
        return guide

def main():
    """
    ä¸»è¦è¨­ç½®æµç¨‹
    Main setup workflow
    """
    
    print("ğŸ¯ Dual-GPU MCMC Optimization Setup")
    print("ç‚ºä½ çš„é›™GPUç³»çµ±å„ªåŒ–MCMCæ¡æ¨£")
    print("=" * 60)
    
    optimizer = DualGPU_MCMC_Optimizer()
    
    # Step 1: Configure environment
    optimizer.configure_environment_variables()
    
    # Step 2: Create optimized config
    config = optimizer.create_dual_gpu_mcmc_config()
    
    # Step 3: Generate deployment code
    deployment_code = optimizer.generate_deployment_code(config)
    
    # Step 4: Generate monitoring code
    monitoring_code = optimizer.create_performance_monitoring()
    
    # Step 5: Generate installation guide
    install_guide = optimizer.generate_installation_guide()
    
    # Save all generated code
    with open('dual_gpu_deployment.py', 'w') as f:
        f.write(deployment_code)
    
    with open('gpu_performance_monitor.py', 'w') as f:
        f.write(monitoring_code)
        
    with open('GPU_INSTALLATION_GUIDE.md', 'w') as f:
        f.write(install_guide)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ Dual-GPU MCMC Setup Complete!")
    print("=" * 60)
    print("ğŸ“‚ Generated Files:")
    print("   â€¢ dual_gpu_deployment.py - éƒ¨ç½²ä»£ç¢¼")
    print("   â€¢ gpu_performance_monitor.py - æ€§èƒ½ç›£æ§")
    print("   â€¢ GPU_INSTALLATION_GUIDE.md - å®‰è£æŒ‡å—")
    print("")
    print("ğŸš€ Next Steps:")
    print("1. Install GPU dependencies (see GPU_INSTALLATION_GUIDE.md)")
    print("2. Run dual_gpu_deployment.py on your GPU system")
    print("3. Replace MCMC configs in your Bayesian analysis")
    print("4. Monitor performance with gpu_performance_monitor.py")
    print("")
    print("ğŸ“ˆ Expected Performance:")
    print(f"   â€¢ Speedup: 4x faster than CPU-only")
    print(f"   â€¢ Chains: 16 parallel (8 per GPU)")
    print(f"   â€¢ Total samples: {config['draws'] * config['chains']:,}")
    print(f"   â€¢ Memory usage: 80% of dual-GPU capacity")

if __name__ == "__main__":
    main()