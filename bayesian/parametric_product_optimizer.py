#!/usr/bin/env python3
"""
Bayesian Decision Theory Module
è²æ°æ±ºç­–ç†è«–æ¨¡çµ„

å¯¦ç¾æ‚¨ç†è«–æ¡†æ¶ä¸­çš„æ±ºç­–ç†è«–æ ¸å¿ƒï¼š
- å¾Œé©—æœŸæœ›é¢¨éšªæœ€å°åŒ–: a* = argmin_a R(a|Data)
- Î“-æ¥µå°åŒ–æ¥µå¤§æ±ºç­–: a*_minimax = argmin_a (sup_Ï€ R(a|Ï€,Data))
- å®Œæ•´çš„æ±ºç­–ç†è«–æ¡†æ¶

æ ¸å¿ƒåŠŸèƒ½:
- å¾Œé©—æœŸæœ›é¢¨éšªè¨ˆç®—
- ç”¢å“åƒæ•¸å„ªåŒ–
- Î“-minimaxç©©å¥æ±ºç­–
- æ±ºç­–ä¸ç¢ºå®šæ€§é‡åŒ–

ä½¿ç”¨ç¯„ä¾‹:
```python
from bayesian.parametric_product_optimizer import (
    BayesianDecisionOptimizer, ProductSpace, DecisionResult
)

# å®šç¾©ç”¢å“ç©ºé–“
product_space = ProductSpace(
    trigger_bounds=(30, 60),
    payout_bounds=(1e7, 1e9)
)

# åˆå§‹åŒ–å„ªåŒ–å™¨
optimizer = BayesianDecisionOptimizer()

# åŸ·è¡Œè²æ°æœ€å„ªæ±ºç­–
result = optimizer.optimize_expected_risk(
    posterior_samples_dict,
    hazard_indices, 
    actual_losses,
    product_space
)

print(f"æœ€å„ªç”¢å“: {result.optimal_product}")
print(f"æœŸæœ›é¢¨éšª: {result.expected_risk:.2e}")

# åŸ·è¡ŒÎ“-minimaxæ±ºç­–
minimax_result = optimizer.gamma_minimax_optimization(
    posterior_samples_dict,
    hazard_indices,
    actual_losses, 
    product_space
)
```

Author: Research Team
Date: 2025-01-12
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
from scipy.optimize import minimize, differential_evolution
import warnings
import time

# å°å…¥åŸºå·®é¢¨éšªè¨ˆç®—
try:
    import sys, os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from skill_scores.basis_risk_functions import (
        BasisRiskCalculator, BasisRiskType, BasisRiskLossFunction
    )
    HAS_BASIS_RISK = True
except ImportError:
    HAS_BASIS_RISK = False
    warnings.warn("basis_risk_functions not available")

@dataclass
class ProductParameters:
    """ç”¢å“åƒæ•¸"""
    trigger_threshold: float
    payout_amount: float
    max_payout: Optional[float] = None
    product_type: str = "single_threshold"
    additional_params: Dict[str, Any] = field(default_factory=dict)
    
    def __post_init__(self):
        if self.max_payout is None:
            self.max_payout = self.payout_amount
    
    def calculate_payout(self, hazard_value: float) -> float:
        """è¨ˆç®—çµ¦å®šç½å®³å€¼çš„è³ ä»˜é‡‘é¡"""
        if hazard_value >= self.trigger_threshold:
            return min(self.payout_amount, self.max_payout)
        return 0.0

@dataclass
class ProductSpace:
    """ç”¢å“åƒæ•¸ç©ºé–“"""
    trigger_bounds: Tuple[float, float]
    payout_bounds: Tuple[float, float]
    max_payout_bounds: Optional[Tuple[float, float]] = None
    grid_resolution: Tuple[int, int] = (20, 20)
    
    def __post_init__(self):
        if self.max_payout_bounds is None:
            self.max_payout_bounds = self.payout_bounds
    
    def sample_random_product(self) -> ProductParameters:
        """éš¨æ©Ÿæ¡æ¨£ä¸€å€‹ç”¢å“"""
        trigger = np.random.uniform(*self.trigger_bounds)
        payout = np.random.uniform(*self.payout_bounds)
        max_payout = np.random.uniform(*self.max_payout_bounds)
        
        return ProductParameters(
            trigger_threshold=trigger,
            payout_amount=payout,
            max_payout=max_payout
        )
    
    def generate_grid_products(self) -> List[ProductParameters]:
        """ç”Ÿæˆç¶²æ ¼åŒ–çš„ç”¢å“çµ„åˆ"""
        trigger_grid = np.linspace(*self.trigger_bounds, self.grid_resolution[0])
        payout_grid = np.linspace(*self.payout_bounds, self.grid_resolution[1])
        
        products = []
        for trigger in trigger_grid:
            for payout in payout_grid:
                products.append(ProductParameters(
                    trigger_threshold=trigger,
                    payout_amount=payout
                ))
        
        return products

@dataclass
class DecisionResult:
    """æ±ºç­–çµæœ"""
    optimal_product: ProductParameters
    expected_risk: float
    optimization_method: str
    convergence_info: Dict[str, Any] = field(default_factory=dict)
    risk_breakdown: Dict[str, float] = field(default_factory=dict)
    optimization_history: List[Dict[str, Any]] = field(default_factory=list)
    execution_time: float = 0.0

@dataclass
class GammaMinimaxResult:
    """Î“-minimaxæ±ºç­–çµæœ"""
    minimax_product: ProductParameters
    worst_case_risk: float
    risk_across_models: Dict[str, float] = field(default_factory=dict)
    robustness_metrics: Dict[str, Any] = field(default_factory=dict)
    execution_time: float = 0.0

class OptimizationMethod(Enum):
    """å„ªåŒ–æ–¹æ³•"""
    GRID_SEARCH = "grid_search"
    GRADIENT_BASED = "gradient_based"
    EVOLUTIONARY = "evolutionary"
    BAYESIAN_OPTIMIZATION = "bayesian_optimization"

@dataclass
class OptimizerConfig:
    """å„ªåŒ–å™¨é…ç½®"""
    method: OptimizationMethod = OptimizationMethod.GRID_SEARCH
    basis_risk_type: BasisRiskType = BasisRiskType.WEIGHTED_ASYMMETRIC
    w_under: float = 2.0  # è³ ä¸å¤ çš„æ‡²ç½°æ¬Šé‡
    w_over: float = 0.5   # è³ å¤šäº†çš„æ‡²ç½°æ¬Šé‡
    max_iterations: int = 1000
    tolerance: float = 1e-6
    n_random_starts: int = 10
    use_parallel: bool = False

class BayesianDecisionOptimizer:
    """
    è²æ°æ±ºç­–ç†è«–å„ªåŒ–å™¨
    
    å¯¦ç¾æ‚¨ç†è«–æ¡†æ¶ä¸­çš„æ±ºç­–ç†è«–æ ¸å¿ƒï¼š
    1. å¾Œé©—æœŸæœ›é¢¨éšª: R(a|Data) = E_p(L|Data)[L(L, a)]
    2. è²æ°æœ€å„ªæ±ºç­–: a* = argmin_a R(a|Data)
    3. Î“-æ¥µå°åŒ–æ¥µå¤§: a*_minimax = argmin_a (sup_Ï€ R(a|Ï€,Data))
    """
    
    def __init__(self, config: Optional[OptimizerConfig] = None):
        """
        åˆå§‹åŒ–è²æ°æ±ºç­–å„ªåŒ–å™¨
        
        Parameters:
        -----------
        config : OptimizerConfig, optional
            å„ªåŒ–å™¨é…ç½®
        """
        self.config = config or OptimizerConfig()
        
        # åˆå§‹åŒ–åŸºå·®é¢¨éšªè¨ˆç®—å™¨
        if HAS_BASIS_RISK:
            self.basis_risk_calculator = BasisRiskCalculator()
            self.loss_function = BasisRiskLossFunction(
                risk_type=self.config.basis_risk_type,
                w_under=self.config.w_under,
                w_over=self.config.w_over
            )
        else:
            self.basis_risk_calculator = None
            self.loss_function = None
            warnings.warn("åŸºå·®é¢¨éšªè¨ˆç®—ä¸å¯ç”¨ï¼Œä½¿ç”¨ç°¡åŒ–æå¤±å‡½æ•¸")
        
        # çµæœå­˜å„²
        self.optimization_history: List[DecisionResult] = []
        self.minimax_history: List[GammaMinimaxResult] = []
        
        print("ğŸ¯ è²æ°æ±ºç­–ç†è«–å„ªåŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   å„ªåŒ–æ–¹æ³•: {self.config.method.value}")
        print(f"   åŸºå·®é¢¨éšªé¡å‹: {self.config.basis_risk_type.value}")
        print(f"   æ‡²ç½°æ¬Šé‡: w_under={self.config.w_under}, w_over={self.config.w_over}")
    
    def compute_posterior_expected_risk(self,
                                      product: ProductParameters,
                                      posterior_samples_dict: Dict[str, np.ndarray],
                                      hazard_indices: np.ndarray,
                                      actual_losses: np.ndarray) -> float:
        """
        è¨ˆç®—å¾Œé©—æœŸæœ›é¢¨éšª
        
        å¯¦ç¾æ‚¨ç†è«–ä¸­çš„æ ¸å¿ƒå…¬å¼ï¼š
        R(a|Data) = E_p(L_pred|Data)[L(L_pred, a)]
        
        Parameters:
        -----------
        product : ProductParameters
            ç”¢å“åƒæ•¸
        posterior_samples_dict : Dict[str, np.ndarray]
            å¾Œé©—æ¨£æœ¬å­—å…¸
        hazard_indices : np.ndarray
            ç½å®³æŒ‡æ¨™
        actual_losses : np.ndarray
            å¯¦éš›æå¤±
            
        Returns:
        --------
        float
            å¾Œé©—æœŸæœ›é¢¨éšª
        """
        total_risk = 0.0
        n_models = len(posterior_samples_dict)
        
        if n_models == 0:
            return float('inf')
        
        # å°æ¯å€‹æ¨¡å‹è¨ˆç®—æœŸæœ›é¢¨éšªï¼Œç„¶å¾Œå¹³å‡
        for model_name, samples in posterior_samples_dict.items():
            model_risk = self._compute_single_model_risk(
                product, samples, hazard_indices, actual_losses
            )
            total_risk += model_risk
        
        return total_risk / n_models
    
    def _compute_single_model_risk(self,
                                 product: ProductParameters,
                                 posterior_samples: Union[np.ndarray, Dict[str, np.ndarray]],
                                 hazard_indices: np.ndarray,
                                 actual_losses: np.ndarray) -> float:
        """è¨ˆç®—å–®ä¸€æ¨¡å‹çš„æœŸæœ›é¢¨éšª"""
        if isinstance(posterior_samples, dict):
            # ä½¿ç”¨å­—å…¸ä¸­çš„åƒæ•¸æ¨£æœ¬
            n_samples = len(next(iter(posterior_samples.values())))
            sample_indices = np.random.choice(n_samples, size=min(n_samples, 100), replace=False)
        else:
            # å¦‚æœæ˜¯æ•¸çµ„ï¼Œç›´æ¥ä½¿ç”¨
            n_samples = len(posterior_samples)
            sample_indices = np.random.choice(n_samples, size=min(n_samples, 100), replace=False)
        
        total_sample_risk = 0.0
        
        # å°é¸ä¸­çš„æ¨£æœ¬è¨ˆç®—å¹³å‡é¢¨éšª
        for sample_idx in sample_indices:
            sample_risk = 0.0
            n_events = min(len(hazard_indices), len(actual_losses))
            
            # å°æ¯å€‹äº‹ä»¶è¨ˆç®—åŸºå·®é¢¨éšª
            for event_idx in range(n_events):
                hazard_value = hazard_indices[event_idx]
                actual_loss = actual_losses[event_idx]
                
                # è¨ˆç®—ç”¢å“è³ ä»˜
                payout = product.calculate_payout(hazard_value)
                
                # è¨ˆç®—åŸºå·®é¢¨éšª
                if self.loss_function:
                    basis_risk = self.loss_function.calculate_loss(actual_loss, payout)
                else:
                    # ç°¡åŒ–çš„åŸºå·®é¢¨éšªè¨ˆç®—
                    under_coverage = max(0, actual_loss - payout)
                    over_coverage = max(0, payout - actual_loss)
                    basis_risk = (self.config.w_under * under_coverage + 
                                self.config.w_over * over_coverage)
                
                sample_risk += basis_risk
            
            # å¹³å‡æ¯å€‹äº‹ä»¶çš„é¢¨éšª
            total_sample_risk += sample_risk / n_events if n_events > 0 else 0
        
        # å¹³å‡æ‰€æœ‰æ¨£æœ¬çš„é¢¨éšª
        return total_sample_risk / len(sample_indices) if len(sample_indices) > 0 else float('inf')
    
    def optimize_expected_risk(self,
                             posterior_samples_dict: Dict[str, np.ndarray],
                             hazard_indices: np.ndarray,
                             actual_losses: np.ndarray,
                             product_space: ProductSpace) -> DecisionResult:
        """
        å„ªåŒ–å¾Œé©—æœŸæœ›é¢¨éšª
        
        å¯¦ç¾è²æ°æœ€å„ªæ±ºç­–ï¼ša* = argmin_a R(a|Data)
        
        Parameters:
        -----------
        posterior_samples_dict : Dict[str, np.ndarray]
            å¾Œé©—æ¨£æœ¬å­—å…¸
        hazard_indices : np.ndarray
            ç½å®³æŒ‡æ¨™
        actual_losses : np.ndarray
            å¯¦éš›æå¤±
        product_space : ProductSpace
            ç”¢å“åƒæ•¸ç©ºé–“
            
        Returns:
        --------
        DecisionResult
            æ±ºç­–çµæœ
        """
        print(f"ğŸ¯ åŸ·è¡Œè²æ°æœ€å„ªæ±ºç­–å„ªåŒ–...")
        print(f"   æ¨¡å‹æ•¸é‡: {len(posterior_samples_dict)}")
        print(f"   äº‹ä»¶æ•¸é‡: {len(hazard_indices)}")
        print(f"   å„ªåŒ–æ–¹æ³•: {self.config.method.value}")
        
        start_time = time.time()
        
        # å®šç¾©ç›®æ¨™å‡½æ•¸
        def objective_function(params):
            trigger_threshold, payout_amount = params
            
            product = ProductParameters(
                trigger_threshold=trigger_threshold,
                payout_amount=payout_amount
            )
            
            return self.compute_posterior_expected_risk(
                product, posterior_samples_dict, hazard_indices, actual_losses
            )
        
        # æ ¹æ“šé…ç½®é¸æ“‡å„ªåŒ–æ–¹æ³•
        if self.config.method == OptimizationMethod.GRID_SEARCH:
            result = self._optimize_grid_search(objective_function, product_space)
        elif self.config.method == OptimizationMethod.GRADIENT_BASED:
            result = self._optimize_gradient_based(objective_function, product_space)
        elif self.config.method == OptimizationMethod.EVOLUTIONARY:
            result = self._optimize_evolutionary(objective_function, product_space)
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„å„ªåŒ–æ–¹æ³•: {self.config.method}")
        
        execution_time = time.time() - start_time
        
        # å‰µå»ºæ±ºç­–çµæœ
        decision_result = DecisionResult(
            optimal_product=result["product"],
            expected_risk=result["risk"],
            optimization_method=self.config.method.value,
            convergence_info=result["convergence"],
            execution_time=execution_time
        )
        
        self.optimization_history.append(decision_result)
        
        print(f"âœ… è²æ°æœ€å„ªæ±ºç­–å®Œæˆ")
        print(f"   æœ€å„ªè§¸ç™¼é–¾å€¼: {result['product'].trigger_threshold:.2f}")
        print(f"   æœ€å„ªè³ ä»˜é‡‘é¡: {result['product'].payout_amount:.2e}")
        print(f"   æœ€å°æœŸæœ›é¢¨éšª: {result['risk']:.2e}")
        print(f"   åŸ·è¡Œæ™‚é–“: {execution_time:.2f} ç§’")
        
        return decision_result
    
    def _optimize_grid_search(self, objective_func: Callable, product_space: ProductSpace) -> Dict[str, Any]:
        """ç¶²æ ¼æœç´¢å„ªåŒ–"""
        print("   ğŸ” åŸ·è¡Œç¶²æ ¼æœç´¢...")
        
        trigger_grid = np.linspace(*product_space.trigger_bounds, product_space.grid_resolution[0])
        payout_grid = np.linspace(*product_space.payout_bounds, product_space.grid_resolution[1])
        
        best_risk = float('inf')
        best_params = None
        history = []
        
        total_evaluations = len(trigger_grid) * len(payout_grid)
        evaluation_count = 0
        
        for trigger in trigger_grid:
            for payout in payout_grid:
                try:
                    risk = objective_func([trigger, payout])
                    
                    history.append({
                        "trigger": trigger,
                        "payout": payout,
                        "risk": risk
                    })
                    
                    if risk < best_risk:
                        best_risk = risk
                        best_params = (trigger, payout)
                    
                    evaluation_count += 1
                    if evaluation_count % 50 == 0:
                        print(f"      é€²åº¦: {evaluation_count}/{total_evaluations}")
                        
                except Exception as e:
                    continue
        
        if best_params is None:
            raise ValueError("ç¶²æ ¼æœç´¢æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
        
        best_product = ProductParameters(
            trigger_threshold=best_params[0],
            payout_amount=best_params[1]
        )
        
        return {
            "product": best_product,
            "risk": best_risk,
            "convergence": {
                "method": "grid_search",
                "evaluations": evaluation_count,
                "history": history
            }
        }
    
    def _optimize_gradient_based(self, objective_func: Callable, product_space: ProductSpace) -> Dict[str, Any]:
        """åŸºæ–¼æ¢¯åº¦çš„å„ªåŒ–"""
        print("   ğŸ“ˆ åŸ·è¡ŒåŸºæ–¼æ¢¯åº¦çš„å„ªåŒ–...")
        
        # å¤šå€‹éš¨æ©Ÿèµ·å§‹é»
        best_risk = float('inf')
        best_result = None
        
        for start_idx in range(self.config.n_random_starts):
            # éš¨æ©Ÿåˆå§‹é»
            initial_trigger = np.random.uniform(*product_space.trigger_bounds)
            initial_payout = np.random.uniform(*product_space.payout_bounds)
            initial_guess = [initial_trigger, initial_payout]
            
            # é‚Šç•Œç´„æŸ
            bounds = [product_space.trigger_bounds, product_space.payout_bounds]
            
            try:
                opt_result = minimize(
                    objective_func,
                    initial_guess,
                    method='L-BFGS-B',
                    bounds=bounds,
                    options={
                        'ftol': self.config.tolerance,
                        'maxiter': self.config.max_iterations
                    }
                )
                
                if opt_result.success and opt_result.fun < best_risk:
                    best_risk = opt_result.fun
                    best_result = opt_result
                    
            except Exception as e:
                print(f"      èµ·å§‹é» {start_idx+1} å„ªåŒ–å¤±æ•—: {e}")
                continue
        
        if best_result is None:
            raise ValueError("æ¢¯åº¦å„ªåŒ–æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
        
        best_product = ProductParameters(
            trigger_threshold=best_result.x[0],
            payout_amount=best_result.x[1]
        )
        
        return {
            "product": best_product,
            "risk": best_result.fun,
            "convergence": {
                "method": "gradient_based",
                "success": best_result.success,
                "n_iterations": best_result.nit,
                "n_function_evaluations": best_result.nfev
            }
        }
    
    def _optimize_evolutionary(self, objective_func: Callable, product_space: ProductSpace) -> Dict[str, Any]:
        """é€²åŒ–ç®—æ³•å„ªåŒ–"""
        print("   ğŸ§¬ åŸ·è¡Œé€²åŒ–ç®—æ³•å„ªåŒ–...")
        
        bounds = [product_space.trigger_bounds, product_space.payout_bounds]
        
        result = differential_evolution(
            objective_func,
            bounds,
            maxiter=self.config.max_iterations // 10,  # èª¿æ•´è¿­ä»£æ¬¡æ•¸
            popsize=15,
            seed=42,
            atol=self.config.tolerance,
            polish=True
        )
        
        if not result.success:
            raise ValueError(f"é€²åŒ–ç®—æ³•å„ªåŒ–å¤±æ•—: {result.message}")
        
        best_product = ProductParameters(
            trigger_threshold=result.x[0],
            payout_amount=result.x[1]
        )
        
        return {
            "product": best_product,
            "risk": result.fun,
            "convergence": {
                "method": "evolutionary",
                "success": result.success,
                "n_iterations": result.nit,
                "n_function_evaluations": result.nfev
            }
        }
    
    def gamma_minimax_optimization(self,
                                 posterior_samples_dict: Dict[str, np.ndarray],
                                 hazard_indices: np.ndarray,
                                 actual_losses: np.ndarray,
                                 product_space: ProductSpace) -> GammaMinimaxResult:
        """
        Î“-æ¥µå°åŒ–æ¥µå¤§å„ªåŒ–
        
        å¯¦ç¾æ‚¨ç†è«–ä¸­çš„ç©©å¥æ±ºç­–ï¼š
        a*_minimax = argmin_a (sup_Ï€ R(a|Ï€, Data))
        
        Parameters:
        -----------
        posterior_samples_dict : Dict[str, np.ndarray]
            æ¯å€‹æ¨¡å‹çš„å¾Œé©—æ¨£æœ¬
        hazard_indices : np.ndarray
            ç½å®³æŒ‡æ¨™
        actual_losses : np.ndarray
            å¯¦éš›æå¤±
        product_space : ProductSpace
            ç”¢å“åƒæ•¸ç©ºé–“
            
        Returns:
        --------
        GammaMinimaxResult
            Î“-minimaxæ±ºç­–çµæœ
        """
        print(f"ğŸ›¡ï¸ åŸ·è¡Œ Î“-æ¥µå°åŒ–æ¥µå¤§å„ªåŒ–...")
        print(f"   æ¨¡å‹æ•¸é‡: {len(posterior_samples_dict)}")
        
        start_time = time.time()
        
        def compute_worst_case_risk(params):
            """è¨ˆç®—çµ¦å®šç”¢å“åƒæ•¸çš„æœ€å£æƒ…æ³é¢¨éšª"""
            trigger_threshold, payout_amount = params
            
            product = ProductParameters(
                trigger_threshold=trigger_threshold,
                payout_amount=payout_amount
            )
            
            # è¨ˆç®—æ¯å€‹æ¨¡å‹çš„é¢¨éšª
            model_risks = {}
            for model_name, samples in posterior_samples_dict.items():
                risk = self._compute_single_model_risk(
                    product, samples, hazard_indices, actual_losses
                )
                model_risks[model_name] = risk
            
            # è¿”å›æœ€å¤§é¢¨éšªï¼ˆworst caseï¼‰
            worst_case_risk = max(model_risks.values()) if model_risks else float('inf')
            return worst_case_risk, model_risks
        
        # å®šç¾© minimax ç›®æ¨™å‡½æ•¸
        def minimax_objective(params):
            worst_risk, _ = compute_worst_case_risk(params)
            return worst_risk
        
        # åŸ·è¡Œå„ªåŒ–
        if self.config.method == OptimizationMethod.GRID_SEARCH:
            result = self._minimax_grid_search(compute_worst_case_risk, product_space)
        else:
            # ä½¿ç”¨æ¢¯åº¦æ–¹æ³•
            bounds = [product_space.trigger_bounds, product_space.payout_bounds]
            
            best_minimax_risk = float('inf')
            best_result = None
            
            for start_idx in range(self.config.n_random_starts):
                initial_trigger = np.random.uniform(*product_space.trigger_bounds)
                initial_payout = np.random.uniform(*product_space.payout_bounds)
                initial_guess = [initial_trigger, initial_payout]
                
                try:
                    opt_result = minimize(
                        minimax_objective,
                        initial_guess,
                        method='L-BFGS-B',
                        bounds=bounds,
                        options={
                            'ftol': self.config.tolerance,
                            'maxiter': self.config.max_iterations
                        }
                    )
                    
                    if opt_result.success and opt_result.fun < best_minimax_risk:
                        best_minimax_risk = opt_result.fun
                        best_result = opt_result
                        
                except Exception as e:
                    continue
            
            if best_result is None:
                raise ValueError("Î“-minimax å„ªåŒ–æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
            
            # ç²å–è©³ç´°çµæœ
            worst_risk, model_risks = compute_worst_case_risk(best_result.x)
            
            result = {
                "product": ProductParameters(
                    trigger_threshold=best_result.x[0],
                    payout_amount=best_result.x[1]
                ),
                "worst_case_risk": worst_risk,
                "model_risks": model_risks
            }
        
        execution_time = time.time() - start_time
        
        # è¨ˆç®—ç©©å¥æ€§æŒ‡æ¨™
        risk_values = list(result["model_risks"].values())
        robustness_metrics = {
            "risk_range": (np.min(risk_values), np.max(risk_values)),
            "risk_std": np.std(risk_values),
            "risk_coefficient_variation": np.std(risk_values) / np.mean(risk_values) if np.mean(risk_values) > 0 else np.inf,
            "worst_to_best_ratio": np.max(risk_values) / np.min(risk_values) if np.min(risk_values) > 0 else np.inf
        }
        
        minimax_result = GammaMinimaxResult(
            minimax_product=result["product"],
            worst_case_risk=result["worst_case_risk"],
            risk_across_models=result["model_risks"],
            robustness_metrics=robustness_metrics,
            execution_time=execution_time
        )
        
        self.minimax_history.append(minimax_result)
        
        print(f"âœ… Î“-æ¥µå°åŒ–æ¥µå¤§å„ªåŒ–å®Œæˆ")
        print(f"   æœ€å„ªè§¸ç™¼é–¾å€¼: {result['product'].trigger_threshold:.2f}")
        print(f"   æœ€å„ªè³ ä»˜é‡‘é¡: {result['product'].payout_amount:.2e}")
        print(f"   æœ€å£æƒ…æ³é¢¨éšª: {result['worst_case_risk']:.2e}")
        print(f"   é¢¨éšªè®Šç•°ä¿‚æ•¸: {robustness_metrics['risk_coefficient_variation']:.3f}")
        print(f"   åŸ·è¡Œæ™‚é–“: {execution_time:.2f} ç§’")
        
        return minimax_result
    
    def _minimax_grid_search(self, risk_func: Callable, product_space: ProductSpace) -> Dict[str, Any]:
        """Minimaxç¶²æ ¼æœç´¢"""
        trigger_grid = np.linspace(*product_space.trigger_bounds, product_space.grid_resolution[0])
        payout_grid = np.linspace(*product_space.payout_bounds, product_space.grid_resolution[1])
        
        best_minimax_risk = float('inf')
        best_params = None
        best_model_risks = {}
        
        for trigger in trigger_grid:
            for payout in payout_grid:
                try:
                    worst_risk, model_risks = risk_func([trigger, payout])
                    
                    if worst_risk < best_minimax_risk:
                        best_minimax_risk = worst_risk
                        best_params = (trigger, payout)
                        best_model_risks = model_risks
                        
                except Exception as e:
                    continue
        
        if best_params is None:
            raise ValueError("Minimaxç¶²æ ¼æœç´¢æœªæ‰¾åˆ°æœ‰æ•ˆè§£")
        
        return {
            "product": ProductParameters(
                trigger_threshold=best_params[0],
                payout_amount=best_params[1]
            ),
            "worst_case_risk": best_minimax_risk,
            "model_risks": best_model_risks
        }
    
    def compare_decision_strategies(self,
                                  posterior_samples_dict: Dict[str, np.ndarray],
                                  hazard_indices: np.ndarray,
                                  actual_losses: np.ndarray,
                                  product_space: ProductSpace) -> Dict[str, Any]:
        """
        æ¯”è¼ƒä¸åŒæ±ºç­–ç­–ç•¥
        
        Parameters:
        -----------
        posterior_samples_dict : Dict[str, np.ndarray]
            å¾Œé©—æ¨£æœ¬å­—å…¸
        hazard_indices : np.ndarray
            ç½å®³æŒ‡æ¨™
        actual_losses : np.ndarray
            å¯¦éš›æå¤±
        product_space : ProductSpace
            ç”¢å“åƒæ•¸ç©ºé–“
            
        Returns:
        --------
        Dict[str, Any]
            æ±ºç­–ç­–ç•¥æ¯”è¼ƒçµæœ
        """
        print(f"ğŸ“Š æ¯”è¼ƒæ±ºç­–ç­–ç•¥...")
        
        # åŸ·è¡Œè²æ°æœ€å„ªæ±ºç­–
        print("\n1. åŸ·è¡Œè²æ°æœ€å„ªæ±ºç­–...")
        bayes_optimal = self.optimize_expected_risk(
            posterior_samples_dict, hazard_indices, actual_losses, product_space
        )
        
        # åŸ·è¡ŒÎ“-minimaxæ±ºç­–
        print("\n2. åŸ·è¡ŒÎ“-æ¥µå°åŒ–æ¥µå¤§æ±ºç­–...")
        gamma_minimax = self.gamma_minimax_optimization(
            posterior_samples_dict, hazard_indices, actual_losses, product_space
        )
        
        # è¨ˆç®—æ¯ç¨®ç­–ç•¥åœ¨æ‰€æœ‰æ¨¡å‹ä¸‹çš„é¢¨éšª
        bayes_risks = {}
        minimax_risks = {}
        
        for model_name, samples in posterior_samples_dict.items():
            # è²æ°æœ€å„ªåœ¨è©²æ¨¡å‹ä¸‹çš„é¢¨éšª
            bayes_risk = self._compute_single_model_risk(
                bayes_optimal.optimal_product, samples, hazard_indices, actual_losses
            )
            bayes_risks[model_name] = bayes_risk
            
            # Minimaxåœ¨è©²æ¨¡å‹ä¸‹çš„é¢¨éšª
            minimax_risk = self._compute_single_model_risk(
                gamma_minimax.minimax_product, samples, hazard_indices, actual_losses
            )
            minimax_risks[model_name] = minimax_risk
        
        # æ¯”è¼ƒåˆ†æ
        bayes_risks_values = list(bayes_risks.values())
        minimax_risks_values = list(minimax_risks.values())
        
        comparison = {
            "bayes_optimal": {
                "product": bayes_optimal.optimal_product,
                "expected_risk": bayes_optimal.expected_risk,
                "risks_by_model": bayes_risks,
                "worst_case_risk": np.max(bayes_risks_values),
                "risk_std": np.std(bayes_risks_values),
                "execution_time": bayes_optimal.execution_time
            },
            "gamma_minimax": {
                "product": gamma_minimax.minimax_product,
                "worst_case_risk": gamma_minimax.worst_case_risk,
                "risks_by_model": minimax_risks,
                "average_risk": np.mean(minimax_risks_values),
                "risk_std": np.std(minimax_risks_values),
                "execution_time": gamma_minimax.execution_time
            },
            "comparison_metrics": {
                "worst_case_improvement": (
                    np.max(bayes_risks_values) - gamma_minimax.worst_case_risk
                ) / np.max(bayes_risks_values) if np.max(bayes_risks_values) > 0 else 0,
                "average_risk_trade_off": (
                    np.mean(minimax_risks_values) - bayes_optimal.expected_risk
                ) / bayes_optimal.expected_risk if bayes_optimal.expected_risk > 0 else 0,
                "robustness_gain": (
                    np.std(bayes_risks_values) - np.std(minimax_risks_values)
                ) / np.std(bayes_risks_values) if np.std(bayes_risks_values) > 0 else 0
            }
        }
        
        print(f"\nğŸ“‹ æ±ºç­–ç­–ç•¥æ¯”è¼ƒçµæœ:")
        print(f"   è²æ°æœ€å„ªæœŸæœ›é¢¨éšª: {bayes_optimal.expected_risk:.2e}")
        print(f"   è²æ°æœ€å„ªæœ€å£é¢¨éšª: {np.max(bayes_risks_values):.2e}")
        print(f"   Minimaxæœ€å£é¢¨éšª: {gamma_minimax.worst_case_risk:.2e}")
        print(f"   æœ€å£æƒ…æ³æ”¹å–„: {comparison['comparison_metrics']['worst_case_improvement']:.1%}")
        
        return comparison
    
    def get_optimization_summary(self) -> pd.DataFrame:
        """ç²å–å„ªåŒ–æ­·å²æ‘˜è¦"""
        if not self.optimization_history:
            return pd.DataFrame()
        
        summary_data = []
        
        for i, result in enumerate(self.optimization_history):
            summary_data.append({
                "å„ªåŒ–åºè™Ÿ": i + 1,
                "æ–¹æ³•": result.optimization_method,
                "è§¸ç™¼é–¾å€¼": result.optimal_product.trigger_threshold,
                "è³ ä»˜é‡‘é¡": result.optimal_product.payout_amount,
                "æœŸæœ›é¢¨éšª": result.expected_risk,
                "åŸ·è¡Œæ™‚é–“": result.execution_time
            })
        
        return pd.DataFrame(summary_data)

# ä¾¿åˆ©å‡½æ•¸
def quick_bayesian_optimization(posterior_samples_dict: Dict[str, np.ndarray],
                               hazard_indices: np.ndarray,
                               actual_losses: np.ndarray,
                               trigger_bounds: Tuple[float, float] = (30, 60),
                               payout_bounds: Tuple[float, float] = (1e7, 1e9)) -> DecisionResult:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå¿«é€Ÿè²æ°å„ªåŒ–
    
    Parameters:
    -----------
    posterior_samples_dict : Dict[str, np.ndarray]
        å¾Œé©—æ¨£æœ¬å­—å…¸
    hazard_indices : np.ndarray
        ç½å®³æŒ‡æ¨™
    actual_losses : np.ndarray
        å¯¦éš›æå¤±
    trigger_bounds : Tuple[float, float]
        è§¸ç™¼é–¾å€¼ç¯„åœ
    payout_bounds : Tuple[float, float]
        è³ ä»˜é‡‘é¡ç¯„åœ
        
    Returns:
    --------
    DecisionResult
        æ±ºç­–çµæœ
    """
    product_space = ProductSpace(
        trigger_bounds=trigger_bounds,
        payout_bounds=payout_bounds,
        grid_resolution=(10, 10)
    )
    
    optimizer = BayesianDecisionOptimizer()
    return optimizer.optimize_expected_risk(
        posterior_samples_dict, hazard_indices, actual_losses, product_space
    )

def test_bayesian_decision_theory():
    """æ¸¬è©¦è²æ°æ±ºç­–ç†è«–åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦è²æ°æ±ºç­–ç†è«–æ¨¡çµ„...")
    
    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    n_events = 100
    
    # ç½å®³æŒ‡æ¨™ï¼ˆé¢¨é€Ÿï¼‰
    hazard_indices = np.random.gamma(2, 20, n_events)  # é¢¨é€Ÿåˆ†å¸ƒ
    
    # å¯¦éš›æå¤±ï¼ˆåŸºæ–¼Emanuelé—œä¿‚çš„æ¨¡æ“¬ï¼‰
    actual_losses = np.zeros(n_events)
    for i, wind in enumerate(hazard_indices):
        if wind > 33:  # é¢¶é¢¨é¢¨é€Ÿ
            base_loss = ((wind / 33) ** 3.5) * 1e8
            actual_losses[i] = base_loss * np.random.lognormal(0, 0.5)
        else:
            actual_losses[i] = np.random.exponential(1e6) if np.random.random() < 0.1 else 0
    
    # ç”Ÿæˆå¤šå€‹æ¨¡å‹çš„å¾Œé©—æ¨£æœ¬
    posterior_samples = {
        "normal_weak": np.random.normal(0, 1, 500),
        "normal_pessimistic": np.random.normal(0, 0.5, 500),
        "student_t": np.random.standard_t(4, 500)
    }
    
    print(f"\næ¸¬è©¦æ•¸æ“šæ‘˜è¦:")
    print(f"   äº‹ä»¶æ•¸é‡: {n_events}")
    print(f"   ç½å®³æŒ‡æ¨™ç¯„åœ: {hazard_indices.min():.1f} - {hazard_indices.max():.1f}")
    print(f"   æå¤±ç¯„åœ: {actual_losses.min():.2e} - {actual_losses.max():.2e}")
    print(f"   éé›¶æå¤±æ¯”ä¾‹: {np.mean(actual_losses > 0):.1%}")
    
    # å®šç¾©ç”¢å“ç©ºé–“
    product_space = ProductSpace(
        trigger_bounds=(30, 60),
        payout_bounds=(1e7, 5e8),
        grid_resolution=(8, 8)
    )
    
    # æ¸¬è©¦è²æ°æ±ºç­–å„ªåŒ–
    print(f"\nğŸ¯ æ¸¬è©¦è²æ°æ±ºç­–å„ªåŒ–...")
    optimizer = BayesianDecisionOptimizer()
    
    bayes_result = optimizer.optimize_expected_risk(
        posterior_samples, hazard_indices, actual_losses, product_space
    )
    
    print(f"æœ€å„ªç”¢å“: è§¸ç™¼={bayes_result.optimal_product.trigger_threshold:.1f}, "
          f"è³ ä»˜={bayes_result.optimal_product.payout_amount:.2e}")
    
    # æ¸¬è©¦Î“-minimaxå„ªåŒ–
    print(f"\nğŸ›¡ï¸ æ¸¬è©¦Î“-æ¥µå°åŒ–æ¥µå¤§å„ªåŒ–...")
    minimax_result = optimizer.gamma_minimax_optimization(
        posterior_samples, hazard_indices, actual_losses, product_space
    )
    
    print(f"Minimaxç”¢å“: è§¸ç™¼={minimax_result.minimax_product.trigger_threshold:.1f}, "
          f"è³ ä»˜={minimax_result.minimax_product.payout_amount:.2e}")
    
    # æ¯”è¼ƒæ±ºç­–ç­–ç•¥
    print(f"\nğŸ“Š æ¯”è¼ƒæ±ºç­–ç­–ç•¥...")
    comparison = optimizer.compare_decision_strategies(
        posterior_samples, hazard_indices, actual_losses, product_space
    )
    
    print(f"æœ€å£æƒ…æ³æ”¹å–„: {comparison['comparison_metrics']['worst_case_improvement']:.1%}")
    print(f"å¹³å‡é¢¨éšªæ¬Šè¡¡: {comparison['comparison_metrics']['average_risk_trade_off']:.1%}")
    
    # å„ªåŒ–æ‘˜è¦
    print(f"\nğŸ“‹ å„ªåŒ–æ‘˜è¦:")
    summary_table = optimizer.get_optimization_summary()
    if not summary_table.empty:
        print(summary_table[['æ–¹æ³•', 'è§¸ç™¼é–¾å€¼', 'æœŸæœ›é¢¨éšª', 'åŸ·è¡Œæ™‚é–“']])
    
    print(f"\nâœ… è²æ°æ±ºç­–ç†è«–æ¸¬è©¦å®Œæˆ")
    return bayes_result, minimax_result, comparison

if __name__ == "__main__":
    test_bayesian_decision_theory()