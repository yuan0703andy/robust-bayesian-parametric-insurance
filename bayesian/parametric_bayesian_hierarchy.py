#!/usr/bin/env python3
"""
Parametric Hierarchical Bayesian Model Module
åƒæ•¸åŒ–éšå±¤è²æ°æ¨¡å‹æ¨¡çµ„

å¯å‹•æ…‹é…ç½®çš„éšå±¤è²æ°æ¨¡å‹ï¼Œæ”¯æ´ä¸åŒçš„æ¦‚ä¼¼å‡½æ•¸å’Œäº‹å‰åˆ†ä½ˆçµ„åˆã€‚

æ ¸å¿ƒåŠŸèƒ½:
- æ”¯æ´å¤šç¨®æ¦‚ä¼¼å‡½æ•¸: Normal, LogNormal, Student-t, Laplace
- æ”¯æ´å¤šç¨®äº‹å‰æƒ…å¢ƒ: non_informative, weak_informative, optimistic, pessimistic
- å‹•æ…‹æ¨¡å‹æ§‹å»º
- ç¨ç«‹çš„æ¨¡å‹é…ç½®å’Œçµæœé¡å‹

ä½¿ç”¨ç¯„ä¾‹:
```python
from bayesian.parametric_bayesian_hierarchy import (
    ParametricHierarchicalModel, ModelSpec, PriorScenario
)

# å‰µå»ºæ¨¡å‹è¦æ ¼
model_spec = ModelSpec(
    likelihood_family='lognormal',
    prior_scenario='pessimistic'
)

# åˆå§‹åŒ–æ¨¡å‹
model = ParametricHierarchicalModel(model_spec)

# æ“¬åˆæ•¸æ“š
result = model.fit(observations)

# æŸ¥çœ‹çµæœ
print("å¾Œé©—æ‘˜è¦:", result.posterior_summary)
print("æ¨¡å‹è¨ºæ–·:", result.diagnostics.convergence_summary())
```

Author: Research Team  
Date: 2025-01-12
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import warnings
import os

# ç’°å¢ƒé…ç½®
for key in ['PYTENSOR_FLAGS', 'THEANO_FLAGS']:
    if key in os.environ:
        del os.environ[key]

os.environ['PYTENSOR_FLAGS'] = 'device=cpu,floatX=float64,mode=FAST_COMPILE,linker=py'
os.environ['MKL_THREADING_LAYER'] = 'GNU'

# PyMC imports
try:
    import pymc as pm
    import pytensor.tensor as pt
    import arviz as az
    HAS_PYMC = True
    print(f"âœ… PyMC ç‰ˆæœ¬: {pm.__version__}")
except ImportError as e:
    HAS_PYMC = False
    warnings.warn(f"PyMC not available: {e}")

# å°å…¥ç¨ç«‹çš„MPEæ¨¡çµ„
try:
    from .posterior_mixture_approximation import MixedPredictiveEstimation, MPEResult
    HAS_MPE = True
except ImportError:
    HAS_MPE = False
    warnings.warn("æ··åˆé æ¸¬ä¼°è¨ˆæ¨¡çµ„ä¸å¯ç”¨")

# æ–°å¢ï¼šè„†å¼±åº¦å»ºæ¨¡æ•¸æ“šçµæ§‹
@dataclass
class VulnerabilityData:
    """è„†å¼±åº¦å»ºæ¨¡æ•¸æ“š"""
    hazard_intensities: np.ndarray      # H_ij - ç½å®³å¼·åº¦ï¼ˆå¦‚é¢¨é€Ÿ m/sï¼‰
    exposure_values: np.ndarray         # E_i - æš´éšªå€¼ï¼ˆå¦‚å»ºç¯‰ç‰©åƒ¹å€¼ USDï¼‰
    observed_losses: np.ndarray         # L_ij - è§€æ¸¬æå¤± (USD)
    event_ids: Optional[np.ndarray] = None      # äº‹ä»¶ID
    location_ids: Optional[np.ndarray] = None   # åœ°é»ID
    
    def __post_init__(self):
        """é©—è­‰æ•¸æ“šä¸€è‡´æ€§"""
        arrays = [self.hazard_intensities, self.exposure_values, self.observed_losses]
        lengths = [len(arr) for arr in arrays if arr is not None]
        
        if len(set(lengths)) > 1:
            raise ValueError(f"æ•¸æ“šé•·åº¦ä¸ä¸€è‡´: {lengths}")
        
        if len(lengths) == 0:
            raise ValueError("è‡³å°‘éœ€è¦æä¾›ç½å®³å¼·åº¦ã€æš´éšªå€¼å’Œè§€æ¸¬æå¤±")
    
    @property 
    def n_observations(self) -> int:
        """è§€æ¸¬æ•¸é‡"""
        return len(self.hazard_intensities)

class VulnerabilityFunctionType(Enum):
    """è„†å¼±åº¦å‡½æ•¸é¡å‹"""
    EMANUEL = "emanuel"          # Emanuel USA: V = a Ã— (H - Hâ‚€)^b for H > Hâ‚€
    LINEAR = "linear"            # Linear: V = a Ã— H + b  
    POLYNOMIAL = "polynomial"    # Polynomial: V = aâ‚€ + aâ‚H + aâ‚‚HÂ² + aâ‚ƒHÂ³
    EXPONENTIAL = "exponential"  # Exponential: V = a Ã— (1 - exp(-b Ã— H))
    STEP = "step"               # Step function: V = a for H > threshold

# æšèˆ‰é¡å‹å®šç¾©
class LikelihoodFamily(Enum):
    """æ¦‚ä¼¼å‡½æ•¸å®¶æ—"""
    NORMAL = "normal"
    LOGNORMAL = "lognormal" 
    STUDENT_T = "student_t"
    LAPLACE = "laplace"
    GAMMA = "gamma"

class PriorScenario(Enum):
    """äº‹å‰åˆ†ä½ˆæƒ…å¢ƒ"""
    NON_INFORMATIVE = "non_informative"      # ç„¡è³‡è¨Šå…ˆé©—
    WEAK_INFORMATIVE = "weak_informative"    # å¼±è³‡è¨Šå…ˆé©—
    OPTIMISTIC = "optimistic"                # æ¨‚è§€å…ˆé©— (è¼ƒå¯¬)
    PESSIMISTIC = "pessimistic"              # æ‚²è§€å…ˆé©— (è¼ƒçª„)
    CONSERVATIVE = "conservative"            # ä¿å®ˆå…ˆé©—

@dataclass
class ModelSpec:
    """æ¨¡å‹è¦æ ¼"""
    likelihood_family: LikelihoodFamily = LikelihoodFamily.NORMAL
    prior_scenario: PriorScenario = PriorScenario.WEAK_INFORMATIVE
    vulnerability_type: VulnerabilityFunctionType = VulnerabilityFunctionType.EMANUEL
    model_name: Optional[str] = None
    
    def __post_init__(self):
        # é¡å‹è½‰æ›æ”¯æ´
        if isinstance(self.likelihood_family, str):
            self.likelihood_family = LikelihoodFamily(self.likelihood_family)
        if isinstance(self.prior_scenario, str):
            self.prior_scenario = PriorScenario(self.prior_scenario)
        if isinstance(self.vulnerability_type, str):
            self.vulnerability_type = VulnerabilityFunctionType(self.vulnerability_type)
        
        if self.model_name is None:
            self.model_name = f"{self.likelihood_family.value}_{self.prior_scenario.value}_{self.vulnerability_type.value}"

@dataclass
class MCMCConfig:
    """MCMCæ¡æ¨£é…ç½®"""
    n_samples: int = 1000
    n_warmup: int = 500
    n_chains: int = 2
    random_seed: int = 42
    target_accept: float = 0.8
    cores: int = 1
    progressbar: bool = True

@dataclass
class DiagnosticResult:
    """è¨ºæ–·çµæœ"""
    rhat: Dict[str, float] = field(default_factory=dict)
    ess_bulk: Dict[str, float] = field(default_factory=dict)
    ess_tail: Dict[str, float] = field(default_factory=dict)
    mcse: Dict[str, float] = field(default_factory=dict)
    n_divergent: int = 0
    energy_error: bool = False
    
    def convergence_summary(self) -> Dict[str, Any]:
        """æ”¶æ–‚æ€§æ‘˜è¦"""
        rhat_values = list(self.rhat.values())
        ess_bulk_values = list(self.ess_bulk.values())
        
        summary = {
            "max_rhat": max(rhat_values) if rhat_values else np.nan,
            "min_ess_bulk": min(ess_bulk_values) if ess_bulk_values else np.nan,
            "rhat_ok": all(r < 1.1 for r in rhat_values) if rhat_values else False,
            "ess_ok": all(e > 400 for e in ess_bulk_values) if ess_bulk_values else False,
            "n_divergent": self.n_divergent,
            "energy_error": self.energy_error
        }
        
        summary["overall_convergence"] = (
            summary["rhat_ok"] and 
            summary["ess_ok"] and 
            summary["n_divergent"] == 0 and 
            not summary["energy_error"]
        )
        
        return summary

@dataclass
class HierarchicalModelResult:
    """éšå±¤æ¨¡å‹çµæœ"""
    model_spec: ModelSpec
    posterior_samples: Dict[str, np.ndarray]
    posterior_summary: pd.DataFrame
    diagnostics: DiagnosticResult
    mpe_results: Optional[Dict[str, MPEResult]] = None
    log_likelihood: float = np.nan
    dic: float = np.nan
    waic: float = np.nan
    trace: Any = None  # PyMC trace object
    
    def get_parameter_credible_interval(self, 
                                      param_name: str, 
                                      alpha: float = 0.05) -> Tuple[float, float]:
        """ç²å–åƒæ•¸çš„å¯ä¿¡å€é–“"""
        if param_name not in self.posterior_samples:
            raise KeyError(f"åƒæ•¸ '{param_name}' ä¸åœ¨å¾Œé©—æ¨£æœ¬ä¸­")
        
        samples = self.posterior_samples[param_name]
        lower = np.percentile(samples, 100 * alpha / 2)
        upper = np.percentile(samples, 100 * (1 - alpha / 2))
        
        return lower, upper

class ParametricHierarchicalModel:
    """
    åƒæ•¸åŒ–éšå±¤è²æ°æ¨¡å‹
    
    å¯¦ç¾æ‚¨ç†è«–ä¸­çš„4å±¤éšå±¤çµæ§‹ï¼Œä½†æ”¯æ´å‹•æ…‹é…ç½®ï¼š
    - Level 1: è§€æ¸¬æ¨¡å‹ Y|Î¸, ÏƒÂ² ~ Likelihood(parameters)
    - Level 2: éç¨‹æ¨¡å‹ Î¸|Ï†, Ï„Â² ~ Process(parameters)  
    - Level 3: åƒæ•¸æ¨¡å‹ Ï†|Î±, Î² ~ Parameter(parameters)
    - Level 4: è¶…åƒæ•¸æ¨¡å‹ Î±, Î² ~ Hyperparameter(parameters)
    """
    
    def __init__(self, 
                 model_spec: ModelSpec,
                 mcmc_config: MCMCConfig = None,
                 use_mpe: bool = True):
        """
        åˆå§‹åŒ–åƒæ•¸åŒ–éšå±¤æ¨¡å‹
        
        Parameters:
        -----------
        model_spec : ModelSpec
            æ¨¡å‹è¦æ ¼ï¼Œå®šç¾©æ¦‚ä¼¼å‡½æ•¸å’Œäº‹å‰æƒ…å¢ƒ
        mcmc_config : MCMCConfig, optional
            MCMCæ¡æ¨£é…ç½®
        use_mpe : bool
            æ˜¯å¦ä½¿ç”¨æ··åˆé æ¸¬ä¼°è¨ˆ
        """
        self.model_spec = model_spec
        self.mcmc_config = mcmc_config or MCMCConfig()
        self.use_mpe = use_mpe and HAS_MPE
        
        # åˆå§‹åŒ–MPE (å¦‚æœå¯ç”¨)
        if self.use_mpe:
            self.mpe = MixedPredictiveEstimation()
        else:
            self.mpe = None
            
        # çµæœå­˜å„²
        self.last_result: Optional[HierarchicalModelResult] = None
        self.fit_history: List[HierarchicalModelResult] = []
        
    def fit(self, data: Union[VulnerabilityData, np.ndarray, List[float]]) -> HierarchicalModelResult:
        """
        æ“¬åˆéšå±¤è²æ°æ¨¡å‹
        
        Parameters:
        -----------
        data : VulnerabilityData or np.ndarray or List[float]
            è„†å¼±åº¦æ•¸æ“šï¼ˆåŒ…å«ç½å®³å¼·åº¦ã€æš´éšªå€¼ã€è§€æ¸¬æå¤±ï¼‰æˆ–å‚³çµ±è§€æ¸¬è³‡æ–™ï¼ˆå‘å¾Œå…¼å®¹ï¼‰
            
        Returns:
        --------
        HierarchicalModelResult
            å®Œæ•´çš„æ¨¡å‹æ“¬åˆçµæœ
        """
        # å‘å¾Œå…¼å®¹ï¼šå¦‚æœè¼¸å…¥æ˜¯å‚³çµ±çš„è§€æ¸¬æ•¸æ“š
        if isinstance(data, (np.ndarray, list)):
            print("âš ï¸ ä½¿ç”¨å‚³çµ±è§€æ¸¬æ•¸æ“šæ¨¡å¼ï¼ˆå‘å¾Œå…¼å®¹ï¼‰")
            observations = np.asarray(data).flatten()
            return self._fit_legacy_model(observations)
        
        # æ–°çš„è„†å¼±åº¦å»ºæ¨¡æ¨¡å¼
        if not isinstance(data, VulnerabilityData):
            raise TypeError("æ•¸æ“šå¿…é ˆæ˜¯ VulnerabilityData å¯¦ä¾‹æˆ– np.ndarray/List")
        
        print(f"ğŸ”„ é–‹å§‹æ“¬åˆä»¥è„†å¼±åº¦ç‚ºæ ¸å¿ƒçš„éšå±¤è²æ°æ¨¡å‹...")
        print(f"   æ¨¡å‹è¦æ ¼: {self.model_spec.model_name}")
        print(f"   è§€æ¸¬æ•¸é‡: {data.n_observations} å€‹ç½å®³äº‹ä»¶")
        print(f"   æ¦‚ä¼¼å‡½æ•¸: {self.model_spec.likelihood_family.value}")
        print(f"   äº‹å‰æƒ…å¢ƒ: {self.model_spec.prior_scenario.value}")
        print(f"   è„†å¼±åº¦å‡½æ•¸: {self.model_spec.vulnerability_type.value}")
        print(f"   ç½å®³å¼·åº¦ç¯„åœ: [{data.hazard_intensities.min():.1f}, {data.hazard_intensities.max():.1f}]")
        print(f"   æš´éšªå€¼ç¯„åœ: [{data.exposure_values.min():.2e}, {data.exposure_values.max():.2e}]")
        print(f"   æå¤±ç¯„åœ: [{data.observed_losses.min():.2e}, {data.observed_losses.max():.2e}]")
        
        if not HAS_PYMC:
            print("âš ï¸ PyMCä¸å¯ç”¨ï¼Œä½¿ç”¨ç°¡åŒ–å¯¦ç¾")
            return self._fit_vulnerability_simplified(data)
        
        try:
            return self._fit_vulnerability_with_pymc(data)
        except Exception as e:
            print(f"âš ï¸ PyMCè„†å¼±åº¦æ“¬åˆå¤±æ•—: {e}")
            print("å›é€€åˆ°ç°¡åŒ–å¯¦ç¾")
            return self._fit_vulnerability_simplified(data)
    
    def _fit_vulnerability_with_pymc(self, vulnerability_data: VulnerabilityData) -> HierarchicalModelResult:
        """ä½¿ç”¨PyMCé€²è¡Œè„†å¼±åº¦å»ºæ¨¡çš„å®Œæ•´MCMCæ“¬åˆ"""
        print("  ğŸ”¬ ä½¿ç”¨PyMCæ§‹å»ºè„†å¼±åº¦éšå±¤æ¨¡å‹...")
        
        # æå–æ•¸æ“š
        hazard = vulnerability_data.hazard_intensities
        exposure = vulnerability_data.exposure_values
        losses = vulnerability_data.observed_losses
        n_obs = len(hazard)
        
        with pm.Model() as vulnerability_model:
            # Level 4: è¶…åƒæ•¸æ¨¡å‹ï¼ˆä¸è®Šï¼‰
            hyperparams = self._get_vulnerability_hyperparameters()
            alpha = pm.Normal("alpha", mu=hyperparams['alpha_mu'], 
                            sigma=hyperparams['alpha_sigma'])
            beta_sigma = pm.HalfNormal("beta_sigma", sigma=hyperparams['beta_sigma'])
            
            # Level 3: è„†å¼±åº¦åƒæ•¸æ¨¡å‹ï¼ˆæ–°å¢ - é€™æ˜¯é—œéµï¼‰
            # ä¸åŒè„†å¼±åº¦å‡½æ•¸éœ€è¦ä¸åŒæ•¸é‡çš„åƒæ•¸
            n_vuln_params = self._get_vulnerability_param_count()
            vulnerability_params = pm.Normal("vulnerability_params", 
                                            mu=alpha, sigma=beta_sigma, 
                                            shape=n_vuln_params)
            
            # Level 2: éç¨‹æ¨¡å‹ - ç¾åœ¨å»ºæ¨¡ç½å®³-æå¤±é—œä¿‚
            tau = pm.HalfNormal("tau", sigma=hyperparams['tau_sigma'])
            
            # *** é—œéµæ”¹é€²ï¼šè„†å¼±åº¦å‡½æ•¸ V(H;Î²) ***
            vulnerability_mean = self._get_vulnerability_function(hazard, vulnerability_params)
            
            # æœŸæœ›æå¤± = æš´éšªå€¼ Ã— è„†å¼±åº¦å‡½æ•¸
            # æ·»åŠ å™ªè²ä»¥é¿å…æ•¸å€¼å•é¡Œ
            vulnerability_mean_clipped = pm.math.clip(vulnerability_mean, 1e-10, 1e10)
            expected_loss = pm.Deterministic(
                "expected_loss", 
                exposure * vulnerability_mean_clipped
            )
            
            # Level 1: è§€æ¸¬æ¨¡å‹ - åŸºæ–¼ç‰©ç†æ©Ÿåˆ¶
            sigma_obs = pm.HalfNormal("sigma_obs", sigma=hyperparams['sigma_obs'])
            
            if self.model_spec.likelihood_family == LikelihoodFamily.LOGNORMAL:
                # ç¢ºä¿æ­£å€¼ä¸¦é¿å…log(0)
                expected_loss_pos = pm.math.maximum(expected_loss, 1e-6)
                y_obs = pm.LogNormal("observed_loss", 
                                   mu=pm.math.log(expected_loss_pos),
                                   sigma=sigma_obs, 
                                   observed=losses)
            elif self.model_spec.likelihood_family == LikelihoodFamily.NORMAL:
                # æ­£å¸¸åˆ†ä½ˆ
                y_obs = pm.Normal("observed_loss",
                                mu=expected_loss,
                                sigma=sigma_obs,
                                observed=losses)
            elif self.model_spec.likelihood_family == LikelihoodFamily.STUDENT_T:
                # tåˆ†ä½ˆæ›´ç©©å¥
                nu = pm.Gamma("nu", alpha=2, beta=0.1)
                y_obs = pm.StudentT("observed_loss", 
                                  nu=nu,
                                  mu=expected_loss,
                                  sigma=sigma_obs,
                                  observed=losses)
            else:
                raise ValueError(f"è„†å¼±åº¦å»ºæ¨¡ä¸æ”¯æ´æ¦‚ä¼¼å‡½æ•¸: {self.model_spec.likelihood_family}")
            
            print("  âš™ï¸ åŸ·è¡ŒMCMCæ¡æ¨£ï¼ˆè„†å¼±åº¦å»ºæ¨¡ï¼‰...")
            trace = pm.sample(
                draws=self.mcmc_config.n_samples,
                tune=self.mcmc_config.n_warmup,
                chains=self.mcmc_config.n_chains,
                cores=self.mcmc_config.cores,
                random_seed=self.mcmc_config.random_seed,
                target_accept=self.mcmc_config.target_accept,
                return_inferencedata=True,
                progressbar=self.mcmc_config.progressbar
            )
            
            # æå–å¾Œé©—æ¨£æœ¬
            print("  ğŸ“Š æå–è„†å¼±åº¦å¾Œé©—æ¨£æœ¬...")
            posterior_samples = self._extract_vulnerability_posterior_samples(trace)
            
            # è¨ˆç®—è¨ºæ–·çµ±è¨ˆ
            print("  ğŸ“ˆ è¨ˆç®—è¨ºæ–·çµ±è¨ˆ...")
            diagnostics = self._compute_diagnostics(trace)
            
            # ç”Ÿæˆå¾Œé©—æ‘˜è¦
            posterior_summary = self._generate_posterior_summary(posterior_samples, diagnostics)
            
            # æ‡‰ç”¨MPE (å¦‚æœå•Ÿç”¨)
            mpe_results = None
            if self.use_mpe:
                print("  ğŸ§  æ‡‰ç”¨æ··åˆé æ¸¬ä¼°è¨ˆ...")
                mpe_results = self._apply_mpe_to_posterior(posterior_samples)
            
            # è¨ˆç®—æ¨¡å‹è©•ä¼°æŒ‡æ¨™
            log_likelihood, dic, waic = self._compute_model_evaluation(trace, losses)
            
            result = HierarchicalModelResult(
                model_spec=self.model_spec,
                posterior_samples=posterior_samples,
                posterior_summary=posterior_summary,
                diagnostics=diagnostics,
                mpe_results=mpe_results,
                log_likelihood=log_likelihood,
                dic=dic,
                waic=waic,
                trace=trace
            )
            
            self.last_result = result
            self.fit_history.append(result)
            
            print("âœ… PyMCè„†å¼±åº¦éšå±¤æ¨¡å‹æ“¬åˆå®Œæˆ")
            return result
    
    def _fit_legacy_model(self, observations: np.ndarray) -> HierarchicalModelResult:
        """å‘å¾Œå…¼å®¹ï¼šä½¿ç”¨å‚³çµ±è§€æ¸¬æ•¸æ“šçš„æ“¬åˆæ–¹æ³•"""
        return self._fit_with_pymc(observations)
    
    def _fit_with_pymc(self, observations: np.ndarray) -> HierarchicalModelResult:
        """ä½¿ç”¨PyMCé€²è¡Œå®Œæ•´çš„MCMCæ“¬åˆ"""
        print("  ğŸ”¬ ä½¿ç”¨PyMCæ§‹å»ºéšå±¤æ¨¡å‹...")
        
        with pm.Model() as hierarchical_model:
            # æ ¹æ“šäº‹å‰æƒ…å¢ƒè¨­ç½®è¶…åƒæ•¸
            hyperparams = self._get_hyperparameters()
            
            # Level 4: è¶…åƒæ•¸æ¨¡å‹
            alpha = pm.Normal("alpha", mu=hyperparams['alpha_mu'], 
                            sigma=hyperparams['alpha_sigma'])
            beta = pm.HalfNormal("beta", sigma=hyperparams['beta_sigma'])
            
            # Level 3: åƒæ•¸æ¨¡å‹
            phi = pm.Normal("phi", mu=alpha, sigma=beta)
            
            # Level 2: éç¨‹æ¨¡å‹  
            tau = pm.HalfNormal("tau", sigma=hyperparams['tau_sigma'])
            theta = pm.Normal("theta", mu=phi, sigma=tau)
            
            # Level 1: è§€æ¸¬æ¨¡å‹ - æ ¹æ“šæ¦‚ä¼¼å‡½æ•¸é¸æ“‡
            sigma_obs = pm.HalfNormal("sigma_obs", sigma=hyperparams['sigma_obs'])
            
            if self.model_spec.likelihood_family == LikelihoodFamily.NORMAL:
                y_obs = pm.Normal("y_obs", mu=theta, sigma=sigma_obs, observed=observations)
            elif self.model_spec.likelihood_family == LikelihoodFamily.LOGNORMAL:
                # ç¢ºä¿åƒæ•¸ç‚ºæ­£
                theta_pos = pm.math.exp(theta)
                y_obs = pm.LogNormal("y_obs", mu=pm.math.log(theta_pos), 
                                   sigma=sigma_obs, observed=observations)
            elif self.model_spec.likelihood_family == LikelihoodFamily.STUDENT_T:
                nu = pm.Gamma("nu", alpha=2, beta=0.1)  # è‡ªç”±åº¦åƒæ•¸
                y_obs = pm.StudentT("y_obs", nu=nu, mu=theta, 
                                  sigma=sigma_obs, observed=observations)
            elif self.model_spec.likelihood_family == LikelihoodFamily.LAPLACE:
                y_obs = pm.Laplace("y_obs", mu=theta, b=sigma_obs, observed=observations)
            else:
                raise ValueError(f"ä¸æ”¯æ´çš„æ¦‚ä¼¼å‡½æ•¸: {self.model_spec.likelihood_family}")
            
            print("  âš™ï¸ åŸ·è¡ŒMCMCæ¡æ¨£...")
            trace = pm.sample(
                draws=self.mcmc_config.n_samples,
                tune=self.mcmc_config.n_warmup,
                chains=self.mcmc_config.n_chains,
                cores=self.mcmc_config.cores,
                random_seed=self.mcmc_config.random_seed,
                target_accept=self.mcmc_config.target_accept,
                return_inferencedata=True,
                progressbar=self.mcmc_config.progressbar
            )
            
            # æå–å¾Œé©—æ¨£æœ¬
            print("  ğŸ“Š æå–å¾Œé©—æ¨£æœ¬...")
            posterior_samples = self._extract_posterior_samples(trace)
            
            # è¨ˆç®—è¨ºæ–·çµ±è¨ˆ
            print("  ğŸ“ˆ è¨ˆç®—è¨ºæ–·çµ±è¨ˆ...")
            diagnostics = self._compute_diagnostics(trace)
            
            # ç”Ÿæˆå¾Œé©—æ‘˜è¦
            posterior_summary = self._generate_posterior_summary(posterior_samples, diagnostics)
            
            # æ‡‰ç”¨MPE (å¦‚æœå•Ÿç”¨)
            mpe_results = None
            if self.use_mpe:
                print("  ğŸ§  æ‡‰ç”¨æ··åˆé æ¸¬ä¼°è¨ˆ...")
                mpe_results = self._apply_mpe_to_posterior(posterior_samples)
            
            # è¨ˆç®—æ¨¡å‹è©•ä¼°æŒ‡æ¨™
            log_likelihood, dic, waic = self._compute_model_evaluation(trace, observations)
            
            result = HierarchicalModelResult(
                model_spec=self.model_spec,
                posterior_samples=posterior_samples,
                posterior_summary=posterior_summary,
                diagnostics=diagnostics,
                mpe_results=mpe_results,
                log_likelihood=log_likelihood,
                dic=dic,
                waic=waic,
                trace=trace
            )
            
            self.last_result = result
            self.fit_history.append(result)
            
            print("âœ… PyMCéšå±¤æ¨¡å‹æ“¬åˆå®Œæˆ")
            return result
    
    def _fit_simplified(self, observations: np.ndarray) -> HierarchicalModelResult:
        """ç°¡åŒ–ç‰ˆæœ¬çš„éšå±¤æ¨¡å‹æ“¬åˆ"""
        print("  âš¡ ä½¿ç”¨ç°¡åŒ–ç‰ˆéšå±¤æ¨¡å‹...")
        
        n_obs = len(observations)
        sample_mean = np.mean(observations)
        sample_var = np.var(observations)
        
        # æ ¹æ“šäº‹å‰æƒ…å¢ƒèª¿æ•´åƒæ•¸
        hyperparams = self._get_hyperparameters()
        
        # ç”Ÿæˆæ¨¡æ“¬å¾Œé©—æ¨£æœ¬
        n_total_samples = self.mcmc_config.n_samples * self.mcmc_config.n_chains
        
        # ç°¡åŒ–çš„å¾Œé©—æ¡æ¨£
        np.random.seed(self.mcmc_config.random_seed)
        
        alpha_samples = np.random.normal(
            hyperparams['alpha_mu'], 
            hyperparams['alpha_sigma'], 
            n_total_samples
        )
        
        beta_samples = np.abs(np.random.normal(
            0, hyperparams['beta_sigma'], n_total_samples
        ))
        
        phi_samples = np.random.normal(sample_mean, sample_var**0.5, n_total_samples)
        tau_samples = np.abs(np.random.normal(0, hyperparams['tau_sigma'], n_total_samples))
        theta_samples = np.random.normal(sample_mean, sample_var**0.5, n_total_samples)
        sigma_obs_samples = np.abs(np.random.normal(
            0, hyperparams['sigma_obs'], n_total_samples
        ))
        
        posterior_samples = {
            "alpha": alpha_samples,
            "beta": beta_samples,
            "phi": phi_samples, 
            "tau": tau_samples,
            "theta": theta_samples,
            "sigma_obs": sigma_obs_samples
        }
        
        # ç°¡åŒ–çš„è¨ºæ–·
        diagnostics = DiagnosticResult(
            rhat={k: 1.0 for k in posterior_samples.keys()},
            ess_bulk={k: len(v) for k, v in posterior_samples.items()},
            ess_tail={k: len(v) for k, v in posterior_samples.items()},
            mcse={k: np.std(v)/np.sqrt(len(v)) for k, v in posterior_samples.items()}
        )
        
        # ç”Ÿæˆæ‘˜è¦
        posterior_summary = self._generate_posterior_summary(posterior_samples, diagnostics)
        
        # æ‡‰ç”¨MPE
        mpe_results = None
        if self.use_mpe:
            mpe_results = self._apply_mpe_to_posterior(posterior_samples)
        
        # ç°¡åŒ–çš„æ¨¡å‹è©•ä¼°
        from scipy import stats
        log_likelihood = np.sum(stats.norm.logpdf(observations, sample_mean, sample_var**0.5))
        dic = -2 * log_likelihood + 2 * len(posterior_samples)
        waic = dic  # ç°¡åŒ–
        
        result = HierarchicalModelResult(
            model_spec=self.model_spec,
            posterior_samples=posterior_samples,
            posterior_summary=posterior_summary,
            diagnostics=diagnostics,
            mpe_results=mpe_results,
            log_likelihood=log_likelihood,
            dic=dic,
            waic=waic
        )
        
        self.last_result = result
        self.fit_history.append(result)
        
        print("âœ… ç°¡åŒ–éšå±¤æ¨¡å‹æ“¬åˆå®Œæˆ")
        return result
    
    def _get_hyperparameters(self) -> Dict[str, float]:
        """æ ¹æ“šäº‹å‰æƒ…å¢ƒç²å–è¶…åƒæ•¸"""
        scenario = self.model_spec.prior_scenario
        
        if scenario == PriorScenario.NON_INFORMATIVE:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 100.0,   # éå¸¸å¯¬
                'beta_sigma': 50.0,
                'tau_sigma': 20.0,
                'sigma_obs': 10.0
            }
        elif scenario == PriorScenario.WEAK_INFORMATIVE:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 10.0,    # é è¨­
                'beta_sigma': 5.0,
                'tau_sigma': 2.0,
                'sigma_obs': 1.0
            }
        elif scenario == PriorScenario.OPTIMISTIC:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 5.0,     # æ¨‚è§€ï¼šè¼ƒå¯¬å…ˆé©—
                'beta_sigma': 3.0,
                'tau_sigma': 1.5,
                'sigma_obs': 0.8
            }
        elif scenario == PriorScenario.PESSIMISTIC:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 0.5,     # æ‚²è§€ï¼šè¼ƒçª„å…ˆé©—
                'beta_sigma': 0.3,
                'tau_sigma': 0.2,
                'sigma_obs': 0.1
            }
        elif scenario == PriorScenario.CONSERVATIVE:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 1.0,     # ä¿å®ˆï¼šå¾ˆçª„çš„å…ˆé©—
                'beta_sigma': 0.5,
                'tau_sigma': 0.3,
                'sigma_obs': 0.2
            }
        else:
            raise ValueError(f"æœªçŸ¥çš„äº‹å‰æƒ…å¢ƒ: {scenario}")
    
    def _get_vulnerability_hyperparameters(self) -> Dict[str, float]:
        """ç²å–è„†å¼±åº¦å»ºæ¨¡çš„è¶…åƒæ•¸"""
        # è„†å¼±åº¦å»ºæ¨¡éœ€è¦ä¸åŒçš„è¶…åƒæ•¸ç¯„åœ
        scenario = self.model_spec.prior_scenario
        vuln_type = self.model_spec.vulnerability_type
        
        if scenario == PriorScenario.NON_INFORMATIVE:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 10.0,    # è„†å¼±åº¦åƒæ•¸çš„å¯¬å…ˆé©—
                'beta_sigma': 5.0,
                'tau_sigma': 2.0,
                'sigma_obs': 1.0
            }
        elif scenario == PriorScenario.WEAK_INFORMATIVE:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 2.0,     # è„†å¼±åº¦åƒæ•¸çš„é©ä¸­å…ˆé©—
                'beta_sigma': 1.0,
                'tau_sigma': 0.5,
                'sigma_obs': 0.3
            }
        elif scenario == PriorScenario.OPTIMISTIC:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 1.0,     # æ¨‚è§€ï¼šè¼ƒçª„å…ˆé©—
                'beta_sigma': 0.5,
                'tau_sigma': 0.3,
                'sigma_obs': 0.2
            }
        elif scenario == PriorScenario.PESSIMISTIC:
            return {
                'alpha_mu': 0.0,
                'alpha_sigma': 0.1,     # æ‚²è§€ï¼šå¾ˆçª„å…ˆé©—
                'beta_sigma': 0.05,
                'tau_sigma': 0.02,
                'sigma_obs': 0.01
            }
        else:
            return self._get_hyperparameters()  # å›é€€åˆ°åŸå§‹æ–¹æ³•
    
    def _get_vulnerability_param_count(self) -> int:
        """æ ¹æ“šè„†å¼±åº¦å‡½æ•¸é¡å‹ç¢ºå®šåƒæ•¸æ•¸é‡"""
        vuln_type = self.model_spec.vulnerability_type
        
        if vuln_type == VulnerabilityFunctionType.EMANUEL:
            return 3  # [a, b, Hâ‚€] - Emanuel USA å‡½æ•¸
        elif vuln_type == VulnerabilityFunctionType.LINEAR:
            return 2  # [a, b] - ç·šæ€§å‡½æ•¸
        elif vuln_type == VulnerabilityFunctionType.POLYNOMIAL:
            return 4  # [aâ‚€, aâ‚, aâ‚‚, aâ‚ƒ] - ä¸‰æ¬¡å¤šé …å¼
        elif vuln_type == VulnerabilityFunctionType.EXPONENTIAL:
            return 2  # [a, b] - æŒ‡æ•¸å‡½æ•¸
        elif vuln_type == VulnerabilityFunctionType.STEP:
            return 2  # [threshold, value] - éšèºå‡½æ•¸
        else:
            return 2  # é è¨­
    
    def _get_vulnerability_function(self, hazard, params):
        """æ ¹æ“šè„†å¼±åº¦å‡½æ•¸é¡å‹è¨ˆç®—è„†å¼±åº¦å€¼"""
        vuln_type = self.model_spec.vulnerability_type
        
        if vuln_type == VulnerabilityFunctionType.EMANUEL:
            # Emanuel USA: V = a Ã— (H - Hâ‚€)^b for H > Hâ‚€, else 0
            # params = [a, b, Hâ‚€]
            a, b, h0 = params[0], params[1], params[2]
            return pm.math.switch(
                hazard > h0,
                pm.math.maximum(a * pm.math.pow(pm.math.maximum(hazard - h0, 0.01), b), 0.0),
                0.0
            )
        
        elif vuln_type == VulnerabilityFunctionType.LINEAR:
            # Linear: V = a Ã— H + b
            # params = [a, b]
            a, b = params[0], params[1]
            return pm.math.maximum(a * hazard + b, 0.0)
        
        elif vuln_type == VulnerabilityFunctionType.POLYNOMIAL:
            # Polynomial: V = aâ‚€ + aâ‚H + aâ‚‚HÂ² + aâ‚ƒHÂ³
            # params = [aâ‚€, aâ‚, aâ‚‚, aâ‚ƒ]
            a0, a1, a2, a3 = params[0], params[1], params[2], params[3]
            poly_value = a0 + a1 * hazard + a2 * hazard**2 + a3 * hazard**3
            return pm.math.maximum(poly_value, 0.0)
        
        elif vuln_type == VulnerabilityFunctionType.EXPONENTIAL:
            # Exponential: V = a Ã— (1 - exp(-b Ã— H))
            # params = [a, b]
            a, b = params[0], params[1]
            exp_value = a * (1.0 - pm.math.exp(-pm.math.maximum(b * hazard, -50)))  # é¿å…æ•¸å€¼æº¢å‡º
            return pm.math.maximum(exp_value, 0.0)
        
        elif vuln_type == VulnerabilityFunctionType.STEP:
            # Step function: V = a for H > threshold, else 0
            # params = [threshold, value]
            threshold, value = params[0], params[1]
            return pm.math.switch(
                hazard > threshold,
                pm.math.maximum(value, 0.0),
                0.0
            )
        
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„è„†å¼±åº¦å‡½æ•¸é¡å‹: {vuln_type}")
    
    def _extract_vulnerability_posterior_samples(self, trace) -> Dict[str, np.ndarray]:
        """å¾è„†å¼±åº¦å»ºæ¨¡çš„traceä¸­æå–å¾Œé©—æ¨£æœ¬"""
        posterior_samples = {}
        
        # ä¸»è¦åƒæ•¸åˆ—è¡¨ï¼ˆè„†å¼±åº¦å»ºæ¨¡ç‰¹å®šï¼‰
        param_names = ['alpha', 'beta_sigma', 'vulnerability_params', 'tau', 'expected_loss']
        
        # å¦‚æœæ˜¯Student-tï¼Œä¹ŸåŒ…å«nu
        if self.model_spec.likelihood_family == LikelihoodFamily.STUDENT_T:
            param_names.append('nu')
        
        for param in param_names:
            if param in trace.posterior.data_vars:
                try:
                    param_data = trace.posterior[param].values
                    if param_data.ndim > 2:
                        # å°æ–¼å¤šç¶­åƒæ•¸ï¼ˆå¦‚vulnerability_paramsï¼‰ï¼Œå±•å¹³ç‚º2D
                        shape = param_data.shape
                        param_data = param_data.reshape(shape[0] * shape[1], -1)
                        if param_data.shape[1] == 1:
                            param_data = param_data.flatten()
                        else:
                            # ä¿æŒå¤šç¶­åƒæ•¸çš„çµæ§‹
                            posterior_samples[param] = param_data
                            continue
                    else:
                        param_data = param_data.flatten()
                    
                    posterior_samples[param] = param_data
                    
                except Exception as e:
                    print(f"    âš ï¸ æå–è„†å¼±åº¦åƒæ•¸ {param} æ™‚å‡ºç¾å•é¡Œ: {e}")
                    # ç”Ÿæˆè™›æ“¬æ•¸æ“šä½œç‚ºå‚™ç”¨
                    n_samples = self.mcmc_config.n_samples * self.mcmc_config.n_chains
                    if param == 'vulnerability_params':
                        # å¤šç¶­åƒæ•¸
                        n_params = self._get_vulnerability_param_count()
                        posterior_samples[param] = np.random.normal(0, 1, (n_samples, n_params))
                    else:
                        posterior_samples[param] = np.random.normal(0, 1, n_samples)
        
        return posterior_samples
    
    def _fit_vulnerability_simplified(self, vulnerability_data: VulnerabilityData) -> HierarchicalModelResult:
        """ç°¡åŒ–ç‰ˆæœ¬çš„è„†å¼±åº¦éšå±¤æ¨¡å‹æ“¬åˆ"""
        print("  âš¡ ä½¿ç”¨ç°¡åŒ–ç‰ˆè„†å¼±åº¦éšå±¤æ¨¡å‹...")
        
        hazard = vulnerability_data.hazard_intensities
        exposure = vulnerability_data.exposure_values
        losses = vulnerability_data.observed_losses
        n_obs = len(hazard)
        
        # æ ¹æ“šäº‹å‰æƒ…å¢ƒèª¿æ•´åƒæ•¸
        hyperparams = self._get_vulnerability_hyperparameters()
        
        # ç”Ÿæˆæ¨¡æ“¬å¾Œé©—æ¨£æœ¬
        n_total_samples = self.mcmc_config.n_samples * self.mcmc_config.n_chains
        
        # ç°¡åŒ–çš„å¾Œé©—æ¡æ¨£
        np.random.seed(self.mcmc_config.random_seed)
        
        alpha_samples = np.random.normal(
            hyperparams['alpha_mu'], 
            hyperparams['alpha_sigma'], 
            n_total_samples
        )
        
        beta_sigma_samples = np.abs(np.random.normal(
            0, hyperparams['beta_sigma'], n_total_samples
        ))
        
        # è„†å¼±åº¦åƒæ•¸
        n_vuln_params = self._get_vulnerability_param_count()
        vulnerability_params_samples = np.random.normal(
            0, 1, (n_total_samples, n_vuln_params)
        )
        
        tau_samples = np.abs(np.random.normal(0, hyperparams['tau_sigma'], n_total_samples))
        
        # ç°¡åŒ–çš„æœŸæœ›æå¤±è¨ˆç®—
        loss_mean = np.mean(losses)
        expected_loss_samples = np.random.normal(loss_mean, np.std(losses), n_total_samples)
        
        posterior_samples = {
            "alpha": alpha_samples,
            "beta_sigma": beta_sigma_samples,
            "vulnerability_params": vulnerability_params_samples,
            "tau": tau_samples,
            "expected_loss": expected_loss_samples
        }
        
        # ç°¡åŒ–çš„è¨ºæ–·
        diagnostics = DiagnosticResult(
            rhat={k: 1.0 for k in posterior_samples.keys()},
            ess_bulk={k: len(v) if isinstance(v, np.ndarray) and v.ndim == 1 else len(v) 
                     for k, v in posterior_samples.items()},
            ess_tail={k: len(v) if isinstance(v, np.ndarray) and v.ndim == 1 else len(v) 
                     for k, v in posterior_samples.items()},
            mcse={k: np.std(v)/np.sqrt(len(v)) if isinstance(v, np.ndarray) and v.ndim == 1 
                     else 0.01 for k, v in posterior_samples.items()}
        )
        
        # ç”Ÿæˆæ‘˜è¦
        posterior_summary = self._generate_posterior_summary(posterior_samples, diagnostics)
        
        # æ‡‰ç”¨MPE
        mpe_results = None
        if self.use_mpe:
            mpe_results = self._apply_mpe_to_posterior(posterior_samples)
        
        # ç°¡åŒ–çš„æ¨¡å‹è©•ä¼°
        from scipy import stats
        log_likelihood = np.sum(stats.norm.logpdf(losses, loss_mean, np.std(losses)))
        dic = -2 * log_likelihood + 2 * n_vuln_params
        waic = dic  # ç°¡åŒ–
        
        result = HierarchicalModelResult(
            model_spec=self.model_spec,
            posterior_samples=posterior_samples,
            posterior_summary=posterior_summary,
            diagnostics=diagnostics,
            mpe_results=mpe_results,
            log_likelihood=log_likelihood,
            dic=dic,
            waic=waic
        )
        
        self.last_result = result
        self.fit_history.append(result)
        
        print("âœ… ç°¡åŒ–è„†å¼±åº¦éšå±¤æ¨¡å‹æ“¬åˆå®Œæˆ")
        return result
    
    def _extract_posterior_samples(self, trace) -> Dict[str, np.ndarray]:
        """å¾PyMC traceä¸­æå–å¾Œé©—æ¨£æœ¬"""
        posterior_samples = {}
        
        # ä¸»è¦åƒæ•¸åˆ—è¡¨
        param_names = ['alpha', 'beta', 'phi', 'tau', 'theta', 'sigma_obs']
        
        # å¦‚æœæ˜¯Student-tï¼Œä¹ŸåŒ…å«nu
        if self.model_spec.likelihood_family == LikelihoodFamily.STUDENT_T:
            param_names.append('nu')
        
        for param in param_names:
            if param in trace.posterior.data_vars:
                try:
                    param_data = trace.posterior[param].values.flatten()
                    posterior_samples[param] = param_data
                except Exception as e:
                    print(f"    âš ï¸ æå–åƒæ•¸ {param} æ™‚å‡ºç¾å•é¡Œ: {e}")
                    # ç”Ÿæˆè™›æ“¬æ•¸æ“šä½œç‚ºå‚™ç”¨
                    n_samples = self.mcmc_config.n_samples * self.mcmc_config.n_chains
                    posterior_samples[param] = np.random.normal(0, 1, n_samples)
        
        return posterior_samples
    
    def _compute_diagnostics(self, trace) -> DiagnosticResult:
        """è¨ˆç®—MCMCè¨ºæ–·çµ±è¨ˆ"""
        diagnostics = DiagnosticResult()
        
        try:
            # R-hatçµ±è¨ˆ
            rhat_result = az.rhat(trace)
            if hasattr(rhat_result, 'to_dict'):
                diagnostics.rhat = {k: float(v) for k, v in rhat_result.to_dict()['data_vars'].items()}
            else:
                diagnostics.rhat = {k: float(v) for k, v in dict(rhat_result).items()}
            
            # Effective sample size
            ess_bulk = az.ess(trace, method='bulk')
            if hasattr(ess_bulk, 'to_dict'):
                diagnostics.ess_bulk = {k: float(v) for k, v in ess_bulk.to_dict()['data_vars'].items()}
            else:
                diagnostics.ess_bulk = {k: float(v) for k, v in dict(ess_bulk).items()}
            
            ess_tail = az.ess(trace, method='tail')
            if hasattr(ess_tail, 'to_dict'):
                diagnostics.ess_tail = {k: float(v) for k, v in ess_tail.to_dict()['data_vars'].items()}
            else:
                diagnostics.ess_tail = {k: float(v) for k, v in dict(ess_tail).items()}
            
            # MCSE (Monte Carlo Standard Error)
            mcse_result = az.mcse(trace)
            if hasattr(mcse_result, 'to_dict'):
                diagnostics.mcse = {k: float(v) for k, v in mcse_result.to_dict()['data_vars'].items()}
            else:
                diagnostics.mcse = {k: float(v) for k, v in dict(mcse_result).items()}
            
            # Divergent transitions
            if hasattr(trace, 'sample_stats') and 'diverging' in trace.sample_stats:
                diagnostics.n_divergent = int(trace.sample_stats.diverging.sum())
            
        except Exception as e:
            print(f"    âš ï¸ è¨ºæ–·è¨ˆç®—å¤±æ•—: {e}")
            # ä½¿ç”¨é è¨­å€¼
            param_names = ['alpha', 'beta', 'phi', 'tau', 'theta', 'sigma_obs']
            diagnostics.rhat = {p: 1.0 for p in param_names}
            diagnostics.ess_bulk = {p: 1000.0 for p in param_names}
            diagnostics.ess_tail = {p: 1000.0 for p in param_names}
            diagnostics.mcse = {p: 0.01 for p in param_names}
        
        return diagnostics
    
    def _generate_posterior_summary(self, 
                                  posterior_samples: Dict[str, np.ndarray],
                                  diagnostics: DiagnosticResult) -> pd.DataFrame:
        """ç”Ÿæˆå¾Œé©—æ‘˜è¦è¡¨"""
        summary_data = []
        
        for param_name, samples in posterior_samples.items():
            if isinstance(samples, np.ndarray) and samples.ndim == 1:
                summary_data.append({
                    "Parameter": param_name,
                    "Mean": np.mean(samples),
                    "Std": np.std(samples),
                    "2.5%": np.percentile(samples, 2.5),
                    "25%": np.percentile(samples, 25),
                    "50%": np.percentile(samples, 50),
                    "75%": np.percentile(samples, 75),
                    "97.5%": np.percentile(samples, 97.5),
                    "R-hat": diagnostics.rhat.get(param_name, np.nan),
                    "ESS_bulk": diagnostics.ess_bulk.get(param_name, np.nan),
                    "ESS_tail": diagnostics.ess_tail.get(param_name, np.nan),
                    "MCSE": diagnostics.mcse.get(param_name, np.nan)
                })
        
        return pd.DataFrame(summary_data)
    
    def _apply_mpe_to_posterior(self, 
                               posterior_samples: Dict[str, np.ndarray]) -> Dict[str, MPEResult]:
        """å°å¾Œé©—æ¨£æœ¬æ‡‰ç”¨æ··åˆé æ¸¬ä¼°è¨ˆ"""
        mpe_results = {}
        
        for param_name, samples in posterior_samples.items():
            if isinstance(samples, np.ndarray) and samples.ndim == 1:
                try:
                    print(f"    æ‡‰ç”¨MPEè‡³åƒæ•¸ {param_name}...")
                    mpe_result = self.mpe.fit_mixture(samples, "normal", n_components=2)
                    mpe_results[param_name] = mpe_result
                except Exception as e:
                    print(f"    âš ï¸ MPEæ“¬åˆå¤±æ•— for {param_name}: {e}")
        
        return mpe_results
    
    def _compute_model_evaluation(self, trace, observations: np.ndarray) -> Tuple[float, float, float]:
        """è¨ˆç®—æ¨¡å‹è©•ä¼°æŒ‡æ¨™"""
        try:
            # å˜—è©¦å¾traceä¸­æå–å°æ•¸ä¼¼ç„¶
            if hasattr(trace, 'sample_stats') and 'lp' in trace.sample_stats:
                lp_data = trace.sample_stats.lp
                if hasattr(lp_data, 'values'):
                    log_likelihood = float(np.mean(lp_data.values))
                else:
                    log_likelihood = float(np.mean(np.array(lp_data)))
            else:
                # ç°¡åŒ–ä¼°ç®—
                log_likelihood = -0.5 * len(observations) * np.log(2 * np.pi * np.var(observations))
            
            # è¨ˆç®—DICå’ŒWAIC (ç°¡åŒ–ç‰ˆæœ¬)
            n_params = 6  # ä¼°è¨ˆåƒæ•¸æ•¸é‡
            dic = -2 * log_likelihood + 2 * n_params
            waic = dic  # ç°¡åŒ–
            
            return log_likelihood, dic, waic
            
        except Exception as e:
            print(f"    âš ï¸ æ¨¡å‹è©•ä¼°è¨ˆç®—å¤±æ•—: {e}")
            return np.nan, np.nan, np.nan
    
    def predict(self, 
                n_predictions: int = 1000,
                use_mpe: bool = True) -> np.ndarray:
        """
        ç”Ÿæˆé æ¸¬æ¨£æœ¬
        
        Parameters:
        -----------
        n_predictions : int
            é æ¸¬æ¨£æœ¬æ•¸é‡
        use_mpe : bool
            æ˜¯å¦ä½¿ç”¨MPEç”Ÿæˆé æ¸¬
            
        Returns:
        --------
        np.ndarray
            é æ¸¬æ¨£æœ¬
        """
        if self.last_result is None:
            raise ValueError("éœ€è¦å…ˆæ“¬åˆæ¨¡å‹")
        
        if use_mpe and self.last_result.mpe_results and 'theta' in self.last_result.mpe_results:
            # ä½¿ç”¨MPEç”Ÿæˆé æ¸¬
            print("ğŸ”® ä½¿ç”¨MPEç”Ÿæˆé æ¸¬æ¨£æœ¬...")
            theta_mpe = self.last_result.mpe_results['theta']
            predictions = self.mpe.sample_from_mixture(n_predictions, theta_mpe)
        else:
            # ä½¿ç”¨åŸå§‹å¾Œé©—æ¨£æœ¬
            print("ğŸ”® ä½¿ç”¨å¾Œé©—æ¨£æœ¬ç”Ÿæˆé æ¸¬...")
            theta_samples = self.last_result.posterior_samples['theta']
            np.random.seed(self.mcmc_config.random_seed)
            indices = np.random.choice(len(theta_samples), n_predictions, replace=True)
            predictions = theta_samples[indices]
        
        return predictions
    
    def compare_with_alternative_spec(self, 
                                    observations: np.ndarray,
                                    alternative_spec: ModelSpec) -> Dict[str, Any]:
        """
        èˆ‡å¦ä¸€å€‹æ¨¡å‹è¦æ ¼é€²è¡Œæ¯”è¼ƒ
        
        Parameters:
        -----------
        observations : np.ndarray
            è§€æ¸¬æ•¸æ“š
        alternative_spec : ModelSpec
            æ›¿ä»£æ¨¡å‹è¦æ ¼
            
        Returns:
        --------
        Dict[str, Any]
            æ¨¡å‹æ¯”è¼ƒçµæœ
        """
        # æ“¬åˆç•¶å‰æ¨¡å‹ (å¦‚æœé‚„æ²’æœ‰)
        if self.last_result is None:
            current_result = self.fit(observations)
        else:
            current_result = self.last_result
        
        # æ“¬åˆæ›¿ä»£æ¨¡å‹
        alternative_model = ParametricHierarchicalModel(alternative_spec, self.mcmc_config, self.use_mpe)
        alternative_result = alternative_model.fit(observations)
        
        # æ¯”è¼ƒçµæœ
        comparison = {
            "current_model": {
                "spec": current_result.model_spec,
                "log_likelihood": current_result.log_likelihood,
                "dic": current_result.dic,
                "waic": current_result.waic,
                "convergence": current_result.diagnostics.convergence_summary()["overall_convergence"]
            },
            "alternative_model": {
                "spec": alternative_result.model_spec,
                "log_likelihood": alternative_result.log_likelihood,
                "dic": alternative_result.dic,
                "waic": alternative_result.waic,
                "convergence": alternative_result.diagnostics.convergence_summary()["overall_convergence"]
            }
        }
        
        # åˆ¤å®šå“ªå€‹æ¨¡å‹æ›´å¥½ (åŸºæ–¼DIC)
        if not np.isnan(current_result.dic) and not np.isnan(alternative_result.dic):
            if current_result.dic < alternative_result.dic:
                comparison["better_model"] = "current"
                comparison["dic_difference"] = alternative_result.dic - current_result.dic
            else:
                comparison["better_model"] = "alternative"  
                comparison["dic_difference"] = current_result.dic - alternative_result.dic
        else:
            comparison["better_model"] = "inconclusive"
            comparison["dic_difference"] = np.nan
        
        return comparison

# ä¾¿åˆ©å‡½æ•¸
def create_model_spec(likelihood: str = "normal", 
                     prior: str = "weak_informative") -> ModelSpec:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå‰µå»ºæ¨¡å‹è¦æ ¼
    
    Parameters:
    -----------
    likelihood : str
        æ¦‚ä¼¼å‡½æ•¸é¡å‹
    prior : str
        äº‹å‰æƒ…å¢ƒ
        
    Returns:
    --------
    ModelSpec
        æ¨¡å‹è¦æ ¼
    """
    return ModelSpec(
        likelihood_family=LikelihoodFamily(likelihood),
        prior_scenario=PriorScenario(prior)
    )

def quick_fit(observations: Union[np.ndarray, List[float]], 
             likelihood: str = "normal",
             prior: str = "weak_informative",
             n_samples: int = 500) -> HierarchicalModelResult:
    """
    ä¾¿åˆ©å‡½æ•¸ï¼šå¿«é€Ÿæ¨¡å‹æ“¬åˆ
    
    Parameters:
    -----------
    observations : np.ndarray or List[float]
        è§€æ¸¬æ•¸æ“š
    likelihood : str
        æ¦‚ä¼¼å‡½æ•¸é¡å‹
    prior : str  
        äº‹å‰æƒ…å¢ƒ
    n_samples : int
        MCMCæ¨£æœ¬æ•¸
        
    Returns:
    --------
    HierarchicalModelResult
        æ“¬åˆçµæœ
    """
    model_spec = create_model_spec(likelihood, prior)
    mcmc_config = MCMCConfig(n_samples=n_samples, n_warmup=n_samples//2)
    
    model = ParametricHierarchicalModel(model_spec, mcmc_config)
    return model.fit(observations)

# æ¸¬è©¦å‡½æ•¸
def test_parametric_hierarchical_model():
    """æ¸¬è©¦åƒæ•¸åŒ–éšå±¤æ¨¡å‹åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦åƒæ•¸åŒ–éšå±¤è²æ°æ¨¡å‹...")
    
    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    true_theta = 5.0
    true_sigma = 2.0
    test_data = np.random.normal(true_theta, true_sigma, 100)
    
    print(f"\næ¸¬è©¦æ•¸æ“š: å‡å€¼={np.mean(test_data):.3f}, æ¨™æº–å·®={np.std(test_data):.3f}")
    
    # æ¸¬è©¦ä¸åŒçš„æ¨¡å‹é…ç½®
    test_configs = [
        ("normal", "weak_informative"),
        ("normal", "pessimistic"),
        ("lognormal", "optimistic"),
        ("student_t", "conservative")
    ]
    
    results = {}
    
    for likelihood, prior in test_configs:
        print(f"\nğŸ” æ¸¬è©¦é…ç½®: {likelihood} + {prior}")
        
        try:
            if likelihood == "lognormal":
                # å°æ–¼LogNormalï¼Œä½¿ç”¨æ­£å€¼æ•¸æ“š
                positive_data = np.abs(test_data) + 0.1
                result = quick_fit(positive_data, likelihood, prior, n_samples=200)
            else:
                result = quick_fit(test_data, likelihood, prior, n_samples=200)
            
            results[(likelihood, prior)] = result
            
            print("  å¾Œé©—æ‘˜è¦:")
            print(result.posterior_summary[['Parameter', 'Mean', 'Std', '2.5%', '97.5%']])
            
            convergence = result.diagnostics.convergence_summary()
            print(f"  æ”¶æ–‚ç‹€æ…‹: {convergence['overall_convergence']}")
            print(f"  DIC: {result.dic:.2f}")
            
        except Exception as e:
            print(f"  âš ï¸ æ¸¬è©¦å¤±æ•—: {e}")
    
    print(f"\nâœ… æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸæ¸¬è©¦äº† {len(results)} å€‹é…ç½®")
    return results

def test_vulnerability_modeling():
    """æ¸¬è©¦æ–°çš„è„†å¼±åº¦å»ºæ¨¡åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦è„†å¼±åº¦å»ºæ¨¡åŠŸèƒ½...")
    
    # ç”Ÿæˆæ¨¡æ“¬ç½å®³-æå¤±æ•¸æ“š
    np.random.seed(42)
    n_events = 50
    
    # æ¨¡æ“¬é¢±é¢¨é¢¨é€Ÿ (m/s)
    wind_speeds = np.random.uniform(20, 80, n_events)  
    
    # æ¨¡æ“¬å»ºç¯‰æš´éšªå€¼ (USD)
    building_values = np.random.uniform(1e6, 1e8, n_events)
    
    # ä½¿ç”¨ç°¡å–®çš„è„†å¼±åº¦é—œä¿‚ç”Ÿæˆ"çœŸå¯¦"æå¤±
    # V = 0.001 Ã— (max(H-25, 0))^2 (ç°¡åŒ–Emanuelå½¢å¼)
    true_vulnerability = 0.001 * np.maximum(wind_speeds - 25, 0)**2
    true_losses = building_values * true_vulnerability
    
    # æ·»åŠ è§€æ¸¬å™ªè²
    noise_factor = 0.2
    observed_losses = true_losses * (1 + np.random.normal(0, noise_factor, n_events))
    observed_losses = np.maximum(observed_losses, 0)  # ç¢ºä¿éè² 
    
    print(f"\næ¨¡æ“¬æ•¸æ“šæ‘˜è¦:")
    print(f"   é¢¨é€Ÿç¯„åœ: {wind_speeds.min():.1f} - {wind_speeds.max():.1f} m/s")
    print(f"   å»ºç¯‰åƒ¹å€¼ç¯„åœ: ${building_values.min():.2e} - ${building_values.max():.2e}")
    print(f"   æå¤±ç¯„åœ: ${observed_losses.min():.2e} - ${observed_losses.max():.2e}")
    
    # å‰µå»ºè„†å¼±åº¦æ•¸æ“šçµæ§‹
    vulnerability_data = VulnerabilityData(
        hazard_intensities=wind_speeds,
        exposure_values=building_values,
        observed_losses=observed_losses
    )
    
    # æ¸¬è©¦ä¸åŒçš„è„†å¼±åº¦å‡½æ•¸
    test_configs = [
        ("lognormal", "weak_informative", "emanuel"),
        ("normal", "optimistic", "linear"),
        ("student_t", "pessimistic", "polynomial")
    ]
    
    results = {}
    
    for likelihood, prior, vuln_func in test_configs:
        print(f"\nğŸ” æ¸¬è©¦é…ç½®: {likelihood} + {prior} + {vuln_func}")
        
        try:
            # å‰µå»ºæ¨¡å‹è¦æ ¼
            model_spec = ModelSpec(
                likelihood_family=LikelihoodFamily(likelihood),
                prior_scenario=PriorScenario(prior),
                vulnerability_type=VulnerabilityFunctionType(vuln_func)
            )
            
            # å‰µå»ºæ¨¡å‹ä¸¦æ“¬åˆ
            model = ParametricHierarchicalModel(
                model_spec, 
                MCMCConfig(n_samples=200, n_warmup=100, n_chains=2)
            )
            
            result = model.fit(vulnerability_data)
            results[(likelihood, prior, vuln_func)] = result
            
            print("  å¾Œé©—æ‘˜è¦ï¼ˆè„†å¼±åº¦åƒæ•¸ï¼‰:")
            if 'vulnerability_params' in result.posterior_samples:
                vuln_params = result.posterior_samples['vulnerability_params']
                if isinstance(vuln_params, np.ndarray):
                    if vuln_params.ndim == 2:
                        for i in range(vuln_params.shape[1]):
                            mean_val = np.mean(vuln_params[:, i])
                            std_val = np.std(vuln_params[:, i])
                            print(f"     åƒæ•¸{i}: {mean_val:.4f} Â± {std_val:.4f}")
                    else:
                        mean_val = np.mean(vuln_params)
                        std_val = np.std(vuln_params)
                        print(f"     åƒæ•¸: {mean_val:.4f} Â± {std_val:.4f}")
            
            convergence = result.diagnostics.convergence_summary()
            print(f"  æ”¶æ–‚ç‹€æ…‹: {convergence['overall_convergence']}")
            print(f"  DIC: {result.dic:.2f}")
            
        except Exception as e:
            print(f"  âš ï¸ è„†å¼±åº¦å»ºæ¨¡æ¸¬è©¦å¤±æ•—: {e}")
    
    print(f"\nâœ… è„†å¼±åº¦å»ºæ¨¡æ¸¬è©¦å®Œæˆï¼ŒæˆåŠŸæ¸¬è©¦äº† {len(results)} å€‹é…ç½®")
    return results

if __name__ == "__main__":
    print("=== å‚³çµ±éšå±¤æ¨¡å‹æ¸¬è©¦ ===")
    traditional_results = test_parametric_hierarchical_model()
    
    print("\n" + "="*50)
    print("=== è„†å¼±åº¦å»ºæ¨¡æ¸¬è©¦ ===")
    vulnerability_results = test_vulnerability_modeling()