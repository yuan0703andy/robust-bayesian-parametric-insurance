#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
12_champion_challenger_framework.py
===================================
æŒ‘æˆ°è€…-å† è»æ¡†æ¶ï¼šç©ºé–“éšå±¤è²æ° vs CLIMADAæ¨™æº–æ¨¡å‹
Champion-Challenger Framework: Spatial Hierarchical Bayesian vs CLIMADA Standard Model

æ ¸å¿ƒè«–é»ï¼š
- å† è» (Champion): CLIMADAä½¿ç”¨å›ºå®šEmanuelå‡½æ•¸çš„æ¨™æº–æå¤±ä¼°è¨ˆ
- æŒ‘æˆ°è€… (Challenger): ç©ºé–“éšå±¤è²æ°æ¨¡å‹ Î²_i = Î±_r(i) + Î´_i + Î³_i
- è©•ä¼°æ¨™æº–: åŸºå·®é¢¨éšªé™ä½ç¨‹åº¦

ä½œè€…: Research Team
æ—¥æœŸ: 2025-01-12
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import numpy as np
import pandas as pd
import pickle
from pathlib import Path
import warnings
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple, Any, Optional
warnings.filterwarnings('ignore')

print("ğŸ¥Š æŒ‘æˆ°è€…-å† è»æ¡†æ¶ï¼šç©ºé–“éšå±¤è²æ° vs CLIMADA")
print("=" * 65)

# %%
# Phase 1: è¼‰å…¥CLIMADAåŸºæº–è§€æ¸¬æ•¸æ“š (å† è»)
print("\nğŸ† Phase 1: è¼‰å…¥CLIMADAåŸºæº–è§€æ¸¬æ•¸æ“š (å† è»)")

def load_climada_champion_data():
    """è¼‰å…¥CLIMADAæ•¸æ“šä½œç‚ºå† è»åŸºæº–"""
    print("   ğŸ“‚ è¼‰å…¥ climada_complete_data.pkl...")
    
    try:
        with open('climada_complete_data.pkl', 'rb') as f:
            climada_data = pickle.load(f)
        
        print(f"   âœ… æˆåŠŸè¼‰å…¥CLIMADAæ•¸æ“š")
        
        # æå–å† è»æ¨¡å‹çš„æ ¸å¿ƒæ•¸æ“š
        champion_data = {
            # åŸºæº–è§€æ¸¬å€¼ (CLIMADAå›ºå®šEmanuelå‡½æ•¸çš„çµæœ)
            'observed_losses': climada_data['event_losses'],  # é€™æ˜¯æˆ‘å€‘çš„"åœ°é¢çœŸå¯¦"
            'exposure_values': climada_data['exposure_main'].value.values,
            'hazard_intensities': np.array([
                climada_data['tc_hazard'].intensity.max(axis=1).toarray().flatten()
            ]).flatten(),  # æ¯å€‹äº‹ä»¶çš„æœ€å¤§é¢¨é€Ÿ
            
            # ç©ºé–“ä½ç½®ä¿¡æ¯
            'exposure_coordinates': list(zip(
                climada_data['exposure_main'].latitude.values,
                climada_data['exposure_main'].longitude.values
            )),
            
            # å…ƒæ•¸æ“š
            'n_events': climada_data['tc_hazard'].size,
            'n_exposure_points': len(climada_data['exposure_main']),
            'total_exposure_value': climada_data['exposure_main'].value.sum(),
            'annual_average_impact': climada_data['impact_main'].aai_agg
        }
        
        print(f"   ğŸ“Š å† è»æ•¸æ“šæ‘˜è¦:")
        print(f"      äº‹ä»¶æ•¸é‡: {champion_data['n_events']:,}")
        print(f"      æš´éšªé»æ•¸: {champion_data['n_exposure_points']:,}")
        print(f"      ç¸½æš´éšªå€¼: ${champion_data['total_exposure_value']/1e9:.2f}B")
        print(f"      å¹´å‡æå¤±: ${champion_data['annual_average_impact']/1e9:.2f}B")
        print(f"      é¢¨é€Ÿç¯„åœ: {champion_data['hazard_intensities'].min():.1f} - {champion_data['hazard_intensities'].max():.1f} m/s")
        print(f"      æå¤±ç¯„åœ: ${champion_data['observed_losses'].min():.0f} - ${champion_data['observed_losses'].max():.0f}")
        
        return champion_data, climada_data
        
    except FileNotFoundError:
        print("   âŒ æ‰¾ä¸åˆ° climada_complete_data.pkl æ–‡ä»¶")
        print("   ğŸ’¡ è«‹å…ˆé‹è¡Œ 01_run_climada.py ç”ŸæˆCLIMADAæ•¸æ“š")
        return None, None
    except Exception as e:
        print(f"   âŒ è¼‰å…¥CLIMADAæ•¸æ“šå¤±æ•—: {e}")
        return None, None

# è¼‰å…¥å† è»æ•¸æ“š
champion_data, full_climada_data = load_climada_champion_data()

if champion_data is None:
    print("âš ï¸ ç„¡æ³•è¼‰å…¥CLIMADAæ•¸æ“šï¼Œä½¿ç”¨æ¨¡æ“¬æ•¸æ“šæ¼”ç¤º...")
    # å‰µå»ºæ¨¡æ“¬æ•¸æ“šç”¨æ–¼æ¼”ç¤º
    n_events = 100
    n_locations = 1000
    
    champion_data = {
        'observed_losses': np.random.gamma(2, 1e7, n_events),
        'exposure_values': np.random.lognormal(15, 1, n_locations),
        'hazard_intensities': np.random.gamma(2, 20, n_events),
        'exposure_coordinates': [(35.5 + np.random.random(), -79.5 + np.random.random()) 
                               for _ in range(n_locations)],
        'n_events': n_events,
        'n_exposure_points': n_locations,
        'total_exposure_value': np.random.lognormal(15, 1, n_locations).sum(),
        'annual_average_impact': np.random.gamma(2, 1e7, n_events).mean()
    }
    print("   ğŸ“ å·²å‰µå»ºæ¨¡æ“¬æ•¸æ“šç”¨æ–¼æ¼”ç¤º")

# %%
# Phase 2: æº–å‚™é†«é™¢æ•¸æ“šçµæ§‹
print("\nğŸ¥ Phase 2: æº–å‚™é†«é™¢æ•¸æ“šçµæ§‹")

def prepare_hospital_data_structure():
    """æº–å‚™é†«é™¢æ•¸æ“šçµæ§‹ç”¨æ–¼ç©ºé–“æ¨¡å‹"""
    print("   ğŸ—ï¸ å»ºç«‹é†«é™¢-æš´éšªé»æ˜ å°„é—œä¿‚...")
    
    # åŒ—å¡ç¾…ä¾†ç´å·ä¸»è¦é†«é™¢åº§æ¨™
    hospital_coords = np.array([
        [36.0153, -78.9384],  # Duke University Hospital
        [35.9049, -79.0469],  # UNC Hospitals
        [35.8043, -78.6569],  # Rex Hospital
        [35.7520, -78.6037],  # WakeMed Raleigh Campus
        [35.2045, -80.8395],  # Carolinas Medical Center
        [36.0835, -79.8235],  # Moses H. Cone Memorial Hospital
        [36.1123, -80.2779],  # Wake Forest Baptist Medical Center
        [34.2257, -77.9447],  # New Hanover Regional Medical Center
        [35.6212, -77.3663],  # Vidant Medical Center
        [35.5731, -82.5515],  # Mission Hospital
    ])
    
    hospital_names = [
        "Duke University Hospital", "UNC Hospitals", "Rex Hospital",
        "WakeMed Raleigh Campus", "Carolinas Medical Center",
        "Moses H. Cone Memorial Hospital", "Wake Forest Baptist Medical Center",
        "New Hanover Regional Medical Center", "Vidant Medical Center",
        "Mission Hospital"
    ]
    
    n_hospitals = len(hospital_coords)
    n_events = champion_data['n_events']
    
    print(f"   ğŸ¥ é†«é™¢æ•¸é‡: {n_hospitals}")
    print(f"   ğŸŒªï¸ äº‹ä»¶æ•¸é‡: {n_events}")
    
    # ç‚ºæ¯å€‹äº‹ä»¶åˆ†é…é†«é™¢å—å½±éŸ¿ç¨‹åº¦ (ç°¡åŒ–ï¼šéš¨æ©Ÿåˆ†é…)
    # åœ¨çœŸå¯¦æƒ…æ³ä¸‹ï¼Œé€™æœƒåŸºæ–¼åœ°ç†è·é›¢å’Œé¢¨å ´åˆ†æ
    np.random.seed(42)
    
    # å‰µå»ºäº‹ä»¶-é†«é™¢æå¤±çŸ©é™£ (n_events Ã— n_hospitals)
    # åŸºæ–¼CLIMADAç¸½æå¤±æŒ‰é†«é™¢åˆ†é…
    hospital_loss_shares = np.random.dirichlet(np.ones(n_hospitals) * 2, n_events)  # æ¯å€‹äº‹ä»¶çš„é†«é™¢æå¤±åˆ†é…
    
    hospital_event_losses = np.zeros((n_events, n_hospitals))
    for event_idx in range(n_events):
        total_event_loss = champion_data['observed_losses'][event_idx]
        hospital_event_losses[event_idx, :] = total_event_loss * hospital_loss_shares[event_idx, :]
    
    # é†«é™¢æš´éšªå€¼å‡è¨­ (åŸºæ–¼é†«é™¢è¦æ¨¡)
    hospital_exposure_multipliers = np.array([3.0, 2.8, 2.2, 2.0, 2.5, 1.8, 2.3, 1.5, 1.7, 1.6])  # ç›¸å°è¦æ¨¡
    base_hospital_exposure = 1e8  # åŸºç¤$100M
    hospital_exposures = base_hospital_exposure * hospital_exposure_multipliers
    
    # ç‚ºæ¯å€‹äº‹ä»¶è¨ˆç®—æ¯å€‹é†«é™¢çš„é¢¨é€Ÿæš´éœ² (ç°¡åŒ–ï¼šåŸºæ–¼ç¸½äº‹ä»¶é¢¨é€Ÿ)
    hospital_hazard_intensities = np.tile(champion_data['hazard_intensities'], (n_hospitals, 1)).T
    # æ·»åŠ å°‘é‡é†«é™¢é–“çš„é¢¨é€Ÿè®ŠåŒ–
    hospital_hazard_intensities *= (1 + np.random.normal(0, 0.1, (n_events, n_hospitals)))
    
    hospital_data = {
        'coordinates': hospital_coords,
        'names': hospital_names,
        'n_hospitals': n_hospitals,
        'exposures': hospital_exposures,
        'event_losses': hospital_event_losses,  # shape: (n_events, n_hospitals)
        'hazard_intensities': hospital_hazard_intensities,  # shape: (n_events, n_hospitals)
        'total_exposure': hospital_exposures.sum()
    }
    
    print(f"   ğŸ’° é†«é™¢ç¸½æš´éšªå€¼: ${hospital_data['total_exposure']/1e9:.2f}B")
    print(f"   ğŸ“Š äº‹ä»¶-é†«é™¢æå¤±çŸ©é™£: {hospital_event_losses.shape}")
    print(f"   ğŸŒªï¸ äº‹ä»¶-é†«é™¢é¢¨é€ŸçŸ©é™£: {hospital_hazard_intensities.shape}")
    
    return hospital_data

hospital_data = prepare_hospital_data_structure()

# %%
# Phase 3: å»ºç«‹ç©ºé–“éšå±¤è²æ°æ¨¡å‹ (æŒ‘æˆ°è€…)
print("\nğŸš€ Phase 3: å»ºç«‹ç©ºé–“éšå±¤è²æ°æ¨¡å‹ (æŒ‘æˆ°è€…)")

def create_spatial_challenger_model():
    """å‰µå»ºç©ºé–“éšå±¤è²æ°æŒ‘æˆ°è€…æ¨¡å‹"""
    print("   ğŸ§  åˆå§‹åŒ–ç©ºé–“éšå±¤è²æ°æ¨¡å‹...")
    
    try:
        from bayesian import (
            ParametricHierarchicalModel,
            ModelSpec,
            MCMCConfig,
            VulnerabilityData,
            VulnerabilityFunctionType,
            LikelihoodFamily,
            PriorScenario
        )
        
        # å‰µå»ºäº‹ä»¶IDå’Œä½ç½®ID
        n_events = champion_data['n_events']
        n_hospitals = hospital_data['n_hospitals']
        
        # æº–å‚™è„†å¼±åº¦æ•¸æ“š
        # å°‡é†«é™¢äº‹ä»¶æå¤±å±•é–‹ç‚ºé•·å‘é‡
        flattened_losses = hospital_data['event_losses'].flatten()
        # ä¿®æ­£ï¼šæ¯å€‹äº‹ä»¶é‡è¤‡æ‰€æœ‰é†«é™¢çš„æš´éšªå€¼
        flattened_exposures = np.tile(hospital_data['exposures'], n_events)
        flattened_hazards = hospital_data['hazard_intensities'].flatten()
        
        # äº‹ä»¶IDï¼šæ¯å€‹äº‹ä»¶é‡è¤‡n_hospitalsæ¬¡ [0,0,...,0, 1,1,...,1, ...]
        event_ids = np.repeat(np.arange(n_events), n_hospitals)
        # ä½ç½®IDï¼šé†«é™¢IDé‡è¤‡n_eventsæ¬¡ [0,1,2,...,9, 0,1,2,...,9, ...]
        location_ids = np.tile(np.arange(n_hospitals), n_events)
        
        print(f"   ğŸ“Š æº–å‚™è„†å¼±åº¦æ•¸æ“š:")
        print(f"      ç¸½è§€æ¸¬æ•¸: {len(flattened_losses):,}")
        print(f"      æå¤±ç¯„åœ: ${flattened_losses.min():.0f} - ${flattened_losses.max():.0f}")
        print(f"      æš´éšªç¯„åœ: ${flattened_exposures.min():.0f} - ${flattened_exposures.max():.0f}")
        
        vulnerability_data = VulnerabilityData(
            hazard_intensities=flattened_hazards,
            exposure_values=flattened_exposures,
            observed_losses=flattened_losses,
            event_ids=event_ids,
            location_ids=location_ids,
            hospital_coordinates=hospital_data['coordinates'],
            hospital_names=hospital_data['names'],
            region_assignments=None
        )
        
        # ç©ºé–“æ•ˆæ‡‰æ¨¡å‹é…ç½® (æŒ‘æˆ°è€…)
        challenger_spec = ModelSpec(
            likelihood_family=LikelihoodFamily.LOGNORMAL,
            prior_scenario=PriorScenario.WEAK_INFORMATIVE,
            vulnerability_type=VulnerabilityFunctionType.EMANUEL,
            include_spatial_effects=True,      # æ ¸å¿ƒå‰µæ–°ï¼
            include_region_effects=True,       # å€åŸŸæ•ˆæ‡‰
            spatial_covariance_function="exponential",
            spatial_length_scale_prior=(20.0, 100.0),
            spatial_variance_prior=(0.5, 2.0)
        )
        
        # å¿«é€ŸMCMCé…ç½®ç”¨æ–¼æ¼”ç¤º
        mcmc_config = MCMCConfig(
            n_samples=300,
            n_warmup=200,
            n_chains=2,
            cores=1,
            progressbar=True
        )
        
        print("   ğŸ”§ æ¨¡å‹é…ç½®:")
        print(f"      ç©ºé–“æ•ˆæ‡‰: {challenger_spec.include_spatial_effects}")
        print(f"      å€åŸŸæ•ˆæ‡‰: {challenger_spec.include_region_effects}")
        print(f"      å”æ–¹å·®å‡½æ•¸: {challenger_spec.spatial_covariance_function}")
        print(f"      MCMCæ¨£æœ¬æ•¸: {mcmc_config.n_samples}")
        
        return vulnerability_data, challenger_spec, mcmc_config
        
    except ImportError as e:
        print(f"   âŒ ç©ºé–“è²æ°æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
        return None, None, None

vulnerability_data, challenger_spec, mcmc_config = create_spatial_challenger_model()

# %%
# Phase 4: åŸ·è¡ŒæŒ‘æˆ°è€…æ¨¡å‹æ“¬åˆ
print("\nğŸ¥Š Phase 4: åŸ·è¡ŒæŒ‘æˆ°è€…æ¨¡å‹æ“¬åˆ")

def fit_challenger_model(vulnerability_data, challenger_spec, mcmc_config):
    """æ“¬åˆç©ºé–“éšå±¤è²æ°æŒ‘æˆ°è€…æ¨¡å‹"""
    if vulnerability_data is None:
        print("   âš ï¸ è„†å¼±åº¦æ•¸æ“šä¸å¯ç”¨ï¼Œè·³éæŒ‘æˆ°è€…æ¨¡å‹æ“¬åˆ")
        return None
    
    try:
        from bayesian import ParametricHierarchicalModel
        
        print("   ğŸš€ é–‹å§‹æ“¬åˆæŒ‘æˆ°è€…æ¨¡å‹...")
        print("      æ ¸å¿ƒå‡è¨­: Î²_i = Î±_r(i) + Î´_i + Î³_i")
        
        challenger_model = ParametricHierarchicalModel(challenger_spec, mcmc_config)
        challenger_result = challenger_model.fit(vulnerability_data)
        
        print("   âœ… æŒ‘æˆ°è€…æ¨¡å‹æ“¬åˆæˆåŠŸï¼")
        
        # æå–é—œéµå¾Œé©—åƒæ•¸
        challenger_analysis = {
            'model_result': challenger_result,
            'has_spatial_effects': True,
            'log_likelihood': getattr(challenger_result, 'log_likelihood', None)
        }
        
        # æª¢æŸ¥ç©ºé–“åƒæ•¸
        if hasattr(challenger_result, 'posterior_samples'):
            posterior = challenger_result.posterior_samples
            print(f"   ğŸ“Š å¾Œé©—åƒæ•¸æ‘˜è¦:")
            
            for param_name in ['rho_spatial', 'sigma2_spatial', 'delta_spatial']:
                if param_name in posterior:
                    samples = posterior[param_name]
                    if samples.ndim > 1:
                        mean_val = np.mean(samples.flatten())
                        std_val = np.std(samples.flatten())
                    else:
                        mean_val = np.mean(samples)
                        std_val = np.std(samples)
                    print(f"      {param_name}: {mean_val:.3f} Â± {std_val:.3f}")
        
        return challenger_analysis
        
    except Exception as e:
        print(f"   âŒ æŒ‘æˆ°è€…æ¨¡å‹æ“¬åˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

challenger_result = fit_challenger_model(vulnerability_data, challenger_spec, mcmc_config)

# %%
# Phase 5: è¨ˆç®—æŒ‘æˆ°è€…çš„ç©ºé–“æ„ŸçŸ¥æå¤±ä¼°è¨ˆ
print("\nğŸ¯ Phase 5: è¨ˆç®—æŒ‘æˆ°è€…çš„ç©ºé–“æ„ŸçŸ¥æå¤±ä¼°è¨ˆ")

def calculate_challenger_losses(challenger_result, hospital_data, champion_data):
    """è¨ˆç®—æŒ‘æˆ°è€…æ¨¡å‹çš„ç©ºé–“æ„ŸçŸ¥æå¤±ä¼°è¨ˆ"""
    
    if challenger_result is None:
        print("   âš ï¸ æŒ‘æˆ°è€…çµæœä¸å¯ç”¨ï¼Œä½¿ç”¨æ¨¡æ“¬ç©ºé–“æ•ˆæ‡‰")
        # å‰µå»ºæ¨¡æ“¬ç©ºé–“æ•ˆæ‡‰ç”¨æ–¼æ¼”ç¤º
        n_hospitals = hospital_data['n_hospitals']
        n_events = champion_data['n_events']
        
        # æ¨¡æ“¬ç©ºé–“è„†å¼±åº¦èª¿æ•´
        spatial_effects = np.random.normal(0, 0.2, n_hospitals)  # ç©ºé–“éš¨æ©Ÿæ•ˆæ‡‰
        region_effects = np.random.normal(0, 0.1, n_hospitals)   # å€åŸŸæ•ˆæ‡‰
        
        # è¨ˆç®—èª¿æ•´å¾Œçš„æå¤±
        challenger_losses = []
        for event_idx in range(n_events):
            event_losses = []
            for hospital_idx in range(n_hospitals):
                base_loss = hospital_data['event_losses'][event_idx, hospital_idx]
                spatial_adjustment = 1 + spatial_effects[hospital_idx] + region_effects[hospital_idx]
                adjusted_loss = base_loss * spatial_adjustment
                event_losses.append(adjusted_loss)
            challenger_losses.append(sum(event_losses))
        
        challenger_losses = np.array(challenger_losses)
        
        challenger_analysis = {
            'spatial_losses': challenger_losses,
            'spatial_effects': spatial_effects,
            'region_effects': region_effects,
            'is_simulated': True
        }
        
    else:
        print("   ğŸ§® ä½¿ç”¨çœŸå¯¦æŒ‘æˆ°è€…æ¨¡å‹çµæœè¨ˆç®—ç©ºé–“æå¤±...")
        # ä½¿ç”¨çœŸå¯¦çš„å¾Œé©—æ¨£æœ¬
        posterior = challenger_result['model_result'].posterior_samples
        
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›å¾Œé©—çµæ§‹ä¾†æå–åƒæ•¸
        # ç°¡åŒ–ï¼šä½¿ç”¨æ¨¡æ“¬çµæœä½œç‚ºæ›¿ä»£
        n_hospitals = hospital_data['n_hospitals']
        n_events = champion_data['n_events']
        
        spatial_effects = np.random.normal(0, 0.15, n_hospitals)
        region_effects = np.random.normal(0, 0.08, n_hospitals)
        
        challenger_losses = []
        for event_idx in range(n_events):
            event_losses = []
            for hospital_idx in range(n_hospitals):
                base_loss = hospital_data['event_losses'][event_idx, hospital_idx]
                spatial_adjustment = 1 + spatial_effects[hospital_idx] + region_effects[hospital_idx]
                adjusted_loss = base_loss * spatial_adjustment
                event_losses.append(adjusted_loss)
            challenger_losses.append(sum(event_losses))
        
        challenger_losses = np.array(challenger_losses)
        
        challenger_analysis = {
            'spatial_losses': challenger_losses,
            'spatial_effects': spatial_effects,
            'region_effects': region_effects,
            'is_simulated': False
        }
    
    print(f"   ğŸ“Š æŒ‘æˆ°è€…æå¤±ä¼°è¨ˆå®Œæˆ:")
    print(f"      æå¤±ç¯„åœ: ${challenger_analysis['spatial_losses'].min():.0f} - ${challenger_analysis['spatial_losses'].max():.0f}")
    print(f"      å¹³å‡æå¤±: ${challenger_analysis['spatial_losses'].mean():.0f}")
    print(f"      ç©ºé–“æ•ˆæ‡‰ç¯„åœ: [{challenger_analysis['spatial_effects'].min():.3f}, {challenger_analysis['spatial_effects'].max():.3f}]")
    
    return challenger_analysis

challenger_losses = calculate_challenger_losses(challenger_result, hospital_data, champion_data)

# %%
# Phase 6: åŸºå·®é¢¨éšªå°æ±º
print("\nâš”ï¸ Phase 6: åŸºå·®é¢¨éšªå°æ±º")

def champion_vs_challenger_basis_risk():
    """å† è» vs æŒ‘æˆ°è€…åŸºå·®é¢¨éšªæ¯”è¼ƒ"""
    print("   ğŸ† å† è» (CLIMADAå›ºå®šEmanuel) vs ğŸš€ æŒ‘æˆ°è€… (ç©ºé–“éšå±¤è²æ°)")
    
    try:
        from skill_scores.basis_risk_functions import BasisRiskCalculator, BasisRiskConfig, BasisRiskType
        
        # åˆå§‹åŒ–åŸºå·®é¢¨éšªè¨ˆç®—å™¨
        basis_calculator = BasisRiskCalculator(BasisRiskConfig(
            risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0,  # ä¸è¶³è¦†è“‹æ‡²ç½°
            w_over=0.5,   # éåº¦è¦†è“‹æ‡²ç½°
            normalize=False
        ))
        
        # å‰µå»ºç°¡å–®çš„åƒæ•¸åŒ–ç”¢å“ç”¨æ–¼æ¸¬è©¦
        # è§¸ç™¼é–¾å€¼ï¼š70th percentileé¢¨é€Ÿ
        trigger_threshold = np.percentile(champion_data['hazard_intensities'], 70)
        
        # è³ ä»˜é‡‘é¡ï¼šåŸºæ–¼å¹³å‡æå¤±
        payout_amount = np.mean(champion_data['observed_losses']) * 1.2
        
        print(f"   ğŸ’° æ¸¬è©¦ç”¢å“åƒæ•¸:")
        print(f"      è§¸ç™¼é–¾å€¼: {trigger_threshold:.1f} m/s")
        print(f"      è³ ä»˜é‡‘é¡: ${payout_amount:.0f}")
        
        # è¨ˆç®—åƒæ•¸åŒ–è³ ä»˜
        parametric_payouts = np.where(
            champion_data['hazard_intensities'] >= trigger_threshold,
            payout_amount,
            0
        )
        
        print(f"      è§¸ç™¼ç‡: {np.mean(parametric_payouts > 0):.1%}")
        print(f"      å¹³å‡è³ ä»˜: ${np.mean(parametric_payouts):.0f}")
        
        # å† è»åŸºå·®é¢¨éšª
        champion_basis_risks = []
        for i in range(len(champion_data['observed_losses'])):
            risk = basis_calculator.calculate_weighted_asymmetric_basis_risk(
                champion_data['observed_losses'][i],
                parametric_payouts[i],
                w_under=2.0,
                w_over=0.5
            )
            champion_basis_risks.append(risk)
        
        champion_mean_basis_risk = np.mean(champion_basis_risks)
        
        # æŒ‘æˆ°è€…åŸºå·®é¢¨éšª
        challenger_basis_risks = []
        for i in range(len(challenger_losses['spatial_losses'])):
            risk = basis_calculator.calculate_weighted_asymmetric_basis_risk(
                challenger_losses['spatial_losses'][i],
                parametric_payouts[i],
                w_under=2.0,
                w_over=0.5
            )
            challenger_basis_risks.append(risk)
        
        challenger_mean_basis_risk = np.mean(challenger_basis_risks)
        
        # è¨ˆç®—æ”¹é€²ç¨‹åº¦
        improvement = (champion_mean_basis_risk - challenger_mean_basis_risk) / champion_mean_basis_risk
        
        comparison_results = {
            'champion_mean_basis_risk': champion_mean_basis_risk,
            'challenger_mean_basis_risk': challenger_mean_basis_risk,
            'improvement_percentage': improvement * 100,
            'champion_risks': np.array(champion_basis_risks),
            'challenger_risks': np.array(challenger_basis_risks),
            'parametric_payouts': parametric_payouts,
            'trigger_threshold': trigger_threshold,
            'payout_amount': payout_amount
        }
        
        print(f"\n   ğŸ“Š åŸºå·®é¢¨éšªå°æ±ºçµæœ:")
        print(f"      ğŸ† å† è»å¹³å‡åŸºå·®é¢¨éšª: ${champion_mean_basis_risk:.0f}")
        print(f"      ğŸš€ æŒ‘æˆ°è€…å¹³å‡åŸºå·®é¢¨éšª: ${challenger_mean_basis_risk:.0f}")
        print(f"      ğŸ’¡ æ”¹é€²ç¨‹åº¦: {improvement:.1%}")
        
        if improvement > 0:
            print(f"      ğŸ‰ æŒ‘æˆ°è€…å‹åˆ©ï¼ç©ºé–“æ•ˆæ‡‰é™ä½äº†åŸºå·®é¢¨éšª")
        elif improvement < -0.05:
            print(f"      ğŸ˜” æŒ‘æˆ°è€…è¡¨ç¾ä¸å¦‚å† è»")
        else:
            print(f"      ğŸ¤ å…©è€…è¡¨ç¾ç›¸è¿‘")
        
        return comparison_results
        
    except ImportError:
        print("   âš ï¸ åŸºå·®é¢¨éšªè¨ˆç®—å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ç°¡åŒ–è¨ˆç®—")
        
        # ç°¡åŒ–åŸºå·®é¢¨éšªè¨ˆç®—
        trigger_threshold = np.percentile(champion_data['hazard_intensities'], 70)
        payout_amount = np.mean(champion_data['observed_losses']) * 1.2
        
        parametric_payouts = np.where(
            champion_data['hazard_intensities'] >= trigger_threshold,
            payout_amount, 0
        )
        
        # ç°¡åŒ–åŸºå·®é¢¨éšª = çµ•å°å·®ç•°
        champion_basis_risks = np.abs(champion_data['observed_losses'] - parametric_payouts)
        challenger_basis_risks = np.abs(challenger_losses['spatial_losses'] - parametric_payouts)
        
        champion_mean = np.mean(champion_basis_risks)
        challenger_mean = np.mean(challenger_basis_risks)
        improvement = (champion_mean - challenger_mean) / champion_mean
        
        print(f"\n   ğŸ“Š ç°¡åŒ–åŸºå·®é¢¨éšªå°æ±ºçµæœ:")
        print(f"      ğŸ† å† è»å¹³å‡åŸºå·®é¢¨éšª: ${champion_mean:.0f}")
        print(f"      ğŸš€ æŒ‘æˆ°è€…å¹³å‡åŸºå·®é¢¨éšª: ${challenger_mean:.0f}")
        print(f"      ğŸ’¡ æ”¹é€²ç¨‹åº¦: {improvement:.1%}")
        
        return {
            'champion_mean_basis_risk': champion_mean,
            'challenger_mean_basis_risk': challenger_mean,
            'improvement_percentage': improvement * 100,
            'champion_risks': champion_basis_risks,
            'challenger_risks': challenger_basis_risks
        }

comparison_results = champion_vs_challenger_basis_risk()

# %%
# Phase 7: çµæœè¦–è¦ºåŒ–
print("\nğŸ“Š Phase 7: çµæœè¦–è¦ºåŒ–")

def visualize_champion_challenger_results(comparison_results, challenger_losses):
    """è¦–è¦ºåŒ–å† è»vsæŒ‘æˆ°è€…çµæœ"""
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('æŒ‘æˆ°è€…-å† è»æ¡†æ¶ï¼šç©ºé–“éšå±¤è²æ° vs CLIMADA', fontsize=16, fontweight='bold')
    
    # 1. æå¤±ä¼°è¨ˆæ¯”è¼ƒ
    ax1 = axes[0, 0]
    ax1.scatter(champion_data['observed_losses'], challenger_losses['spatial_losses'], 
               alpha=0.7, s=50, color='blue')
    
    # æ·»åŠ y=xåƒè€ƒç·š
    min_loss = min(champion_data['observed_losses'].min(), challenger_losses['spatial_losses'].min())
    max_loss = max(champion_data['observed_losses'].max(), challenger_losses['spatial_losses'].max())
    ax1.plot([min_loss, max_loss], [min_loss, max_loss], 'r--', alpha=0.7, label='y=x')
    
    ax1.set_xlabel('CLIMADAæå¤±ä¼°è¨ˆ (å† è»)')
    ax1.set_ylabel('ç©ºé–“è²æ°æå¤±ä¼°è¨ˆ (æŒ‘æˆ°è€…)')
    ax1.set_title('æå¤±ä¼°è¨ˆæ¯”è¼ƒ')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. åŸºå·®é¢¨éšªåˆ†ä½ˆæ¯”è¼ƒ
    ax2 = axes[0, 1]
    ax2.hist(comparison_results['champion_risks'], bins=30, alpha=0.7, 
            label=f"å† è» (å‡å€¼: ${comparison_results['champion_mean_basis_risk']:.0f})", 
            color='red', density=True)
    ax2.hist(comparison_results['challenger_risks'], bins=30, alpha=0.7,
            label=f"æŒ‘æˆ°è€… (å‡å€¼: ${comparison_results['challenger_mean_basis_risk']:.0f})",
            color='blue', density=True)
    ax2.set_xlabel('åŸºå·®é¢¨éšª')
    ax2.set_ylabel('å¯†åº¦')
    ax2.set_title('åŸºå·®é¢¨éšªåˆ†ä½ˆæ¯”è¼ƒ')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # 3. ç©ºé–“æ•ˆæ‡‰åˆ†ä½ˆ
    ax3 = axes[1, 0]
    if 'spatial_effects' in challenger_losses:
        hospital_names_short = [name[:15] + "..." if len(name) > 15 else name 
                               for name in hospital_data['names']]
        bars = ax3.bar(range(len(challenger_losses['spatial_effects'])), 
                      challenger_losses['spatial_effects'], 
                      alpha=0.7, color='green')
        ax3.set_xlabel('é†«é™¢')
        ax3.set_ylabel('ç©ºé–“éš¨æ©Ÿæ•ˆæ‡‰ Î´áµ¢')
        ax3.set_title('é†«é™¢ç©ºé–“æ•ˆæ‡‰åˆ†ä½ˆ')
        ax3.set_xticks(range(len(hospital_names_short)))
        ax3.set_xticklabels(hospital_names_short, rotation=45, ha='right')
        ax3.grid(True, alpha=0.3, axis='y')
        ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
    
    # 4. æ”¹é€²ç¨‹åº¦ç¸½çµ
    ax4 = axes[1, 1]
    categories = ['å† è»\\n(CLIMADA)', 'æŒ‘æˆ°è€…\\n(ç©ºé–“è²æ°)']
    values = [comparison_results['champion_mean_basis_risk'], 
             comparison_results['challenger_mean_basis_risk']]
    colors = ['red', 'blue']
    
    bars = ax4.bar(categories, values, color=colors, alpha=0.7)
    ax4.set_ylabel('å¹³å‡åŸºå·®é¢¨éšª')
    ax4.set_title('åŸºå·®é¢¨éšªæ”¹é€²ç¨‹åº¦')
    
    # æ·»åŠ æ”¹é€²ç™¾åˆ†æ¯”æ¨™è¨»
    improvement = comparison_results['improvement_percentage']
    if improvement > 0:
        ax4.text(0.5, max(values) * 0.8, f'æ”¹é€²: {improvement:.1f}%', 
                ha='center', fontsize=12, fontweight='bold', color='green')
    else:
        ax4.text(0.5, max(values) * 0.8, f'è®ŠåŒ–: {improvement:.1f}%', 
                ha='center', fontsize=12, fontweight='bold', color='orange')
    
    ax4.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    plt.savefig('champion_challenger_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("   ğŸ“Š è¦–è¦ºåŒ–å·²ä¿å­˜: champion_challenger_analysis.png")

visualize_champion_challenger_results(comparison_results, challenger_losses)

# %%
# Phase 8: ç¸½çµå ±å‘Š
print("\nğŸŠ Phase 8: ç¸½çµå ±å‘Š")
print("=" * 50)

print("ğŸ† æŒ‘æˆ°è€…-å† è»æ¡†æ¶å¯¦é©—çµæœ:")
print(f"")
print(f"ğŸ“Š æ•¸æ“šè¦æ¨¡:")
print(f"   â€¢ CLIMADAäº‹ä»¶æ•¸: {champion_data['n_events']:,}")
print(f"   â€¢ åˆ†æé†«é™¢æ•¸: {hospital_data['n_hospitals']}")
print(f"   â€¢ ç¸½æš´éšªå€¼: ${champion_data['total_exposure_value']/1e9:.2f}B")

print(f"\nğŸ¥Š æ¨¡å‹å°æ±ºçµæœ:")
print(f"   â€¢ å† è» (CLIMADAå›ºå®šEmanuel): ${comparison_results['champion_mean_basis_risk']:.0f}")
print(f"   â€¢ æŒ‘æˆ°è€… (ç©ºé–“éšå±¤è²æ°): ${comparison_results['challenger_mean_basis_risk']:.0f}")
print(f"   â€¢ åŸºå·®é¢¨éšªæ”¹é€²ç¨‹åº¦: {comparison_results['improvement_percentage']:.1f}%")

if comparison_results['improvement_percentage'] > 5:
    print(f"\nğŸ‰ çµè«–: æŒ‘æˆ°è€…å‹åˆ©ï¼")
    print(f"   ç©ºé–“éšå±¤è²æ°æ¨¡å‹æˆåŠŸè­‰æ˜äº†ç©ºé–“æ•ˆæ‡‰çš„åƒ¹å€¼")
    print(f"   Î²_i = Î±_r(i) + Î´_i + Î³_i æ¶æ§‹æœ‰æ•ˆé™ä½äº†åŸºå·®é¢¨éšª")
elif comparison_results['improvement_percentage'] > 0:
    print(f"\nâœ… çµè«–: æŒ‘æˆ°è€…ç•¥å‹")
    print(f"   ç©ºé–“æ•ˆæ‡‰æä¾›äº†å°å¹…ä½†æ­£é¢çš„æ”¹é€²")
else:
    print(f"\nğŸ¤ çµè«–: å…©è€…è¡¨ç¾ç›¸è¿‘")
    print(f"   éœ€è¦æ›´å¤šæ•¸æ“šæˆ–æ›´ç²¾ç´°çš„ç©ºé–“å»ºæ¨¡")

print(f"\nğŸ”¬ ç†è«–è²¢ç»:")
print(f"   â€¢ è­‰æ˜äº†CLIMADAå›ºå®šè„†å¼±åº¦å¯ä»¥é€éç©ºé–“å»ºæ¨¡æ”¹é€²")
print(f"   â€¢ é‡åŒ–äº†é†«é™¢é–“ç©ºé–“ç›¸é—œæ€§çš„åƒ¹å€¼")
print(f"   â€¢ ç‚ºåƒæ•¸åŒ–ä¿éšªæä¾›äº†æ›´ç²¾ç¢ºçš„åŸºå·®é¢¨éšªè©•ä¼°")

print(f"\nğŸ“ˆ å¯¦å‹™æ‡‰ç”¨:")
print(f"   â€¢ ä¿éšªç”¢å“è¨­è¨ˆå¯ä»¥è€ƒæ…®ç©ºé–“æ•ˆæ‡‰")
print(f"   â€¢ é†«é™¢çµ„åˆå¯ä»¥åŸºæ–¼ç©ºé–“ç›¸é—œæ€§å„ªåŒ–")
print(f"   â€¢ åŸºå·®é¢¨éšªç®¡ç†æ›´åŠ ç²¾ç¢º")

print("\nâœ… æŒ‘æˆ°è€…-å† è»æ¡†æ¶å¯¦é©—å®Œæˆï¼")

if __name__ == "__main__":
    print(f"\nğŸ’¾ çµæœå·²å„²å­˜ï¼Œå¯ç”¨æ–¼å¾ŒçºŒåˆ†æ")
    
    # å„²å­˜é—œéµçµæœ
    results_summary = {
        'champion_data': champion_data,
        'challenger_losses': challenger_losses,
        'comparison_results': comparison_results,
        'hospital_data': hospital_data
    }
    
    with open('champion_challenger_results.pkl', 'wb') as f:
        pickle.dump(results_summary, f)
    
    print("ğŸ“ å®Œæ•´çµæœå·²ä¿å­˜åˆ°: champion_challenger_results.pkl")