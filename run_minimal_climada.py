#!/usr/bin/env python3
"""
æœ€å°åŒ–CLIMADAæ•¸æ“šç”Ÿæˆ
Minimal CLIMADA Data Generation

å¾æˆåŠŸçš„nc_tc_comprehensive_functional.pyæå–æœ€æ ¸å¿ƒçš„æ•¸æ“šç”Ÿæˆä»£ç¢¼
ç›´æ¥åŸ·è¡Œï¼Œä¸åšè¤‡é›œçš„éŒ¯èª¤è™•ç†
"""

print("ğŸš€ æœ€å°åŒ–CLIMADAæ•¸æ“šç”Ÿæˆ")

# %% ç›´æ¥è¤‡è£½æˆåŠŸè…³æœ¬çš„å°å…¥å’Œè¨­ç½®
import os
import sys
import numpy as np
from datetime import datetime

# è¨­ç½®è·¯å¾‘ (è¤‡è£½è‡ªæˆåŠŸè…³æœ¬)
current_dir = os.path.dirname(os.path.abspath(__file__))
insurance_dir = os.path.join(current_dir, 'insurance_analysis_refactored')

for path in [insurance_dir, current_dir]:
    if path not in sys.path:
        sys.path.append(path)

print(f"âœ… è·¯å¾‘è¨­ç½®: {current_dir}")

# %% ç›´æ¥å°å…¥ (è¤‡è£½è‡ªæˆåŠŸè…³æœ¬)
print("ğŸ“¦ å°å…¥æ¨¡çµ„...")
from config.settings import NC_BOUNDS, YEAR_RANGE, RESOLUTION
from data_processing.track_processing import get_regional_tracks
from hazard_modeling.tc_hazard import create_tc_hazard
from exposure_modeling.litpop_processing import process_litpop_exposures
from exposure_modeling.hospital_osm_extraction import get_nc_hospitals
from impact_analysis.impact_calculation import calculate_tc_impact

print("âœ… æ¨¡çµ„å°å…¥å®Œæˆ")

# %% ç›´æ¥è¤‡è£½æ•¸æ“šç”Ÿæˆä»£ç¢¼
print("\nğŸŒªï¸ æº–å‚™CLIMADAçœŸå¯¦æ•¸æ“š...")

print("æ­£åœ¨æº–å‚™CLIMADAçœŸå¯¦æ•¸æ“š...")
# ç²å–è»Œè·¡æ•¸æ“š
print(f"   ğŸŒ€ ç›®æ¨™å€åŸŸ: North Carolina {NC_BOUNDS}")
print(f"   ğŸ“… åˆ†ææœŸé–“: {YEAR_RANGE[0]}-{YEAR_RANGE[1]}")

tracks = get_regional_tracks(NC_BOUNDS, YEAR_RANGE, nb_synth=3)
print(f"   âœ… ç²å– {len(tracks.data)} æ¢è»Œè·¡")

# å‰µå»ºç½å®³å ´
from hazard_modeling.centroids import create_hazard_centroids
centroids_lat, centroids_lon = create_hazard_centroids(NC_BOUNDS, RESOLUTION)
tc_hazard = create_tc_hazard(tracks, centroids_lat, centroids_lon)
print(f"   âœ… ç½å®³å ´: {tc_hazard.size} å€‹äº‹ä»¶")

# å‰µå»ºæ›éšª
exposure_dict, successful_years = process_litpop_exposures(
    country_iso="USA", state_name="North Carolina", years=[2020, 2019]
)

if successful_years:
    exposure_main = exposure_dict[successful_years[0]]
    print(f"   âœ… æ›éšªæ•¸æ“š: {len(exposure_main.gdf)} å€‹é»")
    print(f"   ğŸ’° ç¸½æ›éšªå€¼: ${exposure_main.value.sum()/1e9:.2f}B")
    
    # è¨ˆç®—å½±éŸ¿
    impact, impact_func_set = calculate_tc_impact(tc_hazard, exposure_main)
    
    # è¼¸å‡ºè©³ç´°çµæœçµ±è¨ˆ
    print(f"\nğŸ’¥ ç½å®³å½±éŸ¿åˆ†æçµæœ:")
    print(f"   å¹´å‡ç¸½æå¤± (AAI): ${impact.aai_agg/1e9:.2f}B")
    print(f"   ç¸½äº‹ä»¶æå¤±: ${impact.at_event.sum()/1e9:.2f}B")
    print(f"   æœ€å¤§å–®æ¬¡äº‹ä»¶æå¤±: ${impact.at_event.max()/1e9:.2f}B")
    print(f"   å—å½±éŸ¿äº‹ä»¶æ•¸: {(impact.at_event > 0).sum()}")
    
    # è¨ˆç®—å›æ­¸æœŸæå¤±
    freq_curve = impact.calc_freq_curve()
    rp_losses = {
        10: freq_curve.impact[np.argmin(np.abs(freq_curve.return_per - 10))],
        50: freq_curve.impact[np.argmin(np.abs(freq_curve.return_per - 50))], 
        100: freq_curve.impact[np.argmin(np.abs(freq_curve.return_per - 100))],
        500: freq_curve.impact[np.argmin(np.abs(freq_curve.return_per - 500))]
    }
    
    print(f"\nğŸ“Š å›æ­¸æœŸæå¤±ä¼°è¨ˆ:")
    for rp, loss in rp_losses.items():
        print(f"   {rp}å¹´å›æ­¸æœŸ: ${loss/1e9:.2f}B")
    
    print(f"ğŸ“ˆ ç½å®³å½±éŸ¿è¨ˆç®—å®Œæˆ")
    
    # æº–å‚™æ•¸æ“š
    climada_complete_data = {
        'tc_hazard': tc_hazard,
        'exposure': exposure_main,
        'impact': impact,
        'impact_func_set': impact_func_set,  # æ·»åŠ å½±éŸ¿å‡½æ•¸é›†
        'event_losses': impact.at_event,
        'exposure_locations': [(lat, lon) for lat, lon in zip(exposure_main.latitude, exposure_main.longitude)],
        'metadata': {
            'n_events': tc_hazard.size,
            'total_exposure': exposure_main.value.sum(),
            'annual_average_impact': impact.aai_agg,
            'generation_time': datetime.now().isoformat()
        }
    }
    print("   ğŸ‰ CLIMADAçœŸå¯¦æ•¸æ“šæº–å‚™å®Œæˆï¼")
    
    # ä¿å­˜åˆ°pickle
    import pickle
    with open('climada_complete_data.pkl', 'wb') as f:
        pickle.dump(climada_complete_data, f)
    print("ğŸ’¾ æ•¸æ“šå·²ä¿å­˜åˆ° climada_complete_data.pkl")
    
else:
    print("   âŒ ç„¡æ³•å‰µå»ºæ›éšªæ•¸æ“š")
    raise ValueError("ç„¡æ³•å‰µå»ºæ›éšªæ•¸æ“š")

print("\nğŸŠ å®Œæˆï¼CLIMADAå®Œæ•´æ•¸æ“šå°è±¡å·²ç”Ÿæˆ")
print("å¯é€šéä»¥ä¸‹æ–¹å¼ä½¿ç”¨ï¼š")
print("  import pickle")
print("  with open('climada_complete_data.pkl', 'rb') as f:")
print("      data = pickle.load(f)")