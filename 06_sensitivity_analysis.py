#!/usr/bin/env python3
"""
æ¬Šé‡æ•æ„Ÿæ€§åˆ†æ - ä½¿ç”¨æ¨¡çµ„åŒ–æ¶æ§‹
Weight Sensitivity Analysis - Using Modular Architecture

ä½¿ç”¨æ–°çš„æ¨¡çµ„åŒ– bayesian.WeightSensitivityAnalyzer å¯¦ç¾æ¬Šé‡æ•æ„Ÿæ€§åˆ†æ
é‡å°æ‡²ç½°æ¬Šé‡ (w_under, w_over) çš„æ•æ„Ÿæ€§é€²è¡Œå…¨é¢åˆ†æ

Author: Research Team  
Date: 2025-01-10
"""

import numpy as np
from pathlib import Path

# ä½¿ç”¨æ–°çš„æ¨¡çµ„åŒ–çµ„ä»¶
from bayesian import WeightSensitivityAnalyzer


def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸ - ä½¿ç”¨æ¨¡çµ„åŒ–æ¬Šé‡æ•æ„Ÿæ€§åˆ†æå™¨"""
    
    print("ğŸš€ æ¬Šé‡æ•æ„Ÿæ€§åˆ†æé–‹å§‹ï¼ˆä½¿ç”¨æ¨¡çµ„åŒ–æ¶æ§‹ï¼‰...")
    print("=" * 60)
    
    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    print("ğŸ“Š ç”Ÿæˆæ¨¡æ“¬æ•¸æ“š...")
    
    n_scenarios = 1000
    np.random.seed(42)
    
    # ç”Ÿæˆæå¤±æƒ…å¢ƒ (å°æ•¸æ­£æ…‹åˆ†ä½ˆï¼Œæ›´ç¬¦åˆå·¨ç½æå¤±ç‰¹å¾µ)
    loss_mean = 1e8  # 1å„„å¹³å‡æå¤±
    loss_std = 5e7   # 0.5å„„æ¨™æº–å·®
    
    log_mean = np.log(loss_mean) - 0.5 * np.log(1 + (loss_std / loss_mean) ** 2)
    log_std = np.sqrt(np.log(1 + (loss_std / loss_mean) ** 2))
    
    actual_losses = np.random.lognormal(log_mean, log_std, n_scenarios)
    
    # åŠ å…¥30%çš„é›¶æå¤±æƒ…å¢ƒ
    zero_loss_indices = np.random.choice(n_scenarios, size=int(0.3 * n_scenarios), replace=False)
    actual_losses[zero_loss_indices] = 0
    
    # ç”Ÿæˆç½å®³æŒ‡æ¨™ (Gammaåˆ†ä½ˆï¼Œæ›´ç¬¦åˆé¢¨ç½æŒ‡æ¨™)
    hazard_indices = np.random.gamma(2, 20, n_scenarios)
    
    print(f"   æå¤±ç¯„åœ: {actual_losses.min():.2e} - {actual_losses.max():.2e}")
    print(f"   ç½å®³æŒ‡æ¨™ç¯„åœ: {hazard_indices.min():.2f} - {hazard_indices.max():.2f}")
    
    # å‰µå»ºæ¬Šé‡æ•æ„Ÿæ€§åˆ†æå™¨ï¼ˆä½¿ç”¨æ¨¡çµ„åŒ–çµ„ä»¶ï¼‰
    print("\nğŸ”§ åˆå§‹åŒ–æ¬Šé‡æ•æ„Ÿæ€§åˆ†æå™¨...")
    
    # å®šç¾©æ¬Šé‡çµ„åˆé€²è¡Œæ¸¬è©¦
    weight_combinations = [
        # åŸºæº–çµ„åˆ
        (2.0, 0.5),  # ç•¶å‰ä½¿ç”¨ (4:1 æ¯”ç‡)
        
        # å°ç¨±çµ„åˆ  
        (1.0, 1.0),  # ç›¸ç­‰æ¬Šé‡
        
        # ä¸åŒæ¯”ç‡æ¸¬è©¦
        (2.0, 1.0),  # 2:1 æ¯”ç‡
        (3.0, 1.0),  # 3:1 æ¯”ç‡
        (4.0, 1.0),  # 4:1 æ¯”ç‡
        (5.0, 1.0),  # 5:1 æ¯”ç‡
        (10.0, 1.0), # 10:1 æ¯”ç‡
        
        # åå‘æ¬Šé‡ (æ›´é—œå¿ƒéåº¦è³ ä»˜)
        (0.5, 2.0),  # 1:4 æ¯”ç‡
        (1.0, 2.0),  # 1:2 æ¯”ç‡
        
        # æ¥µç«¯æƒ…æ³
        (5.0, 0.1),  # æ¥µåº¦æ‡²ç½°ä¸è¶³è¦†è“‹
        (0.1, 5.0),  # æ¥µåº¦æ‡²ç½°éåº¦è¦†è“‹
        
        # æº«å’Œæ¬Šé‡
        (1.5, 1.0),  # 1.5:1 æ¯”ç‡
        (1.0, 0.7),  # 1:0.7 æ¯”ç‡
    ]
    
    # ä½¿ç”¨æ¨¡çµ„åŒ–çµ„ä»¶é…ç½®
    from bayesian.weight_sensitivity_analyzer import WeightSensitivityConfig
    
    config = WeightSensitivityConfig(
        weight_combinations=weight_combinations,
        output_dir="results/sensitivity_analysis_modular"
    )
    
    analyzer = WeightSensitivityAnalyzer(config=config)
    
    # åŸ·è¡Œæ¬Šé‡æ•æ„Ÿæ€§åˆ†æ
    print(f"\nğŸ” åŸ·è¡Œæ¬Šé‡æ•æ„Ÿæ€§åˆ†æ ({len(weight_combinations)} å€‹æ¬Šé‡çµ„åˆ)...")
    
    # å®šç¾©ç”¢å“åƒæ•¸æœç´¢ç¯„åœ
    product_bounds = {
        'trigger_threshold': (np.percentile(hazard_indices, 50), np.percentile(hazard_indices, 95)),
        'payout_amount': (np.percentile(actual_losses[actual_losses > 0], 10), 
                         np.percentile(actual_losses[actual_losses > 0], 90))
    }
    
    print(f"   ç”¢å“æœç´¢ç¯„åœ:")
    print(f"     è§¸ç™¼é–¾å€¼: {product_bounds['trigger_threshold'][0]:.2f} - {product_bounds['trigger_threshold'][1]:.2f}")
    print(f"     è³ ä»˜é‡‘é¡: {product_bounds['payout_amount'][0]:.2e} - {product_bounds['payout_amount'][1]:.2e}")
    
    results = analyzer.analyze_weight_sensitivity(
        observations=actual_losses,      # è¨“ç·´æ•¸æ“š
        validation_data=actual_losses,   # é©—è­‰æ•¸æ“šï¼ˆåœ¨é€™å€‹ç¤ºä¾‹ä¸­ä½¿ç”¨ç›¸åŒæ•¸æ“šï¼‰
        hazard_indices=hazard_indices,
        actual_losses=actual_losses,
        product_bounds=product_bounds
    )
    
    # é¡¯ç¤ºçµæœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“‹ æ¬Šé‡æ•æ„Ÿæ€§åˆ†æçµæœæ‘˜è¦:")
    print("=" * 60)
    
    if hasattr(results, 'weight_combinations_analysis') and results.weight_combinations_analysis:
        analysis_data = results.weight_combinations_analysis
        
        # æ‰¾åˆ°æœ€ä½³å’Œæœ€å·®æ¬Šé‡çµ„åˆ
        best_idx = min(range(len(analysis_data)), key=lambda i: analysis_data[i]['optimal_expected_loss'])
        worst_idx = max(range(len(analysis_data)), key=lambda i: analysis_data[i]['optimal_expected_loss'])
        
        best_combo = analysis_data[best_idx]
        worst_combo = analysis_data[worst_idx]
        
        print(f"âœ… æœ€ä½³æ¬Šé‡çµ„åˆ:")
        print(f"   w_under={best_combo['w_under']:.1f}, w_over={best_combo['w_over']:.1f}")
        print(f"   æ¬Šé‡æ¯”ç‡: {best_combo['w_under']/best_combo['w_over']:.1f}:1")
        print(f"   æœ€å°æœŸæœ›æå¤±: {best_combo['optimal_expected_loss']:.2e}")
        
        print(f"\nâŒ æœ€å·®æ¬Šé‡çµ„åˆ:")
        print(f"   w_under={worst_combo['w_under']:.1f}, w_over={worst_combo['w_over']:.1f}")
        print(f"   æ¬Šé‡æ¯”ç‡: {worst_combo['w_under']/worst_combo['w_over']:.1f}:1")
        print(f"   æœ€å¤§æœŸæœ›æå¤±: {worst_combo['optimal_expected_loss']:.2e}")
        
        print(f"\nğŸ“ˆ æ•æ„Ÿæ€§çµ±è¨ˆ:")
        risks = [x['optimal_expected_loss'] for x in analysis_data]
        print(f"   æœŸæœ›æå¤±è®Šç•°ä¿‚æ•¸: {np.std(risks)/np.mean(risks):.3f}")
        print(f"   æ€§èƒ½å·®ç•°å€æ•¸: {worst_combo['optimal_expected_loss']/best_combo['optimal_expected_loss']:.2f}")
    else:
        print("âš ï¸ åˆ†æçµæœæ ¼å¼æœªçŸ¥æˆ–ç‚ºç©º")
        if hasattr(results, '__dict__'):
            print(f"   çµæœå±¬æ€§: {list(results.__dict__.keys())}")
    
    # è¼¸å‡ºæª”æ¡ˆä½ç½®
    print(f"\nğŸ“ çµæœå·²ä¿å­˜è‡³:")
    output_dir = Path("results/sensitivity_analysis_modular")
    if output_dir.exists():
        for file in output_dir.glob("*"):
            print(f"   â€¢ {file}")
    
    # å¦‚æœæœ‰ç¸½çµå ±å‘Šï¼Œé¡¯ç¤ºé—œéµæ´å¯Ÿ
    if hasattr(results, 'summary_report'):
        print(f"\nğŸ’¡ é—œéµæ´å¯Ÿ:")
        summary = results.summary_report
        if 'sensitivity_insights' in summary:
            insights = summary['sensitivity_insights']
            if 'correlation_analysis' in insights:
                correlation = insights['correlation_analysis']
                print(f"   æ¬Šé‡-æ€§èƒ½ç›¸é—œæ€§: {correlation.get('correlation_coefficient', 'N/A')}")
            if 'robustness_assessment' in insights:
                robustness = insights['robustness_assessment']
                print(f"   ç©©å¥æ€§è©•åˆ†: {robustness.get('stability_score', 'N/A')}")
            if 'recommendations' in insights:
                print(f"   å»ºè­°: {insights['recommendations']}")
    
    print(f"\nğŸ‰ æ¬Šé‡æ•æ„Ÿæ€§åˆ†æå®Œæˆï¼")
    print("âœ¨ ä½¿ç”¨æ¨¡çµ„åŒ– bayesian.WeightSensitivityAnalyzer å¯¦ç¾")
    
    return results


if __name__ == "__main__":
    results = main()