#!/usr/bin/env python3
"""
Dual GPU Fix for JAX/NumPyro
é›™GPUä¿®å¾© - JAX/NumPyroå¤šè¨­å‚™ä¸¦è¡Œ

Forces JAX to use both RTX A5000 GPUs simultaneously
å¼·åˆ¶JAXåŒæ™‚ä½¿ç”¨å…©å€‹RTX A5000 GPU
"""

import os

def configure_dual_gpu_environment():
    """é…ç½®é›™GPUç’°å¢ƒè®Šæ•¸"""
    
    print("ğŸ”§ Configuring Dual RTX A5000 GPU Environment...")
    
    # JAXé›™GPUå¼·åˆ¶é…ç½®
    dual_gpu_env = {
        # é—œéµï¼šå¼·åˆ¶JAXè­˜åˆ¥å¤šå€‹è¨­å‚™
        'JAX_PLATFORMS': 'cuda',  # åªç”¨CUDAï¼Œä¸è¦CPU fallback
        'JAX_ENABLE_X64': 'False',
        'JAX_PLATFORM_NAME': 'gpu',
        
        # é—œéµï¼šå¤šè¨­å‚™ä¸¦è¡Œé…ç½®
        'XLA_FLAGS': '--xla_force_host_platform_device_count=2',  # å¼·åˆ¶2å€‹è¨­å‚™
        'CUDA_VISIBLE_DEVICES': '0,1',  # ç¢ºä¿å…©å€‹GPUéƒ½å¯è¦‹
        'CUDA_DEVICE_ORDER': 'PCI_BUS_ID',
        
        # è¨˜æ†¶é«”å’Œä¸¦è¡Œé…ç½®
        'XLA_PYTHON_CLIENT_MEM_FRACTION': '0.8',  # ç¨å¾®æ¸›å°‘é¿å…OOM
        'XLA_PYTHON_CLIENT_PREALLOCATE': 'true',
        'XLA_PYTHON_CLIENT_ALLOCATOR': 'platform',
        
        # NumPyroå¤šè¨­å‚™é…ç½®
        'NUMPYRO_PLATFORM': 'gpu',
        'NUMPYRO_NUM_CHAINS': '24',  # æ˜ç¢ºæŒ‡å®šéˆæ•¸
        
        # PyTensorå¼·åˆ¶CUDA
        'PYTENSOR_FLAGS': 'device=cuda,floatX=float32,optimizer=fast_run,force_device=True',
        'THEANO_FLAGS': 'device=cuda,floatX=float32,force_device=True',
        
        # å¤šç·šç¨‹é…ç½®
        'OMP_NUM_THREADS': '16',
        'MKL_NUM_THREADS': '16',
        'OPENBLAS_NUM_THREADS': '16',
    }
    
    for key, value in dual_gpu_env.items():
        os.environ[key] = value
        print(f"   âœ… {key} = {value}")
    
    return dual_gpu_env

def test_dual_gpu_detection():
    """æ¸¬è©¦é›™GPUæª¢æ¸¬"""
    
    print("\nğŸ§ª Testing Dual GPU Detection...")
    
    try:
        import jax
        import jax.numpy as jnp
        
        devices = jax.devices()
        print(f"ğŸ“Š JAX devices detected: {len(devices)}")
        for i, device in enumerate(devices):
            print(f"   Device {i}: {device}")
        
        # æ¸¬è©¦å¤šè¨­å‚™è¨ˆç®—
        if len(devices) >= 2:
            print("\nğŸš€ Testing multi-device computation...")
            
            # åœ¨ä¸åŒGPUä¸Šå‰µå»ºæ•¸çµ„
            x0 = jax.device_put(jnp.ones((1000, 1000)), devices[0])
            x1 = jax.device_put(jnp.ones((1000, 1000)), devices[1])
            
            print(f"   Array on GPU 0: {x0.device()}")
            print(f"   Array on GPU 1: {x1.device()}")
            
            # ä¸¦è¡Œè¨ˆç®—
            result0 = jnp.sum(x0)
            result1 = jnp.sum(x1)
            
            print(f"   GPU 0 result: {result0} on {result0.device()}")
            print(f"   GPU 1 result: {result1} on {result1.device()}")
            
            print("âœ… Dual GPU computation successful!")
            return True
        else:
            print("âŒ Only 1 GPU detected - dual GPU not working")
            return False
            
    except ImportError:
        print("âŒ JAX not available")
        return False
    except Exception as e:
        print(f"âŒ GPU test failed: {e}")
        return False

def create_dual_gpu_mcmc_config():
    """å‰µå»ºé›™GPU MCMCé…ç½®"""
    
    dual_gpu_mcmc_config = {
        # éˆåˆ†é…ç­–ç•¥ï¼šæ¯å€‹GPU 12æ¢éˆ
        "n_samples": 2000,       # é©ä¸­æ¨£æœ¬æ•¸
        "n_warmup": 1000,        # é©ä¸­warmup
        "n_chains": 24,          # 24æ¢éˆ = æ¯GPU 12æ¢
        "cores": 24,             # åŒ¹é…éˆæ•¸
        "target_accept": 0.88,   # ç¨ä½æ¥å—ç‡æé«˜é€Ÿåº¦
        
        # é—œéµï¼šNumPyroå¤šè¨­å‚™åƒæ•¸
        "nuts_sampler": "numpyro",
        "chain_method": "parallel",
        
        # æ˜ç¢ºè¨­å‚™åˆ†é…
        "num_devices": 2,        # æ˜ç¢ºæŒ‡å®š2å€‹è¨­å‚™
        "chains_per_device": 12, # æ¯è¨­å‚™12æ¢éˆ
        
        # æ€§èƒ½å„ªåŒ–
        "progress_bar": True,
        "return_inferencedata": True,
    }
    
    print("\nğŸ“Š Dual GPU MCMC Configuration:")
    print("=" * 40)
    for key, value in dual_gpu_mcmc_config.items():
        print(f"   {key}: {value}")
    
    return dual_gpu_mcmc_config

if __name__ == "__main__":
    print("ğŸš€ Dual RTX A5000 GPU Configuration")
    print("=" * 50)
    
    # 1. é…ç½®ç’°å¢ƒ
    env_config = configure_dual_gpu_environment()
    
    # 2. æ¸¬è©¦é›™GPU
    gpu_working = test_dual_gpu_detection()
    
    # 3. å‰µå»ºMCMCé…ç½®
    mcmc_config = create_dual_gpu_mcmc_config()
    
    # 4. ç¸½çµ
    print("\n" + "=" * 50)
    if gpu_working:
        print("ğŸ‰ Dual GPU configuration successful!")
        print("ğŸ’¡ Next steps:")
        print("   1. Run your analysis with these settings")
        print("   2. Monitor nvidia-smi for dual GPU usage")
        print("   3. Expect 80%+ usage on BOTH GPUs")
    else:
        print("âš ï¸  Dual GPU configuration needs adjustment")
        print("ğŸ’¡ Troubleshooting:")
        print("   1. Check CUDA_VISIBLE_DEVICES")
        print("   2. Restart Python session")
        print("   3. Verify JAX-CUDA installation")