#!/usr/bin/env python3
"""
è¨ºæ–· GPU ä½¿ç”¨ç‹€æ³
Diagnose GPU Usage Status

æª¢æŸ¥ PyMC/JAX æ˜¯å¦çœŸæ­£ä½¿ç”¨ GPU åŠ é€Ÿ
Check if PyMC/JAX is actually using GPU acceleration
"""

import os
import sys

# ğŸ”¥ é—œéµï¼šåœ¨å°å…¥ PyMC ä¹‹å‰è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼
print("ğŸ”§ Setting GPU environment BEFORE importing PyMC...")
os.environ['PYTENSOR_FLAGS'] = 'device=cuda,floatX=float32,optimizer=fast_run,allow_gc=True'
os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'
os.environ['JAX_PLATFORM_NAME'] = 'gpu'
print("âœ… Environment variables set")

import time
import numpy as np

print("=" * 80)
print("ğŸ” GPU ä½¿ç”¨ç‹€æ³è¨ºæ–·")
print("=" * 80)

# 1. æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
print("\nğŸ“‹ Step 1: æª¢æŸ¥ç’°å¢ƒè®Šæ•¸")
print("-" * 40)
gpu_env_vars = {
    'CUDA_VISIBLE_DEVICES': os.environ.get('CUDA_VISIBLE_DEVICES', 'not set'),
    'JAX_PLATFORM_NAME': os.environ.get('JAX_PLATFORM_NAME', 'not set'),
    'JAX_PLATFORMS': os.environ.get('JAX_PLATFORMS', 'not set'),
    'PYTENSOR_FLAGS': os.environ.get('PYTENSOR_FLAGS', 'not set'),
}
for var, value in gpu_env_vars.items():
    print(f"   {var}: {value}")

# 2. æª¢æŸ¥ JAX GPU ç‹€æ…‹
print("\nğŸ“‹ Step 2: æª¢æŸ¥ JAX GPU ç‹€æ…‹")
print("-" * 40)
try:
    import jax
    import jax.numpy as jnp
    
    print(f"   JAX ç‰ˆæœ¬: {jax.__version__}")
    print(f"   JAX å¾Œç«¯: {jax.default_backend()}")
    print(f"   JAX è¨­å‚™: {jax.devices()}")
    
    # æ¸¬è©¦ç°¡å–®è¨ˆç®—
    x = jnp.array(np.random.randn(1000, 1000))
    y = jnp.array(np.random.randn(1000, 1000))
    
    start = time.time()
    z = jnp.matmul(x, y)
    z.block_until_ready()  # ç­‰å¾…è¨ˆç®—å®Œæˆ
    elapsed = time.time() - start
    
    print(f"   çŸ©é™£ä¹˜æ³•æ¸¬è©¦ (1000x1000): {elapsed:.4f} ç§’")
    print(f"   è¨ˆç®—è¨­å‚™: {z.devices()}")
    
    if 'gpu' in jax.default_backend().lower() or any('cuda' in str(d).lower() for d in jax.devices()):
        print("   âœ… JAX æ­£åœ¨ä½¿ç”¨ GPU")
    else:
        print("   âŒ JAX æ²’æœ‰ä½¿ç”¨ GPU")
        
except Exception as e:
    print(f"   âŒ JAX æ¸¬è©¦å¤±æ•—: {e}")

# 3. æª¢æŸ¥ PyMC/PyTensor GPU ç‹€æ…‹
print("\nğŸ“‹ Step 3: æª¢æŸ¥ PyMC/PyTensor GPU ç‹€æ…‹")
print("-" * 40)
try:
    import pymc as pm
    import pytensor
    import pytensor.tensor as pt
    
    print(f"   PyMC ç‰ˆæœ¬: {pm.__version__}")
    print(f"   PyTensor ç‰ˆæœ¬: {pytensor.__version__}")
    
    # æª¢æŸ¥ PyTensor è¨­å‚™
    from pytensor.configdefaults import config
    print(f"   PyTensor device: {config.device}")
    print(f"   PyTensor floatX: {config.floatX}")
    print(f"   PyTensor optimizer: {config.optimizer}")
    
    # æ¸¬è©¦ç°¡å–®æ¨¡å‹
    print("\n   æ¸¬è©¦ç°¡å–® PyMC æ¨¡å‹...")
    with pm.Model() as test_model:
        x = pm.Normal('x', mu=0, sigma=1, shape=100)
        y = pm.Normal('y', mu=x, sigma=1, observed=np.random.randn(100))
        
        # åªæ¡æ¨£å¾ˆå°‘çš„æ¨£æœ¬ä¾†æ¸¬è©¦
        start = time.time()
        trace = pm.sample(
            draws=100,
            tune=50,
            chains=1,
            progressbar=False,
            return_inferencedata=False
        )
        elapsed = time.time() - start
        
    print(f"   PyMC æ¡æ¨£æ¸¬è©¦ (100 draws): {elapsed:.2f} ç§’")
    
    if config.device == 'cuda':
        print("   âœ… PyTensor é…ç½®ç‚ºä½¿ç”¨ CUDA")
    else:
        print(f"   âš ï¸ PyTensor ä½¿ç”¨: {config.device}")
        
except Exception as e:
    print(f"   âŒ PyMC/PyTensor æ¸¬è©¦å¤±æ•—: {e}")

# 4. æª¢æŸ¥ GPU ç¡¬é«”
print("\nğŸ“‹ Step 4: æª¢æŸ¥ GPU ç¡¬é«”")
print("-" * 40)

# å˜—è©¦ä½¿ç”¨ nvidia-ml-py
try:
    import pynvml
    pynvml.nvmlInit()
    device_count = pynvml.nvmlDeviceGetCount()
    print(f"   æª¢æ¸¬åˆ° {device_count} å€‹ NVIDIA GPU")
    
    for i in range(device_count):
        handle = pynvml.nvmlDeviceGetHandleByIndex(i)
        name = pynvml.nvmlDeviceGetName(handle)
        memory = pynvml.nvmlDeviceGetMemoryInfo(handle)
        utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
        
        print(f"\n   GPU {i}: {name.decode('utf-8')}")
        print(f"      è¨˜æ†¶é«”: {memory.used/1e9:.1f}/{memory.total/1e9:.1f} GB")
        print(f"      GPU ä½¿ç”¨ç‡: {utilization.gpu}%")
        print(f"      è¨˜æ†¶é«”ä½¿ç”¨ç‡: {utilization.memory}%")
        
    pynvml.nvmlShutdown()
except ImportError:
    print("   âš ï¸ pynvml æœªå®‰è£ï¼Œå˜—è©¦ GPUtil...")
    
    try:
        import GPUtil
        gpus = GPUtil.getGPUs()
        if gpus:
            print(f"   æª¢æ¸¬åˆ° {len(gpus)} å€‹ GPU")
            for gpu in gpus:
                print(f"\n   GPU {gpu.id}: {gpu.name}")
                print(f"      è¨˜æ†¶é«”: {gpu.memoryUsed}/{gpu.memoryTotal} MB")
                print(f"      GPU è² è¼‰: {gpu.load*100:.1f}%")
                print(f"      è¨˜æ†¶é«”ä½¿ç”¨ç‡: {gpu.memoryUtil*100:.1f}%")
        else:
            print("   âŒ æ²’æœ‰æª¢æ¸¬åˆ° GPU")
    except ImportError:
        print("   âŒ GPUtil æœªå®‰è£")
except Exception as e:
    print(f"   âŒ GPU ç¡¬é«”æª¢æ¸¬å¤±æ•—: {e}")

# 5. è¨ºæ–·çµè«–
print("\n" + "=" * 80)
print("ğŸ¯ è¨ºæ–·çµè«–")
print("=" * 80)

issues = []
recommendations = []

# æª¢æŸ¥ JAX
if 'JAX_PLATFORM_NAME' in os.environ and os.environ['JAX_PLATFORM_NAME'] != 'gpu':
    issues.append("JAX_PLATFORM_NAME ä¸æ˜¯è¨­ç½®ç‚º 'gpu'")
    recommendations.append("è¨­ç½® export JAX_PLATFORM_NAME=gpu")

# æª¢æŸ¥ PyTensor
if 'PYTENSOR_FLAGS' in os.environ:
    if 'device=cuda' not in os.environ['PYTENSOR_FLAGS']:
        issues.append("PYTENSOR_FLAGS æ²’æœ‰åŒ…å« device=cuda")
        recommendations.append("ç¢ºä¿ PYTENSOR_FLAGS åŒ…å« 'device=cuda'")

# æª¢æŸ¥ CUDA
if os.environ.get('CUDA_VISIBLE_DEVICES', 'not set') == 'not set':
    issues.append("CUDA_VISIBLE_DEVICES æœªè¨­ç½®")
    recommendations.append("è¨­ç½® export CUDA_VISIBLE_DEVICES=0,1")

if issues:
    print("âŒ ç™¼ç¾çš„å•é¡Œ:")
    for issue in issues:
        print(f"   â€¢ {issue}")
    
    print("\nğŸ’¡ å»ºè­°:")
    for rec in recommendations:
        print(f"   â€¢ {rec}")
else:
    print("âœ… GPU é…ç½®çœ‹èµ·ä¾†æ­£ç¢º")

print("\nğŸ“Š æ€§èƒ½æç¤º:")
print("   1. PyMC çš„ GPU åŠ é€Ÿä¸»è¦å°å¤§å‹æ¨¡å‹æœ‰æ•ˆ")
print("   2. å°æ¨¡å‹å¯èƒ½åœ¨ CPU ä¸Šæ›´å¿«ï¼ˆGPU å•Ÿå‹•é–‹éŠ·ï¼‰")
print("   3. ç¢ºä¿ä½¿ç”¨ NUTS æ¡æ¨£å™¨ï¼ˆè‡ªå‹•é¸æ“‡ï¼‰")
print("   4. è€ƒæ…®ä½¿ç”¨ JAX æ¡æ¨£å™¨: pm.sample(nuts_sampler='numpyro')")
print("   5. å°æ–¼é›™ GPUï¼Œä½¿ç”¨ chains=2 æˆ– 4ï¼Œcores=2")

print("\nğŸš€ æ¸¬è©¦ GPU åŠ é€Ÿçš„æœ€ä½³æ–¹æ³•:")
print("   æ¯”è¼ƒç›¸åŒæ¨¡å‹åœ¨ CPU vs GPU çš„æ¡æ¨£æ™‚é–“")
print("   export PYTENSOR_FLAGS='device=cpu' vs 'device=cuda'")