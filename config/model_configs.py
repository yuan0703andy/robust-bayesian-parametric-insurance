#!/usr/bin/env python3
"""
Model Configurations Module
æ¨¡å‹é…ç½®æ¨¡çµ„

çµ±ä¸€çš„æ¨¡å‹é…ç½®ç®¡ç†ï¼Œæ”¯æ´8éšæ®µå·¥ä½œæµç¨‹
éµå¾ª 05_complete_integrated_framework.py çš„æ¶æ§‹

æ ¸å¿ƒåŠŸèƒ½:
- çµ±ä¸€çš„æ¨¡å‹é…ç½®ç®¡ç†
- 8éšæ®µå·¥ä½œæµç¨‹é…ç½®
- é è¨­é…ç½®å’Œè‡ªå®šç¾©é…ç½®æ”¯æ´

Author: Research Team  
Date: 2025-01-17
"""

import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import os

# ========================================
# å·¥ä½œæµç¨‹éšæ®µå®šç¾©
# ========================================

class WorkflowStage(Enum):
    """8éšæ®µå·¥ä½œæµç¨‹å®šç¾©"""
    DATA_PROCESSING = "1_data_processing"
    ROBUST_PRIORS = "2_robust_priors"
    HIERARCHICAL_MODELING = "3_hierarchical_modeling"
    MODEL_SELECTION = "4_model_selection"
    HYPERPARAMETER_OPTIMIZATION = "5_hyperparameter_optimization"
    MCMC_VALIDATION = "6_mcmc_validation"
    POSTERIOR_ANALYSIS = "7_posterior_analysis"
    PARAMETRIC_INSURANCE = "8_parametric_insurance"

class ModelComplexity(Enum):
    """æ¨¡å‹è¤‡é›œåº¦ç´šåˆ¥"""
    SIMPLE = "simple"           # å¿«é€ŸåŸå‹
    STANDARD = "standard"       # æ¨™æº–åˆ†æ
    COMPREHENSIVE = "comprehensive"  # å…¨é¢åˆ†æ
    RESEARCH = "research"       # ç ”ç©¶ç´šåˆ¥

# ========================================
# é…ç½®çµæ§‹
# ========================================

@dataclass
class DataProcessingConfig:
    """æ•¸æ“šè™•ç†é…ç½® - éšæ®µ1"""
    use_climada_loader: bool = True
    data_validation: bool = True
    missing_data_strategy: str = "interpolation"  # interpolation, removal, imputation
    outlier_detection: bool = True
    outlier_threshold: float = 3.0  # Z-score threshold
    
@dataclass
class RobustPriorsConfig:
    """ç©©å¥å…ˆé©—é…ç½® - éšæ®µ2"""
    use_epsilon_contamination: bool = True
    epsilon_estimation_method: str = "empirical_frequency"
    contamination_class: str = "typhoon_specific"
    robustness_criterion: str = "worst_case"
    # Îµ-contaminationç‰¹å®šåƒæ•¸
    epsilon_range: Tuple[float, float] = (0.01, 0.20)
    typhoon_frequency_per_year: float = 3.2

@dataclass
class HierarchicalModelingConfig:
    """éšå±¤å»ºæ¨¡é…ç½® - éšæ®µ3"""
    likelihood_family: str = "lognormal"
    prior_scenario: str = "weak_informative"
    vulnerability_type: str = "emanuel"
    include_spatial_effects: bool = True
    include_region_effects: bool = True
    spatial_covariance_function: str = "exponential"
    
@dataclass
class VIScreeningConfig:
    """VIç¯©é¸é…ç½® - éšæ®µ4"""
    use_vi_screening: bool = True
    vi_max_iterations: int = 5000
    vi_learning_rate: float = 0.01
    vi_convergence_tolerance: float = 1e-6
    basis_risk_aware: bool = True
    differentiable_crps: bool = True

@dataclass
class CRPSFrameworkConfig:
    """CRPSæ¡†æ¶é…ç½® - éšæ®µ5"""
    use_crps_optimization: bool = True
    weight_sensitivity_analysis: bool = True
    density_ratio_estimation: bool = True
    crps_ensemble_size: int = 500
    basis_risk_threshold: float = 0.1

@dataclass
class MCMCValidationConfig:
    """MCMCé©—è­‰é…ç½® - éšæ®µ6"""
    n_samples: int = 2000
    n_warmup: int = 1000
    n_chains: int = 4
    target_accept: float = 0.8
    max_treedepth: int = 10
    use_nuts: bool = True
    # HPCç‰¹å®šé…ç½®
    use_hpc_optimization: bool = False
    cores_per_chain: int = 1

@dataclass
class PosteriorAnalysisConfig:
    """å¾Œé©—åˆ†æé…ç½® - éšæ®µ7"""
    compute_credible_intervals: bool = True
    robust_intervals: bool = True
    posterior_predictive_checks: bool = True
    mixture_approximation: bool = True
    convergence_diagnostics: bool = True
    # è¼¸å‡ºé…ç½®
    generate_plots: bool = True
    save_trace: bool = False

@dataclass
class ParametricInsuranceConfig:
    """åƒæ•¸ä¿éšªé…ç½® - éšæ®µ8"""
    basis_risk_minimization: bool = True
    product_optimization: bool = True
    technical_premium_calculation: bool = True
    risk_metrics_computation: bool = True
    # ç”¢å“ç‰¹å®šåƒæ•¸
    coverage_ratio_range: Tuple[float, float] = (0.5, 1.0)
    deductible_range: Tuple[float, float] = (0.0, 0.3)

@dataclass
class ComputationConfig:
    """è¨ˆç®—ç’°å¢ƒé…ç½®"""
    # ç’°å¢ƒè¨­ç½®
    device: str = "cpu"  # cpu, gpu, tpu
    float_precision: str = "float64"
    compile_mode: str = "FAST_COMPILE"
    
    # å¹³è¡ŒåŒ–é…ç½®
    use_multiprocessing: bool = True
    max_workers: int = 4
    threading_layer: str = "GNU"
    
    # HPCé…ç½®
    detect_hpc: bool = True
    slurm_integration: bool = True
    pbs_integration: bool = True
    
    # è¨˜æ†¶é«”ç®¡ç†
    memory_efficient: bool = True
    cache_intermediate_results: bool = True
    max_memory_gb: float = 8.0
    
    def __post_init__(self):
        """è‡ªå‹•é…ç½®HPCç’°å¢ƒ"""
        if self.detect_hpc:
            self._configure_hpc_environment()
    
    def _configure_hpc_environment(self):
        """é…ç½®HPCç’°å¢ƒè®Šæ•¸"""
        # è¨­ç½®åŸºæœ¬ç’°å¢ƒè®Šæ•¸
        os.environ['PYTENSOR_FLAGS'] = f'device={self.device},floatX={self.float_precision},mode={self.compile_mode},linker=py'
        os.environ['MKL_THREADING_LAYER'] = self.threading_layer
        
        # HPCç³»çµ±æª¢æ¸¬
        if 'SLURM_CPUS_PER_TASK' in os.environ and self.slurm_integration:
            self.max_workers = int(os.environ['SLURM_CPUS_PER_TASK'])
            os.environ['OMP_NUM_THREADS'] = os.environ['SLURM_CPUS_PER_TASK']
            print(f"ğŸ–¥ï¸ æª¢æ¸¬åˆ°SLURMç’°å¢ƒï¼Œä½¿ç”¨ {self.max_workers} å€‹CPUæ ¸å¿ƒ")
            
        elif 'PBS_NCPUS' in os.environ and self.pbs_integration:
            self.max_workers = int(os.environ['PBS_NCPUS'])
            os.environ['OMP_NUM_THREADS'] = os.environ['PBS_NCPUS']
            print(f"ğŸ–¥ï¸ æª¢æ¸¬åˆ°PBSç’°å¢ƒï¼Œä½¿ç”¨ {self.max_workers} å€‹CPUæ ¸å¿ƒ")
            
        else:
            os.environ['OMP_NUM_THREADS'] = str(self.max_workers)
            print(f"ğŸ–¥ï¸ ä½¿ç”¨æœ¬åœ°ç’°å¢ƒï¼Œ{self.max_workers} å€‹å·¥ä½œé€²ç¨‹")

@dataclass
class IntegratedFrameworkConfig:
    """æ•´åˆæ¡†æ¶é…ç½® - å®Œæ•´çš„8éšæ®µå·¥ä½œæµç¨‹"""
    # åŸºæœ¬è¨­ç½®
    complexity_level: ModelComplexity = ModelComplexity.STANDARD
    random_seed: int = 42
    verbose: bool = True
    
    # å„éšæ®µé…ç½®
    data_processing: DataProcessingConfig = field(default_factory=DataProcessingConfig)
    robust_priors: RobustPriorsConfig = field(default_factory=RobustPriorsConfig)
    hierarchical_modeling: HierarchicalModelingConfig = field(default_factory=HierarchicalModelingConfig)
    vi_screening: VIScreeningConfig = field(default_factory=VIScreeningConfig)
    crps_framework: CRPSFrameworkConfig = field(default_factory=CRPSFrameworkConfig)
    mcmc_validation: MCMCValidationConfig = field(default_factory=MCMCValidationConfig)
    posterior_analysis: PosteriorAnalysisConfig = field(default_factory=PosteriorAnalysisConfig)
    parametric_insurance: ParametricInsuranceConfig = field(default_factory=ParametricInsuranceConfig)
    
    # è¨ˆç®—é…ç½®
    computation: ComputationConfig = field(default_factory=ComputationConfig)
    
    def __post_init__(self):
        """æ ¹æ“šè¤‡é›œåº¦ç´šåˆ¥èª¿æ•´é…ç½®"""
        self._adjust_for_complexity()
        
        # è¨­ç½®éš¨æ©Ÿç¨®å­
        np.random.seed(self.random_seed)
    
    def _adjust_for_complexity(self):
        """æ ¹æ“šè¤‡é›œåº¦ç´šåˆ¥èª¿æ•´é…ç½®åƒæ•¸"""
        if self.complexity_level == ModelComplexity.SIMPLE:
            # å¿«é€ŸåŸå‹é…ç½®
            self.mcmc_validation.n_samples = 500
            self.mcmc_validation.n_warmup = 250
            self.mcmc_validation.n_chains = 2
            self.crps_framework.crps_ensemble_size = 200
            self.vi_screening.vi_max_iterations = 1000
            
        elif self.complexity_level == ModelComplexity.STANDARD:
            # æ¨™æº–é…ç½®ï¼ˆå·²åœ¨dataclassä¸­å®šç¾©ï¼‰
            pass
            
        elif self.complexity_level == ModelComplexity.COMPREHENSIVE:
            # å…¨é¢åˆ†æé…ç½®
            self.mcmc_validation.n_samples = 5000
            self.mcmc_validation.n_warmup = 2000
            self.mcmc_validation.n_chains = 6
            self.crps_framework.crps_ensemble_size = 1000
            self.vi_screening.vi_max_iterations = 10000
            self.posterior_analysis.save_trace = True
            
        elif self.complexity_level == ModelComplexity.RESEARCH:
            # ç ”ç©¶ç´šåˆ¥é…ç½®
            self.mcmc_validation.n_samples = 10000
            self.mcmc_validation.n_warmup = 5000
            self.mcmc_validation.n_chains = 8
            self.crps_framework.crps_ensemble_size = 2000
            self.vi_screening.vi_max_iterations = 20000
            self.posterior_analysis.save_trace = True
            self.computation.max_memory_gb = 16.0
    
    def get_stage_config(self, stage: WorkflowStage) -> Any:
        """ç²å–ç‰¹å®šéšæ®µçš„é…ç½®"""
        stage_mapping = {
            WorkflowStage.DATA_PROCESSING: self.data_processing,
            WorkflowStage.ROBUST_PRIORS: self.robust_priors,
            WorkflowStage.HIERARCHICAL_MODELING: self.hierarchical_modeling,
            WorkflowStage.VI_SCREENING: self.vi_screening,
            WorkflowStage.CRPS_FRAMEWORK: self.crps_framework,
            WorkflowStage.MCMC_VALIDATION: self.mcmc_validation,
            WorkflowStage.POSTERIOR_ANALYSIS: self.posterior_analysis,
            WorkflowStage.PARAMETRIC_INSURANCE: self.parametric_insurance
        }
        return stage_mapping.get(stage)
    
    def validate_configuration(self) -> Tuple[bool, List[str]]:
        """é©—è­‰é…ç½®çš„ä¸€è‡´æ€§"""
        warnings = []
        
        # æª¢æŸ¥MCMCé…ç½®
        if self.mcmc_validation.n_samples < 100:
            warnings.append("MCMCæ¨£æœ¬æ•¸éå°‘ï¼Œå¯èƒ½å½±éŸ¿æ”¶æ–‚æ€§")
        
        if self.mcmc_validation.n_chains < 2:
            warnings.append("å»ºè­°ä½¿ç”¨è‡³å°‘2æ¢MCMCéˆé€²è¡Œè¨ºæ–·")
        
        # æª¢æŸ¥è¨˜æ†¶é«”é…ç½®
        if self.computation.max_memory_gb < 2.0:
            warnings.append("è¨˜æ†¶é«”é…ç½®å¯èƒ½ä¸è¶³ä»¥å®Œæˆåˆ†æ")
        
        # æª¢æŸ¥Îµ-contaminationé…ç½®
        if (self.robust_priors.use_epsilon_contamination and 
            self.robust_priors.epsilon_range[1] > 0.5):
            warnings.append("Îµæ±¡æŸ“ç¨‹åº¦éé«˜å¯èƒ½å°è‡´ä¸ç©©å®š")
        
        # æª¢æŸ¥VIé…ç½®
        if (self.vi_screening.use_vi_screening and 
            self.vi_screening.vi_max_iterations < 1000):
            warnings.append("VIè¿­ä»£æ¬¡æ•¸å¯èƒ½ä¸è¶³ä»¥æ”¶æ–‚")
        
        is_valid = len(warnings) == 0
        return is_valid, warnings
    
    def summary(self) -> Dict[str, Any]:
        """é…ç½®æ‘˜è¦"""
        return {
            "è¤‡é›œåº¦ç´šåˆ¥": self.complexity_level.value,
            "éš¨æ©Ÿç¨®å­": self.random_seed,
            "MCMCè¨­ç½®": f"{self.mcmc_validation.n_samples} samples, {self.mcmc_validation.n_chains} chains",
            "Îµ-contamination": self.robust_priors.use_epsilon_contamination,
            "ç©ºé–“æ•ˆæ‡‰": self.hierarchical_modeling.include_spatial_effects,
            "VIç¯©é¸": self.vi_screening.use_vi_screening,
            "CRPSå„ªåŒ–": self.crps_framework.use_crps_optimization,
            "è¨ˆç®—è¨­å‚™": self.computation.device,
            "å·¥ä½œé€²ç¨‹": self.computation.max_workers
        }

# ========================================
# é è¨­é…ç½®ç”Ÿæˆå™¨
# ========================================

def create_quick_prototype_config() -> IntegratedFrameworkConfig:
    """å‰µå»ºå¿«é€ŸåŸå‹é…ç½®"""
    return IntegratedFrameworkConfig(
        complexity_level=ModelComplexity.SIMPLE,
        verbose=True
    )

def create_standard_analysis_config() -> IntegratedFrameworkConfig:
    """å‰µå»ºæ¨™æº–åˆ†æé…ç½®"""
    return IntegratedFrameworkConfig(
        complexity_level=ModelComplexity.STANDARD,
        verbose=True
    )

def create_comprehensive_research_config() -> IntegratedFrameworkConfig:
    """å‰µå»ºå…¨é¢ç ”ç©¶é…ç½®"""
    return IntegratedFrameworkConfig(
        complexity_level=ModelComplexity.COMPREHENSIVE,
        verbose=True
    )

def create_hpc_optimized_config() -> IntegratedFrameworkConfig:
    """å‰µå»ºHPCå„ªåŒ–é…ç½®"""
    config = IntegratedFrameworkConfig(
        complexity_level=ModelComplexity.RESEARCH,
        verbose=False  # HPCç’°å¢ƒä¸­æ¸›å°‘è¼¸å‡º
    )
    
    # HPCç‰¹å®šèª¿æ•´
    config.computation.detect_hpc = True
    config.computation.memory_efficient = True
    config.computation.cache_intermediate_results = False  # é¿å…ç£ç¢ŸIO
    config.mcmc_validation.use_hpc_optimization = True
    
    return config

def create_epsilon_contamination_focused_config() -> IntegratedFrameworkConfig:
    """å‰µå»ºå°ˆæ³¨æ–¼Îµ-contaminationçš„é…ç½®"""
    config = IntegratedFrameworkConfig(complexity_level=ModelComplexity.STANDARD)
    
    # å¼·åŒ–Îµ-contaminationç›¸é—œè¨­ç½®
    config.robust_priors.use_epsilon_contamination = True
    config.robust_priors.epsilon_estimation_method = "bayesian_model_selection"
    config.robust_priors.contamination_class = "typhoon_specific"
    config.robust_priors.epsilon_range = (0.005, 0.15)  # æ›´ç²¾ç¢ºçš„ç¯„åœ
    
    # å¢å¼·å¾Œé©—åˆ†æ
    config.posterior_analysis.robust_intervals = True
    config.posterior_analysis.mixture_approximation = True
    
    return config

def test_model_configs():
    """æ¸¬è©¦æ¨¡å‹é…ç½®åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦æ¨¡å‹é…ç½®æ¨¡çµ„...")
    
    # æ¸¬è©¦æ¨™æº–é…ç½®
    print("âœ… æ¸¬è©¦æ¨™æº–é…ç½®:")
    config = create_standard_analysis_config()
    print(f"   è¤‡é›œåº¦: {config.complexity_level.value}")
    print(f"   MCMCéˆæ•¸: {config.mcmc_validation.n_chains}")
    
    # æ¸¬è©¦é…ç½®é©—è­‰
    print("âœ… æ¸¬è©¦é…ç½®é©—è­‰:")
    is_valid, warnings = config.validate_configuration()
    print(f"   é©—è­‰çµæœ: {is_valid}")
    if warnings:
        print(f"   è­¦å‘Šæ•¸é‡: {len(warnings)}")
    
    # æ¸¬è©¦é…ç½®æ‘˜è¦
    print("âœ… æ¸¬è©¦é…ç½®æ‘˜è¦:")
    summary = config.summary()
    print(f"   æ‘˜è¦é …ç›®: {len(summary)}")
    
    # æ¸¬è©¦HPCé…ç½®
    print("âœ… æ¸¬è©¦HPCé…ç½®:")
    hpc_config = create_hpc_optimized_config()
    print(f"   HPCå„ªåŒ–: {hpc_config.computation.detect_hpc}")
    
    print("âœ… æ¨¡å‹é…ç½®æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    test_model_configs()