# ============================================================================
# 3. æ–°çš„ Bayesian æ•´åˆä»£ç¢¼ - æ›¿æ›ç¬¬1242-1350è¡Œ
# ============================================================================

# %% ğŸ§  æ–°ç‰ˆæ•´åˆè²è‘‰æ–¯åˆ†æ
if modules_available['bayesian'] and 'tc_hazard' in main_data and 'exposure' in main_data:
    try:
        print("   ğŸš€ å•Ÿå‹•æ–°ç‰ˆæ•´åˆè²è‘‰æ–¯åˆ†æå™¨...")
        print("   ğŸ“– ç†è«–åŸºç¤: bayesian_implement.md - æ–¹æ³•ä¸€ â†’ æ–¹æ³•äºŒé€£è²«æµç¨‹")
        
        # åˆå§‹åŒ–æ–°ç‰ˆåˆ†æå™¨
        bayesian_analyzer = RobustBayesianAnalyzer(
            density_ratio_constraint=2.0,
            n_monte_carlo_samples=n_monte_carlo_samples,
            n_mixture_components=3
        )
        
        # æº–å‚™åˆ†ææ•¸æ“š
        print("      ğŸ“Š æº–å‚™å…©éšæ®µåˆ†ææ•¸æ“š...")
        
        # é¸æ“‡æ›éšªæ•¸æ“š
        if 'hospital_exposures' in locals() and hospital_exposures is not None:
            exposure_for_bayesian = hospital_exposures
            print(f"      ğŸ¯ ä½¿ç”¨ {len(exposure_for_bayesian.gdf)} å€‹é†«é™¢é»é€²è¡Œå»ºæ¨¡")
        else:
            exposure_for_bayesian = exposure_main
            print(f"      âš ï¸ ä½¿ç”¨å®Œæ•´LitPopæ•¸æ“š ({len(exposure_for_bayesian.gdf)} é»)")
        
        # ç¢ºä¿æå¤±æ•¸æ“šæ ¼å¼æ­£ç¢º
        damages_array = np.array(damages, dtype=np.float64)
        n_events = len(damages_array)
        
        # æ™ºèƒ½æ•¸æ“šåˆ†å‰² (æ–¹æ³•ä¸€éœ€è¦è¨“ç·´/é©—è­‰åˆ†å‰²)
        if n_events >= 50:
            n_train = max(int(0.7 * n_events), 30)  # è‡³å°‘30å€‹è¨“ç·´æ¨£æœ¬
        else:
            n_train = max(int(0.8 * n_events), 10)  # å°æ•¸æ“šé›†ç”¨æ›´å¤šè¨“ç·´æ¨£æœ¬
            
        n_validation = n_events - n_train
        
        if n_validation < 5:  # ç¢ºä¿è‡³å°‘æœ‰5å€‹é©—è­‰æ¨£æœ¬
            n_train = max(n_events - 5, 10)
            n_validation = n_events - n_train
        
        train_losses = damages_array[:n_train]
        validation_losses = damages_array[n_train:]
        
        print(f"      ğŸ“‹ æ™ºèƒ½æ•¸æ“šåˆ†å‰²: è¨“ç·´({n_train}) / é©—è­‰({n_validation})")
        
        # å‰µå»ºé¢¨éšªæŒ‡æ¨™ (æ–¹æ³•äºŒéœ€è¦)
        print("      ğŸŒªï¸ å»ºç«‹é¢¨éšªæŒ‡æ¨™...")
        if 'hospital_wind_series' in locals() and hospital_wind_series:
            # ä½¿ç”¨é†«é™¢é¢¨é€Ÿæ•¸æ“š
            hazard_indices = np.array(list(hospital_wind_series.values())).mean(axis=0)[:n_train]
            print(f"         ä½¿ç”¨é†«é™¢é¢¨é€Ÿæ•¸æ“š ({len(hazard_indices)} å€‹äº‹ä»¶)")
        else:
            # åŸºæ–¼æå¤±å¤§å°æ¨ä¼°é¢¨éšªæŒ‡æ¨™
            # é«˜æå¤± -> é«˜é¢¨éšªæŒ‡æ¨™ï¼Œä½æå¤± -> ä½é¢¨éšªæŒ‡æ¨™
            normalized_losses = (train_losses - np.min(train_losses)) / (np.max(train_losses) - np.min(train_losses) + 1e-10)
            hazard_indices = 25 + normalized_losses * 40  # å°æ‡‰é¢¨é€Ÿ 25-65
            print(f"         åŸºæ–¼æå¤±æ¨ä¼°é¢¨éšªæŒ‡æ¨™ ({len(hazard_indices)} å€‹äº‹ä»¶)")
        
        # å‰µå»ºæå¤±æƒ…å¢ƒçŸ©é™£ (æ–¹æ³•äºŒçš„æœŸæœ›æå¤±è¨ˆç®—éœ€è¦)
        print(f"      ğŸ² ç”Ÿæˆ {n_loss_scenarios} å€‹æå¤±æƒ…å¢ƒ...")
        actual_losses_matrix = np.zeros((n_loss_scenarios, n_train))
        
        for i in range(n_loss_scenarios):
            # åŸºæ–¼ä¸ç¢ºå®šæ€§ç”Ÿæˆæƒ…å¢ƒ
            hazard_uncertainty = np.random.normal(1.0, 0.15, n_train)  # 15% é¢¨éšªä¸ç¢ºå®šæ€§
            exposure_uncertainty = np.random.lognormal(0, 0.20)        # 20% æ›éšªä¸ç¢ºå®šæ€§
            vulnerability_uncertainty = np.random.normal(1.0, 0.10)   # 10% è„†å¼±æ€§ä¸ç¢ºå®šæ€§
            
            scenario_losses = (train_losses * 
                             hazard_uncertainty * 
                             exposure_uncertainty * 
                             vulnerability_uncertainty)
            
            actual_losses_matrix[i, :] = np.maximum(scenario_losses, 0)  # ç¢ºä¿éè² 
        
        print(f"         å¹³å‡æƒ…å¢ƒæå¤±: ${np.mean(actual_losses_matrix)/1e9:.2f}B")
        print(f"         æå¤±è®Šç•°ç¯„åœ: ${np.std(actual_losses_matrix)/1e9:.2f}B")
        
        # å®šç¾©ç”¢å“åƒæ•¸æœ€ä½³åŒ–é‚Šç•Œ
        # åŸºæ–¼ç¾æœ‰æ•¸æ“šç¯„åœè¨­ç½®åˆç†é‚Šç•Œ
        min_wind, max_wind = np.min(hazard_indices), np.max(hazard_indices)
        mean_loss = np.mean(train_losses)
        max_loss = np.max(train_losses)
        
        product_bounds = {
            'trigger_threshold': (max(min_wind - 5, 20), min(max_wind + 5, 70)),
            'payout_amount': (mean_loss * 0.5, max_loss * 2.0),
            'max_payout': (max_loss * 3.0, max_loss * 5.0)
        }
        
        print(f"      âš™ï¸ ç”¢å“åƒæ•¸é‚Šç•Œ:")
        print(f"         è§¸ç™¼é–¾å€¼: {product_bounds['trigger_threshold'][0]:.1f} - {product_bounds['trigger_threshold'][1]:.1f}")
        print(f"         è³ ä»˜é‡‘é¡: ${product_bounds['payout_amount'][0]/1e9:.2f}B - ${product_bounds['payout_amount'][1]/1e9:.2f}B")
        
        print("      ğŸš€ åŸ·è¡Œæ•´åˆè²è‘‰æ–¯æœ€ä½³åŒ– (æ–¹æ³•ä¸€ + æ–¹æ³•äºŒ)...")
        
        # ğŸ¯ ä½¿ç”¨æ–°çš„æ•´åˆæ–¹æ³•
        bayesian_results = bayesian_analyzer.integrated_bayesian_optimization(
            observations=train_losses,
            validation_data=validation_losses,
            hazard_indices=hazard_indices,
            actual_losses=actual_losses_matrix,
            product_bounds=product_bounds,
            basis_risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0,  # è³ ä¸å¤ çš„æ‡²ç½°æ¬Šé‡è¼ƒé«˜
            w_over=0.5,   # è³ å¤šäº†çš„æ‡²ç½°æ¬Šé‡è¼ƒä½
            **pymc_config  # ä½¿ç”¨ç’°å¢ƒé…ç½®
        )
        
        print("   âœ… æ–°ç‰ˆæ•´åˆè²è‘‰æ–¯åˆ†æå®Œæˆï¼")
        
        # æå–çµæœ
        phase1_results = bayesian_results['phase_1_model_comparison']
        phase2_results = bayesian_results['phase_2_decision_optimization']
        integration_validation = bayesian_results['integration_validation']
        
        print(f"      ğŸ† æ–¹æ³•ä¸€çµæœ:")
        print(f"         å† è»æ¨¡å‹: {phase1_results['champion_model']['name']}")
        print(f"         CRPS åˆ†æ•¸: {phase1_results['champion_model']['crps_score']:.3e}")
        print(f"         å€™é¸æ¨¡å‹æ•¸: {len(phase1_results['candidate_models'])}")
        
        print(f"      ğŸ¯ æ–¹æ³•äºŒçµæœ:")
        print(f"         æœ€ä½³è§¸ç™¼é–¾å€¼: {phase2_results['optimal_product']['trigger_threshold']:.1f}")
        print(f"         æœ€ä½³è³ ä»˜é‡‘é¡: ${phase2_results['optimal_product']['payout_amount']/1e9:.2f}B")
        print(f"         æœŸæœ›åŸºå·®é¢¨éšª: ${phase2_results['expected_basis_risk']/1e9:.3f}B")
        
        print(f"      âœ… ç†è«–é©—è­‰: {integration_validation['theoretical_compliance']}")
        
        # å‰µå»ºèˆ‡ç¾æœ‰ç³»çµ±å…¼å®¹çš„çµæœæ ¼å¼
        bayesian_optimal_product = {
            'product_id': 'bayesian_integrated_optimal',
            'trigger_threshold': phase2_results['optimal_product']['trigger_threshold'],
            'payout_amount': phase2_results['optimal_product']['payout_amount'],
            'max_payout': phase2_results['optimal_product'].get('max_payout', phase2_results['optimal_product']['payout_amount']),
            'method': 'integrated_bayesian_optimization_v2',
            'champion_model': phase1_results['champion_model']['name'],
            'champion_crps': phase1_results['champion_model']['crps_score'],
            'expected_basis_risk': phase2_results['expected_basis_risk'],
            'optimization_method': phase2_results['methodology'],
            'theoretical_framework': 'bayesian_implement.md'
        }
        
        # æ¨¡æ“¬è¨ˆç®—æ–°ç”¢å“åœ¨åŸå§‹æ•¸æ“šä¸Šçš„è¡¨ç¾
        print("      ğŸ“Š è¨ˆç®—æœ€ä½³ç”¢å“åœ¨å…¨éƒ¨æ•¸æ“šä¸Šçš„è¡¨ç¾...")
        optimal_payouts = []
        for i, loss in enumerate(damages_array):
            if i < len(hazard_indices):
                wind = hazard_indices[i]
            else:
                # å°é©—è­‰é›†æ¨ä¼°é¢¨éšªæŒ‡æ¨™
                val_normalized = (loss - np.min(damages_array)) / (np.max(damages_array) - np.min(damages_array) + 1e-10)
                wind = 25 + val_normalized * 40
            
            if wind >= bayesian_optimal_product['trigger_threshold']:
                payout = min(bayesian_optimal_product['payout_amount'], bayesian_optimal_product['max_payout'])
            else:
                payout = 0.0
            optimal_payouts.append(payout)
        
        optimal_payouts = np.array(optimal_payouts)
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        correlation = np.corrcoef(damages_array, optimal_payouts)[0, 1] if len(optimal_payouts) > 1 else 0
        trigger_rate = np.mean(optimal_payouts > 0)
        
        bayesian_optimal_product.update({
            'payouts': optimal_payouts,
            'correlation': correlation,
            'trigger_rate': trigger_rate,
            'radius_km': 'integrated',  # ä¸ä½¿ç”¨å›ºå®šåŠå¾‘ï¼Œè€Œæ˜¯æ•´åˆåˆ†æ
        })
        
        print(f"         ç›¸é—œæ€§: {correlation:.3f}")
        print(f"         è§¸ç™¼ç‡: {trigger_rate:.1%}")
        print(f"         ç¸½è³ ä»˜: ${np.sum(optimal_payouts)/1e9:.2f}B")
        
        # ç‚ºå…¼å®¹æ€§å‰µå»ºæ©Ÿç‡æå¤±åˆ†å¸ƒ
        print("      ğŸ”„ å»ºç«‹å…¼å®¹æ€§æå¤±åˆ†å¸ƒ...")
        event_loss_distributions = {}
        for event_idx in range(min(n_train, len(damages_array))):
            if event_idx < actual_losses_matrix.shape[1]:
                event_samples = actual_losses_matrix[:, event_idx]
            else:
                # ç‚ºè¶…å‡ºè¨“ç·´ç¯„åœçš„äº‹ä»¶ç”Ÿæˆåˆ†å¸ƒ
                base_loss = damages_array[event_idx]
                event_samples = base_loss * np.random.lognormal(0, 0.3, n_loss_scenarios)
            
            event_loss_distributions[f'event_{event_idx}'] = {
                'mean': float(np.mean(event_samples)),
                'std': float(np.std(event_samples)),
                'samples': event_samples.tolist()[:min(len(event_samples), 100)],  # é™åˆ¶æ¨£æœ¬æ•¸
                'percentiles': {
                    '5th': float(np.percentile(event_samples, 5)),
                    '95th': float(np.percentile(event_samples, 95)),
                    '50th': float(np.percentile(event_samples, 50))
                }
            }
        
        loss_distributions = event_loss_distributions
        
        print(f"   âœ… æ•´åˆåˆ†æå…¨éƒ¨å®Œæˆï¼")
        print(f"      ğŸ“Š ç”Ÿæˆäº† {len(loss_distributions)} å€‹äº‹ä»¶çš„æ©Ÿç‡æ€§æå¤±åˆ†å¸ƒ")
        print(f"      ğŸ¯ æ¯å€‹åˆ†å¸ƒåŒ…å«æœ€å¤š {n_loss_scenarios} å€‹æ¨£æœ¬")
        print(f"      ğŸ† æ¨è–¦ç”¢å“: {bayesian_optimal_product['product_id']}")
        
    except Exception as e:
        print(f"   âŒ æ–°ç‰ˆæ•´åˆè²è‘‰æ–¯åˆ†æå¤±æ•—: {e}")
        print(f"      éŒ¯èª¤è©³æƒ…: {str(e)}")
        print("      ğŸ”„ å›é€€åˆ°åŸå§‹æ–¹æ³•...")
        
        # å°å…¥å…·é«”çš„éŒ¯èª¤ä¿¡æ¯
        import traceback
        print(f"      ğŸ“‹ è©³ç´°éŒ¯èª¤è¿½è¹¤:")
        for line in traceback.format_exc().split('\n')[:5]:  # åªé¡¯ç¤ºå‰5è¡Œ
            if line.strip():
                print(f"         {line}")
        
        modules_available['bayesian'] = False
        bayesian_optimal_product = None
        loss_distributions = {}

else:
    print("   âš ï¸ è·³éæ–°ç‰ˆè²æ°åˆ†æ")
    if not modules_available['bayesian']:
        print("      åŸå› : Bayesian æ¨¡çµ„ä¸å¯ç”¨")
    elif 'tc_hazard' not in main_data:
        print("      åŸå› : tc_hazard æ•¸æ“šæœªæº–å‚™")
    elif 'exposure' not in main_data:
        print("      åŸå› : exposure æ•¸æ“šæœªæº–å‚™")
    
    bayesian_optimal_product = None
    loss_distributions = {}