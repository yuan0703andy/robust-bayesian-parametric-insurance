"""
Event-Level Analysis for Parametric Insurance Products
äº‹ä»¶ç´šåƒæ•¸å‹ä¿éšªç”¢å“åˆ†æ

This module provides detailed event-by-event analysis capabilities for parametric insurance products:
- Figure 5 style basis risk analysis and visualization
- Event severity classification and categorization
- Loss vs payout correlation analysis
- Basis risk categorization (loss_only, payout_only, both_triggered, perfect_match)
- Comprehensive event-level reporting and insights

æœ¬æ¨¡çµ„æä¾›åƒæ•¸å‹ä¿éšªç”¢å“çš„è©³ç´°äº‹ä»¶ç´šåˆ†æåŠŸèƒ½ï¼š
- Figure 5 é¢¨æ ¼çš„åŸºå·®é¢¨éšªåˆ†æå’Œè¦–è¦ºåŒ–
- äº‹ä»¶åš´é‡ç¨‹åº¦åˆ†é¡å’Œåˆ†é¡
- æå¤± vs è³ ä»˜ç›¸é—œæ€§åˆ†æ
- åŸºå·®é¢¨éšªåˆ†é¡ (loss_only, payout_only, both_triggered, perfect_match)
- å…¨é¢çš„äº‹ä»¶ç´šå ±å‘Šå’Œæ´å¯Ÿ
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Union, Any
from dataclasses import dataclass, field
from enum import Enum
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import pearsonr, spearmanr
import warnings

# è¨­ç½®matplotlibä¸­æ–‡å­—é«”
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class BasisRiskCategory(Enum):
    """åŸºå·®é¢¨éšªåˆ†é¡"""
    PERFECT_MATCH = "perfect_match"      # å®Œå…¨åŒ¹é…ï¼šæå¤±å’Œè³ ä»˜éƒ½è§¸ç™¼
    LOSS_ONLY = "loss_only"             # åƒ…æå¤±ï¼šæœ‰æå¤±ä½†ç„¡è³ ä»˜
    PAYOUT_ONLY = "payout_only"         # åƒ…è³ ä»˜ï¼šæœ‰è³ ä»˜ä½†ç„¡é¡¯è‘—æå¤±
    BOTH_TRIGGERED = "both_triggered"    # é›™é‡è§¸ç™¼ï¼šæœ‰æå¤±ä¹Ÿæœ‰è³ ä»˜ä½†ä¸åŒ¹é…
    NO_ACTIVITY = "no_activity"         # ç„¡æ´»å‹•ï¼šç„¡æå¤±ä¹Ÿç„¡è³ ä»˜


class EventSeverity(Enum):
    """äº‹ä»¶åš´é‡ç¨‹åº¦"""
    CATASTROPHIC = "catastrophic"       # ç½é›£æ€§ (> $5B)
    MAJOR = "major"                     # é‡å¤§ ($1B - $5B)
    MODERATE = "moderate"               # ä¸­ç­‰ ($100M - $1B)
    MINOR = "minor"                     # è¼•å¾® ($10M - $100M)
    MINIMAL = "minimal"                 # æ¥µè¼•å¾® (< $10M)


@dataclass
class EventAnalysis:
    """å–®ä¸€äº‹ä»¶åˆ†æçµæœ"""
    event_id: str
    event_name: Optional[str]
    actual_loss: float
    predicted_payout: float
    basis_risk_category: BasisRiskCategory
    severity: EventSeverity
    parametric_indices: Dict[str, float]
    
    # åˆ†ææŒ‡æ¨™
    relative_basis_risk: float  # ç›¸å°åŸºå·®é¢¨éšª = |loss - payout| / max(loss, payout)
    coverage_ratio: float       # è¦†è“‹ç‡ = payout / loss
    trigger_efficiency: float   # è§¸ç™¼æ•ˆç‡ = min(payout, loss) / max(payout, loss)
    
    # å…ƒæ•¸æ“š
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class EventLevelResults:
    """äº‹ä»¶ç´šåˆ†æçµæœ"""
    individual_events: List[EventAnalysis]
    summary_statistics: Dict[str, float]
    basis_risk_distribution: Dict[BasisRiskCategory, int]
    severity_distribution: Dict[EventSeverity, int]
    correlation_metrics: Dict[str, float]
    recommendation_insights: List[str]
    
    # å¯è¦–åŒ–æ•¸æ“š
    visualization_data: Dict[str, Any] = field(default_factory=dict)


class EventLevelAnalyzer:
    """
    äº‹ä»¶ç´šåˆ†æå™¨
    
    æä¾›å…¨é¢çš„äº‹ä»¶ç´šåƒæ•¸å‹ä¿éšªåˆ†æåŠŸèƒ½ï¼š
    - äº‹ä»¶åˆ†é¡å’Œåš´é‡ç¨‹åº¦è©•ä¼°
    - åŸºå·®é¢¨éšªè©³ç´°åˆ†æ
    - è§¸ç™¼æ•ˆç‡å’Œè¦†è“‹ç‡è¨ˆç®—
    - Figure 5 é¢¨æ ¼çš„åˆ†æå’Œè¦–è¦ºåŒ–
    """
    
    def __init__(self, 
                 loss_threshold_minor: float = 1e7,      # $10M
                 loss_threshold_moderate: float = 1e8,   # $100M
                 loss_threshold_major: float = 1e9,      # $1B
                 loss_threshold_catastrophic: float = 5e9, # $5B
                 basis_risk_tolerance: float = 0.2):    # 20% åŸºå·®å®¹å¿åº¦
        """
        åˆå§‹åŒ–äº‹ä»¶ç´šåˆ†æå™¨
        
        Parameters:
        -----------
        loss_threshold_minor : float
            è¼•å¾®äº‹ä»¶æå¤±é–¾å€¼
        loss_threshold_moderate : float
            ä¸­ç­‰äº‹ä»¶æå¤±é–¾å€¼
        loss_threshold_major : float
            é‡å¤§äº‹ä»¶æå¤±é–¾å€¼
        loss_threshold_catastrophic : float
            ç½é›£æ€§äº‹ä»¶æå¤±é–¾å€¼
        basis_risk_tolerance : float
            åŸºå·®é¢¨éšªå®¹å¿åº¦ (ç›¸å°èª¤å·®)
        """
        self.loss_thresholds = {
            'minimal': 0,
            'minor': loss_threshold_minor,
            'moderate': loss_threshold_moderate,
            'major': loss_threshold_major,
            'catastrophic': loss_threshold_catastrophic
        }
        
        self.basis_risk_tolerance = basis_risk_tolerance
        
        # åˆ†æç·©å­˜
        self._analysis_cache = {}
        
        print(f"ğŸ” åˆå§‹åŒ–äº‹ä»¶ç´šåˆ†æå™¨")
        print(f"   æå¤±åˆ†ç´šé–¾å€¼:")
        print(f"     è¼•å¾®: ${loss_threshold_minor/1e6:.0f}M")
        print(f"     ä¸­ç­‰: ${loss_threshold_moderate/1e6:.0f}M") 
        print(f"     é‡å¤§: ${loss_threshold_major/1e9:.1f}B")
        print(f"     ç½é›£æ€§: ${loss_threshold_catastrophic/1e9:.1f}B")
        print(f"   åŸºå·®é¢¨éšªå®¹å¿åº¦: {basis_risk_tolerance*100:.1f}%")
    
    def analyze_events(self,
                      actual_losses: np.ndarray,
                      predicted_payouts: np.ndarray,
                      parametric_indices: Dict[str, np.ndarray],
                      event_metadata: Optional[pd.DataFrame] = None) -> EventLevelResults:
        """
        å®Œæ•´çš„äº‹ä»¶ç´šåˆ†æ
        
        Parameters:
        -----------
        actual_losses : np.ndarray
            å¯¦éš›æå¤±æ•¸çµ„
        predicted_payouts : np.ndarray
            é æ¸¬è³ ä»˜æ•¸çµ„
        parametric_indices : Dict[str, np.ndarray]
            åƒæ•¸æŒ‡æ¨™å­—å…¸
        event_metadata : pd.DataFrame, optional
            äº‹ä»¶å…ƒæ•¸æ“š
            
        Returns:
        --------
        EventLevelResults
            å®Œæ•´çš„äº‹ä»¶ç´šåˆ†æçµæœ
        """
        
        print(f"ğŸ”„ é–‹å§‹äº‹ä»¶ç´šè©³ç´°åˆ†æ...")
        print(f"   åˆ†æäº‹ä»¶æ•¸: {len(actual_losses)}")
        print(f"   åƒæ•¸æŒ‡æ¨™æ•¸: {len(parametric_indices)}")
        
        # é©—è­‰è¼¸å…¥
        self._validate_inputs(actual_losses, predicted_payouts, parametric_indices)
        
        # é€äº‹ä»¶åˆ†æ
        individual_events = []
        
        for i in range(len(actual_losses)):
            event_analysis = self._analyze_single_event(
                event_index=i,
                actual_loss=actual_losses[i],
                predicted_payout=predicted_payouts[i],
                parametric_indices={key: values[i] for key, values in parametric_indices.items()},
                event_metadata=event_metadata.iloc[i] if event_metadata is not None else None
            )
            individual_events.append(event_analysis)
        
        # è¨ˆç®—ç¸½é«”çµ±è¨ˆ
        summary_stats = self._calculate_summary_statistics(individual_events)
        
        # åˆ†å¸ƒçµ±è¨ˆ
        basis_risk_dist = self._calculate_basis_risk_distribution(individual_events)
        severity_dist = self._calculate_severity_distribution(individual_events)
        
        # ç›¸é—œæ€§åˆ†æ
        correlation_metrics = self._calculate_correlation_metrics(
            actual_losses, predicted_payouts, parametric_indices
        )
        
        # ç”Ÿæˆæ´å¯Ÿå’Œå»ºè­°
        insights = self._generate_insights(
            individual_events, summary_stats, basis_risk_dist, correlation_metrics
        )
        
        # æº–å‚™è¦–è¦ºåŒ–æ•¸æ“š
        viz_data = self._prepare_visualization_data(
            individual_events, actual_losses, predicted_payouts
        )
        
        results = EventLevelResults(
            individual_events=individual_events,
            summary_statistics=summary_stats,
            basis_risk_distribution=basis_risk_dist,
            severity_distribution=severity_dist,
            correlation_metrics=correlation_metrics,
            recommendation_insights=insights,
            visualization_data=viz_data
        )
        
        print(f"âœ… äº‹ä»¶ç´šåˆ†æå®Œæˆï¼")
        print(f"   åˆ†æäº‹ä»¶: {len(individual_events)}")
        print(f"   åŸºå·®é¢¨éšªåˆ†é¡: {len(basis_risk_dist)} ç¨®")
        print(f"   ç”Ÿæˆæ´å¯Ÿ: {len(insights)} æ¢")
        
        return results
    
    def _validate_inputs(self, actual_losses, predicted_payouts, parametric_indices):
        """é©—è­‰è¼¸å…¥æ•¸æ“šçš„æœ‰æ•ˆæ€§"""
        n_events = len(actual_losses)
        
        if len(predicted_payouts) != n_events:
            raise ValueError(f"Length mismatch: losses={n_events}, payouts={len(predicted_payouts)}")
        
        for key, values in parametric_indices.items():
            if len(values) != n_events:
                raise ValueError(f"Parametric index '{key}' length mismatch: {len(values)} != {n_events}")
        
        # æª¢æŸ¥æ•¸å€¼æœ‰æ•ˆæ€§
        if np.any(actual_losses < 0):
            warnings.warn("Negative losses detected")
        if np.any(predicted_payouts < 0):
            warnings.warn("Negative payouts detected")
    
    def _analyze_single_event(self,
                            event_index: int,
                            actual_loss: float,
                            predicted_payout: float,
                            parametric_indices: Dict[str, float],
                            event_metadata: Optional[pd.Series] = None) -> EventAnalysis:
        """åˆ†æå–®ä¸€äº‹ä»¶"""
        
        # åŸºæœ¬è³‡è¨Š
        event_id = f"event_{event_index:04d}"
        event_name = None
        
        if event_metadata is not None:
            if 'event_id' in event_metadata:
                event_id = event_metadata['event_id']
            if 'event_name' in event_metadata:
                event_name = event_metadata['event_name']
        
        # åˆ†é¡
        severity = self._classify_event_severity(actual_loss)
        basis_risk_category = self._classify_basis_risk(actual_loss, predicted_payout)
        
        # è¨ˆç®—é¢¨éšªæŒ‡æ¨™
        relative_basis_risk = self._calculate_relative_basis_risk(actual_loss, predicted_payout)
        coverage_ratio = self._calculate_coverage_ratio(actual_loss, predicted_payout)
        trigger_efficiency = self._calculate_trigger_efficiency(actual_loss, predicted_payout)
        
        # å…ƒæ•¸æ“š
        metadata = {}
        if event_metadata is not None:
            metadata = event_metadata.to_dict()
        
        return EventAnalysis(
            event_id=event_id,
            event_name=event_name,
            actual_loss=actual_loss,
            predicted_payout=predicted_payout,
            basis_risk_category=basis_risk_category,
            severity=severity,
            parametric_indices=parametric_indices,
            relative_basis_risk=relative_basis_risk,
            coverage_ratio=coverage_ratio,
            trigger_efficiency=trigger_efficiency,
            metadata=metadata
        )
    
    def _classify_event_severity(self, loss: float) -> EventSeverity:
        """æ ¹æ“šæå¤±å¤§å°åˆ†é¡äº‹ä»¶åš´é‡ç¨‹åº¦"""
        if loss >= self.loss_thresholds['catastrophic']:
            return EventSeverity.CATASTROPHIC
        elif loss >= self.loss_thresholds['major']:
            return EventSeverity.MAJOR
        elif loss >= self.loss_thresholds['moderate']:
            return EventSeverity.MODERATE
        elif loss >= self.loss_thresholds['minor']:
            return EventSeverity.MINOR
        else:
            return EventSeverity.MINIMAL
    
    def _classify_basis_risk(self, loss: float, payout: float) -> BasisRiskCategory:
        """åˆ†é¡åŸºå·®é¢¨éšªé¡å‹"""
        loss_significant = loss > self.loss_thresholds['minor']
        payout_significant = payout > self.loss_thresholds['minor']
        
        if not loss_significant and not payout_significant:
            return BasisRiskCategory.NO_ACTIVITY
        elif loss_significant and not payout_significant:
            return BasisRiskCategory.LOSS_ONLY
        elif not loss_significant and payout_significant:
            return BasisRiskCategory.PAYOUT_ONLY
        else:
            # å…©è€…éƒ½æœ‰ï¼Œæª¢æŸ¥åŒ¹é…ç¨‹åº¦
            relative_error = abs(loss - payout) / max(loss, payout)
            if relative_error <= self.basis_risk_tolerance:
                return BasisRiskCategory.PERFECT_MATCH
            else:
                return BasisRiskCategory.BOTH_TRIGGERED
    
    def _calculate_relative_basis_risk(self, loss: float, payout: float) -> float:
        """è¨ˆç®—ç›¸å°åŸºå·®é¢¨éšª"""
        if max(loss, payout) == 0:
            return 0.0
        return abs(loss - payout) / max(loss, payout)
    
    def _calculate_coverage_ratio(self, loss: float, payout: float) -> float:
        """è¨ˆç®—è¦†è“‹ç‡"""
        if loss == 0:
            return float('inf') if payout > 0 else 1.0
        return payout / loss
    
    def _calculate_trigger_efficiency(self, loss: float, payout: float) -> float:
        """è¨ˆç®—è§¸ç™¼æ•ˆç‡"""
        if max(loss, payout) == 0:
            return 1.0
        return min(loss, payout) / max(loss, payout)
    
    def _calculate_summary_statistics(self, events: List[EventAnalysis]) -> Dict[str, float]:
        """è¨ˆç®—ç¸½é«”çµ±è¨ˆæŒ‡æ¨™"""
        if not events:
            return {}
        
        # æå–æ•¸å€¼
        losses = [e.actual_loss for e in events]
        payouts = [e.predicted_payout for e in events]
        basis_risks = [e.relative_basis_risk for e in events]
        coverage_ratios = [e.coverage_ratio for e in events if not np.isinf(e.coverage_ratio)]
        trigger_efficiencies = [e.trigger_efficiency for e in events]
        
        return {
            'total_events': len(events),
            'total_actual_loss': np.sum(losses),
            'total_predicted_payout': np.sum(payouts),
            'mean_actual_loss': np.mean(losses),
            'mean_predicted_payout': np.mean(payouts),
            'median_actual_loss': np.median(losses),
            'median_predicted_payout': np.median(payouts),
            'std_actual_loss': np.std(losses),
            'std_predicted_payout': np.std(payouts),
            'mean_relative_basis_risk': np.mean(basis_risks),
            'median_relative_basis_risk': np.median(basis_risks),
            'mean_coverage_ratio': np.mean(coverage_ratios) if coverage_ratios else 0,
            'mean_trigger_efficiency': np.mean(trigger_efficiencies),
            'max_loss_event_loss': np.max(losses),
            'max_payout_event_payout': np.max(payouts),
            'correlation_loss_payout': pearsonr(losses, payouts)[0] if len(losses) > 1 else 0
        }
    
    def _calculate_basis_risk_distribution(self, events: List[EventAnalysis]) -> Dict[BasisRiskCategory, int]:
        """è¨ˆç®—åŸºå·®é¢¨éšªåˆ†å¸ƒ"""
        distribution = {category: 0 for category in BasisRiskCategory}
        
        for event in events:
            distribution[event.basis_risk_category] += 1
        
        return distribution
    
    def _calculate_severity_distribution(self, events: List[EventAnalysis]) -> Dict[EventSeverity, int]:
        """è¨ˆç®—åš´é‡ç¨‹åº¦åˆ†å¸ƒ"""
        distribution = {severity: 0 for severity in EventSeverity}
        
        for event in events:
            distribution[event.severity] += 1
        
        return distribution
    
    def _calculate_correlation_metrics(self,
                                     actual_losses: np.ndarray,
                                     predicted_payouts: np.ndarray,
                                     parametric_indices: Dict[str, np.ndarray]) -> Dict[str, float]:
        """è¨ˆç®—ç›¸é—œæ€§æŒ‡æ¨™"""
        metrics = {}
        
        # æå¤±èˆ‡è³ ä»˜ç›¸é—œæ€§
        if len(actual_losses) > 1:
            pearson_r, pearson_p = pearsonr(actual_losses, predicted_payouts)
            spearman_r, spearman_p = spearmanr(actual_losses, predicted_payouts)
            
            metrics['loss_payout_pearson'] = pearson_r
            metrics['loss_payout_pearson_pvalue'] = pearson_p
            metrics['loss_payout_spearman'] = spearman_r
            metrics['loss_payout_spearman_pvalue'] = spearman_p
        
        # åƒæ•¸æŒ‡æ¨™èˆ‡æå¤±çš„ç›¸é—œæ€§
        for index_name, index_values in parametric_indices.items():
            if len(index_values) > 1 and np.std(index_values) > 0:
                try:
                    pearson_r, _ = pearsonr(index_values, actual_losses)
                    metrics[f'{index_name}_loss_correlation'] = pearson_r
                except:
                    metrics[f'{index_name}_loss_correlation'] = 0.0
        
        # åƒæ•¸æŒ‡æ¨™èˆ‡è³ ä»˜çš„ç›¸é—œæ€§
        for index_name, index_values in parametric_indices.items():
            if len(index_values) > 1 and np.std(index_values) > 0:
                try:
                    pearson_r, _ = pearsonr(index_values, predicted_payouts)
                    metrics[f'{index_name}_payout_correlation'] = pearson_r
                except:
                    metrics[f'{index_name}_payout_correlation'] = 0.0
        
        return metrics
    
    def _generate_insights(self,
                          events: List[EventAnalysis],
                          summary_stats: Dict[str, float],
                          basis_risk_dist: Dict[BasisRiskCategory, int],
                          correlation_metrics: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆåˆ†ææ´å¯Ÿå’Œå»ºè­°"""
        insights = []
        
        total_events = len(events)
        if total_events == 0:
            return ["ç„¡å¯åˆ†æçš„äº‹ä»¶æ•¸æ“š"]
        
        # åŸºå·®é¢¨éšªåˆ†æ
        perfect_match_rate = basis_risk_dist[BasisRiskCategory.PERFECT_MATCH] / total_events
        loss_only_rate = basis_risk_dist[BasisRiskCategory.LOSS_ONLY] / total_events
        payout_only_rate = basis_risk_dist[BasisRiskCategory.PAYOUT_ONLY] / total_events
        
        if perfect_match_rate > 0.7:
            insights.append(f"âœ… ç”¢å“è¡¨ç¾å„ªç§€ï¼š{perfect_match_rate*100:.1f}% çš„äº‹ä»¶å¯¦ç¾å®Œç¾åŒ¹é…")
        elif perfect_match_rate > 0.5:
            insights.append(f"ğŸ”„ ç”¢å“è¡¨ç¾è‰¯å¥½ï¼š{perfect_match_rate*100:.1f}% çš„äº‹ä»¶å¯¦ç¾å®Œç¾åŒ¹é…ï¼Œæœ‰æ”¹å–„ç©ºé–“")
        else:
            insights.append(f"âš ï¸ ç”¢å“éœ€è¦å„ªåŒ–ï¼šåƒ… {perfect_match_rate*100:.1f}% çš„äº‹ä»¶å¯¦ç¾å®Œç¾åŒ¹é…")
        
        if loss_only_rate > 0.3:
            insights.append(f"ğŸ“‰ åŸºå·®é¢¨éšªè­¦å‘Šï¼š{loss_only_rate*100:.1f}% çš„æå¤±äº‹ä»¶æœªç²å¾—è³ ä»˜ï¼Œå»ºè­°é™ä½è§¸ç™¼é–¾å€¼")
        
        if payout_only_rate > 0.2:
            insights.append(f"ğŸ’° éåº¦è³ ä»˜é¢¨éšªï¼š{payout_only_rate*100:.1f}% çš„è³ ä»˜ç™¼ç”Ÿåœ¨ç„¡é‡å¤§æå¤±æ™‚ï¼Œå»ºè­°æé«˜è§¸ç™¼é–¾å€¼")
        
        # ç›¸é—œæ€§åˆ†æ
        loss_payout_corr = correlation_metrics.get('loss_payout_pearson', 0)
        if loss_payout_corr > 0.8:
            insights.append(f"ğŸ¯ å¼·ç›¸é—œæ€§ï¼šæå¤±èˆ‡è³ ä»˜ç›¸é—œä¿‚æ•¸ {loss_payout_corr:.3f}ï¼Œç”¢å“è¨­è¨ˆéå¸¸æœ‰æ•ˆ")
        elif loss_payout_corr > 0.6:
            insights.append(f"ğŸ‘ ä¸­ç­‰ç›¸é—œæ€§ï¼šæå¤±èˆ‡è³ ä»˜ç›¸é—œä¿‚æ•¸ {loss_payout_corr:.3f}ï¼Œç”¢å“è¨­è¨ˆåŸºæœ¬æœ‰æ•ˆ")
        else:
            insights.append(f"âš ï¸ å¼±ç›¸é—œæ€§ï¼šæå¤±èˆ‡è³ ä»˜ç›¸é—œä¿‚æ•¸ {loss_payout_corr:.3f}ï¼Œéœ€è¦é‡æ–°è¨­è¨ˆåƒæ•¸æŒ‡æ¨™")
        
        # è¦†è“‹ç‡åˆ†æ
        mean_coverage = summary_stats.get('mean_coverage_ratio', 0)
        if mean_coverage > 1.5:
            insights.append(f"ğŸ“ˆ éåº¦è¦†è“‹ï¼šå¹³å‡è¦†è“‹ç‡ {mean_coverage:.2f}ï¼Œå¯èƒ½å­˜åœ¨é“å¾·é¢¨éšª")
        elif mean_coverage < 0.5:
            insights.append(f"ğŸ“‰ è¦†è“‹ä¸è¶³ï¼šå¹³å‡è¦†è“‹ç‡ {mean_coverage:.2f}ï¼Œç„¡æ³•æœ‰æ•ˆè½‰ç§»é¢¨éšª")
        else:
            insights.append(f"âœ… é©ç•¶è¦†è“‹ï¼šå¹³å‡è¦†è“‹ç‡ {mean_coverage:.2f}ï¼Œé¢¨éšªè½‰ç§»æ•ˆæœè‰¯å¥½")
        
        # æœ€ä½³åƒæ•¸æŒ‡æ¨™è­˜åˆ¥
        best_corr = 0
        best_index = None
        for key, value in correlation_metrics.items():
            if '_loss_correlation' in key and abs(value) > abs(best_corr):
                best_corr = value
                best_index = key.replace('_loss_correlation', '')
        
        if best_index and abs(best_corr) > 0.7:
            insights.append(f"ğŸ† æœ€ä½³åƒæ•¸æŒ‡æ¨™ï¼š{best_index} (ç›¸é—œä¿‚æ•¸ {best_corr:.3f})")
        
        return insights
    
    def _prepare_visualization_data(self,
                                  events: List[EventAnalysis],
                                  actual_losses: np.ndarray,
                                  predicted_payouts: np.ndarray) -> Dict[str, Any]:
        """æº–å‚™è¦–è¦ºåŒ–æ•¸æ“š"""
        return {
            'scatter_data': {
                'actual_losses': actual_losses,
                'predicted_payouts': predicted_payouts,
                'basis_risk_categories': [e.basis_risk_category.value for e in events],
                'severities': [e.severity.value for e in events],
                'event_ids': [e.event_id for e in events]
            },
            'distribution_data': {
                'relative_basis_risks': [e.relative_basis_risk for e in events],
                'coverage_ratios': [e.coverage_ratio for e in events if not np.isinf(e.coverage_ratio)],
                'trigger_efficiencies': [e.trigger_efficiency for e in events]
            }
        }
    
    def create_loss_vs_payout_analysis(self, results: EventLevelResults,
                                     figsize: Tuple[int, int] = (15, 10),
                                     save_path: Optional[str] = None) -> plt.Figure:
        """
        å‰µå»º Figure 5 é¢¨æ ¼çš„æå¤± vs è³ ä»˜åˆ†æåœ–
        
        Parameters:
        -----------
        results : EventLevelResults
            äº‹ä»¶ç´šåˆ†æçµæœ
        figsize : Tuple[int, int]
            åœ–è¡¨å¤§å°
        save_path : str, optional
            ä¿å­˜è·¯å¾‘
            
        Returns:
        --------
        plt.Figure
            åœ–è¡¨å°è±¡
        """
        
        fig, axes = plt.subplots(2, 2, figsize=figsize)
        fig.suptitle('äº‹ä»¶ç´šæå¤± vs è³ ä»˜åˆ†æ (Figure 5 é¢¨æ ¼)', fontsize=16, fontweight='bold')
        
        scatter_data = results.visualization_data['scatter_data']
        dist_data = results.visualization_data['distribution_data']
        
        # å­åœ–1: æå¤± vs è³ ä»˜æ•£é»åœ– (æŒ‰åŸºå·®é¢¨éšªåˆ†é¡)
        ax1 = axes[0, 0]
        
        # åŸºå·®é¢¨éšªé¡åˆ¥é¡è‰²æ˜ å°„
        color_map = {
            'perfect_match': '#2E8B57',    # æµ·ç¶ è‰²
            'both_triggered': '#FFD700',   # é‡‘è‰²
            'loss_only': '#DC143C',        # æ·±ç´…è‰²
            'payout_only': '#4169E1',      # çš‡å®¶è—
            'no_activity': '#708090'       # çŸ³æ¿ç°
        }
        
        for category in set(scatter_data['basis_risk_categories']):
            mask = np.array(scatter_data['basis_risk_categories']) == category
            ax1.scatter(
                np.array(scatter_data['actual_losses'])[mask] / 1e9,
                np.array(scatter_data['predicted_payouts'])[mask] / 1e9,
                c=color_map.get(category, '#000000'),
                label=category.replace('_', ' ').title(),
                alpha=0.7,
                s=50
            )
        
        # æ·»åŠ å°è§’ç·š (å®Œç¾åŒ¹é…ç·š)
        max_val = max(
            np.max(scatter_data['actual_losses']) / 1e9,
            np.max(scatter_data['predicted_payouts']) / 1e9
        )
        ax1.plot([0, max_val], [0, max_val], 'k--', alpha=0.5, label='å®Œç¾åŒ¹é…ç·š')
        
        ax1.set_xlabel('å¯¦éš›æå¤± (åå„„ç¾å…ƒ)')
        ax1.set_ylabel('é æ¸¬è³ ä»˜ (åå„„ç¾å…ƒ)')
        ax1.set_title('æå¤± vs è³ ä»˜ (æŒ‰åŸºå·®é¢¨éšªåˆ†é¡)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # å­åœ–2: æå¤± vs è³ ä»˜æ•£é»åœ– (æŒ‰äº‹ä»¶åš´é‡ç¨‹åº¦)
        ax2 = axes[0, 1]
        
        severity_colors = {
            'catastrophic': '#8B0000',    # æ·±ç´…
            'major': '#FF4500',           # æ©™ç´…
            'moderate': '#FFA500',        # æ©™è‰²
            'minor': '#FFD700',           # é‡‘è‰²
            'minimal': '#90EE90'          # æ·ºç¶ 
        }
        
        for severity in set(scatter_data['severities']):
            mask = np.array(scatter_data['severities']) == severity
            ax2.scatter(
                np.array(scatter_data['actual_losses'])[mask] / 1e9,
                np.array(scatter_data['predicted_payouts'])[mask] / 1e9,
                c=severity_colors.get(severity, '#000000'),
                label=severity.title(),
                alpha=0.7,
                s=50
            )
        
        ax2.plot([0, max_val], [0, max_val], 'k--', alpha=0.5)
        ax2.set_xlabel('å¯¦éš›æå¤± (åå„„ç¾å…ƒ)')
        ax2.set_ylabel('é æ¸¬è³ ä»˜ (åå„„ç¾å…ƒ)')
        ax2.set_title('æå¤± vs è³ ä»˜ (æŒ‰äº‹ä»¶åš´é‡ç¨‹åº¦)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # å­åœ–3: ç›¸å°åŸºå·®é¢¨éšªåˆ†å¸ƒ
        ax3 = axes[1, 0]
        
        basis_risks = dist_data['relative_basis_risks']
        ax3.hist(basis_risks, bins=30, alpha=0.7, color='skyblue', edgecolor='black')
        ax3.axvline(np.mean(basis_risks), color='red', linestyle='--', label=f'å¹³å‡å€¼: {np.mean(basis_risks):.3f}')
        ax3.axvline(np.median(basis_risks), color='orange', linestyle='--', label=f'ä¸­ä½æ•¸: {np.median(basis_risks):.3f}')
        
        ax3.set_xlabel('ç›¸å°åŸºå·®é¢¨éšª')
        ax3.set_ylabel('äº‹ä»¶æ•¸é‡')
        ax3.set_title('ç›¸å°åŸºå·®é¢¨éšªåˆ†å¸ƒ')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # å­åœ–4: è¦†è“‹ç‡åˆ†å¸ƒ
        ax4 = axes[1, 1]
        
        coverage_ratios = [cr for cr in dist_data['coverage_ratios'] if cr <= 5]  # é™åˆ¶ç•°å¸¸å€¼
        if coverage_ratios:
            ax4.hist(coverage_ratios, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
            ax4.axvline(np.mean(coverage_ratios), color='red', linestyle='--', 
                       label=f'å¹³å‡å€¼: {np.mean(coverage_ratios):.2f}')
            ax4.axvline(1.0, color='green', linestyle='-', linewidth=2, label='å®Œç¾è¦†è“‹')
        
        ax4.set_xlabel('è¦†è“‹ç‡ (è³ ä»˜/æå¤±)')
        ax4.set_ylabel('äº‹ä»¶æ•¸é‡')
        ax4.set_title('è¦†è“‹ç‡åˆ†å¸ƒ')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"ğŸ’¾ åœ–è¡¨å·²ä¿å­˜åˆ°: {save_path}")
        
        return fig
    
    def generate_event_analysis_report(self, results: EventLevelResults) -> str:
        """
        ç”Ÿæˆå…¨é¢çš„äº‹ä»¶ç´šåˆ†æå ±å‘Š
        
        Parameters:
        -----------
        results : EventLevelResults
            äº‹ä»¶ç´šåˆ†æçµæœ
            
        Returns:
        --------
        str
            æ ¼å¼åŒ–çš„åˆ†æå ±å‘Š
        """
        
        report = []
        report.append("=" * 80)
        report.append("                    äº‹ä»¶ç´šåƒæ•¸å‹ä¿éšªåˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # ç¸½é«”çµ±è¨ˆ
        stats = results.summary_statistics
        report.append("ğŸ“Š ç¸½é«”çµ±è¨ˆ")
        report.append("-" * 40)
        report.append(f"åˆ†æäº‹ä»¶ç¸½æ•¸: {int(stats['total_events'])}")
        report.append(f"ç¸½å¯¦éš›æå¤±: ${stats['total_actual_loss']/1e9:.2f}B")
        report.append(f"ç¸½é æ¸¬è³ ä»˜: ${stats['total_predicted_payout']/1e9:.2f}B")
        report.append(f"å¹³å‡äº‹ä»¶æå¤±: ${stats['mean_actual_loss']/1e6:.1f}M")
        report.append(f"å¹³å‡äº‹ä»¶è³ ä»˜: ${stats['mean_predicted_payout']/1e6:.1f}M")
        report.append(f"æå¤±-è³ ä»˜ç›¸é—œä¿‚æ•¸: {stats['correlation_loss_payout']:.3f}")
        report.append("")
        
        # åŸºå·®é¢¨éšªåˆ†å¸ƒ
        report.append("ğŸ¯ åŸºå·®é¢¨éšªåˆ†æ")
        report.append("-" * 40)
        total_events = stats['total_events']
        for category, count in results.basis_risk_distribution.items():
            percentage = (count / total_events) * 100
            report.append(f"{category.value.replace('_', ' ').title():<20}: {count:>3} ({percentage:>5.1f}%)")
        
        report.append(f"å¹³å‡ç›¸å°åŸºå·®é¢¨éšª: {stats['mean_relative_basis_risk']:.3f}")
        report.append("")
        
        # åš´é‡ç¨‹åº¦åˆ†å¸ƒ
        report.append("âš¡ äº‹ä»¶åš´é‡ç¨‹åº¦åˆ†å¸ƒ")
        report.append("-" * 40)
        for severity, count in results.severity_distribution.items():
            percentage = (count / total_events) * 100
            report.append(f"{severity.value.title():<20}: {count:>3} ({percentage:>5.1f}%)")
        report.append("")
        
        # é—œéµæ´å¯Ÿ
        report.append("ğŸ’¡ é—œéµæ´å¯Ÿèˆ‡å»ºè­°")
        report.append("-" * 40)
        for i, insight in enumerate(results.recommendation_insights, 1):
            report.append(f"{i:>2}. {insight}")
        report.append("")
        
        # é ‚ç´šäº‹ä»¶åˆ†æ
        report.append("ğŸ† é—œéµäº‹ä»¶åˆ†æ")
        report.append("-" * 40)
        
        # æ‰¾å‡ºæœ€å¤§æå¤±äº‹ä»¶
        max_loss_event = max(results.individual_events, key=lambda e: e.actual_loss)
        report.append(f"æœ€å¤§æå¤±äº‹ä»¶: {max_loss_event.event_id}")
        report.append(f"  å¯¦éš›æå¤±: ${max_loss_event.actual_loss/1e9:.2f}B")
        report.append(f"  é æ¸¬è³ ä»˜: ${max_loss_event.predicted_payout/1e9:.2f}B")
        report.append(f"  è¦†è“‹ç‡: {max_loss_event.coverage_ratio:.2f}")
        report.append(f"  åŸºå·®é¢¨éšªé¡åˆ¥: {max_loss_event.basis_risk_category.value}")
        
        # æ‰¾å‡ºæœ€å¤§åŸºå·®é¢¨éšªäº‹ä»¶
        max_basis_risk_event = max(results.individual_events, key=lambda e: e.relative_basis_risk)
        report.append(f"æœ€å¤§åŸºå·®é¢¨éšªäº‹ä»¶: {max_basis_risk_event.event_id}")
        report.append(f"  ç›¸å°åŸºå·®é¢¨éšª: {max_basis_risk_event.relative_basis_risk:.3f}")
        report.append(f"  å¯¦éš›æå¤±: ${max_basis_risk_event.actual_loss/1e6:.1f}M")
        report.append(f"  é æ¸¬è³ ä»˜: ${max_basis_risk_event.predicted_payout/1e6:.1f}M")
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def export_detailed_results(self, results: EventLevelResults, 
                              output_path: str,
                              include_visualization: bool = True) -> None:
        """
        å°å‡ºè©³ç´°çš„äº‹ä»¶ç´šåˆ†æçµæœ
        
        Parameters:
        -----------
        results : EventLevelResults
            åˆ†æçµæœ
        output_path : str
            è¼¸å‡ºè·¯å¾‘ (ä¸å«å‰¯æª”å)
        include_visualization : bool
            æ˜¯å¦åŒ…å«è¦–è¦ºåŒ–
        """
        
        # 1. å°å‡ºäº‹ä»¶è©³æƒ…ç‚º CSV
        events_data = []
        for event in results.individual_events:
            event_dict = {
                'event_id': event.event_id,
                'event_name': event.event_name,
                'actual_loss': event.actual_loss,
                'predicted_payout': event.predicted_payout,
                'basis_risk_category': event.basis_risk_category.value,
                'severity': event.severity.value,
                'relative_basis_risk': event.relative_basis_risk,
                'coverage_ratio': event.coverage_ratio,
                'trigger_efficiency': event.trigger_efficiency
            }
            
            # æ·»åŠ åƒæ•¸æŒ‡æ¨™
            for key, value in event.parametric_indices.items():
                event_dict[f'param_{key}'] = value
            
            events_data.append(event_dict)
        
        events_df = pd.DataFrame(events_data)
        events_df.to_csv(f"{output_path}_events_detail.csv", index=False, encoding='utf-8-sig')
        
        # 2. å°å‡ºåˆ†æå ±å‘Šç‚ºæ–‡æœ¬æ–‡ä»¶
        report = self.generate_event_analysis_report(results)
        with open(f"{output_path}_analysis_report.txt", 'w', encoding='utf-8') as f:
            f.write(report)
        
        # 3. å°å‡ºæ‘˜è¦çµ±è¨ˆç‚º JSON
        import json
        summary = {
            'summary_statistics': results.summary_statistics,
            'basis_risk_distribution': {k.value: v for k, v in results.basis_risk_distribution.items()},
            'severity_distribution': {k.value: v for k, v in results.severity_distribution.items()},
            'correlation_metrics': results.correlation_metrics,
            'recommendation_insights': results.recommendation_insights
        }
        
        with open(f"{output_path}_summary.json", 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # 4. å‰µå»ºä¸¦ä¿å­˜è¦–è¦ºåŒ–
        if include_visualization:
            fig = self.create_loss_vs_payout_analysis(results, save_path=f"{output_path}_visualization.png")
            plt.close(fig)
        
        print(f"âœ… äº‹ä»¶ç´šåˆ†æçµæœå·²å°å‡ºåˆ°: {output_path}_*")
        print(f"   - äº‹ä»¶è©³æƒ…: {output_path}_events_detail.csv")
        print(f"   - åˆ†æå ±å‘Š: {output_path}_analysis_report.txt")
        print(f"   - æ‘˜è¦çµ±è¨ˆ: {output_path}_summary.json")
        if include_visualization:
            print(f"   - è¦–è¦ºåŒ–åœ–è¡¨: {output_path}_visualization.png")


# ä¾¿åˆ©å‡½æ•¸

def quick_event_analysis(actual_losses: np.ndarray,
                        predicted_payouts: np.ndarray,
                        parametric_indices: Dict[str, np.ndarray],
                        event_metadata: Optional[pd.DataFrame] = None,
                        output_prefix: Optional[str] = None) -> EventLevelResults:
    """
    å¿«é€Ÿäº‹ä»¶ç´šåˆ†æ
    
    Parameters:
    -----------
    actual_losses : np.ndarray
        å¯¦éš›æå¤±
    predicted_payouts : np.ndarray
        é æ¸¬è³ ä»˜
    parametric_indices : Dict[str, np.ndarray]
        åƒæ•¸æŒ‡æ¨™
    event_metadata : pd.DataFrame, optional
        äº‹ä»¶å…ƒæ•¸æ“š
    output_prefix : str, optional
        è¼¸å‡ºæ–‡ä»¶å‰ç¶´
        
    Returns:
    --------
    EventLevelResults
        åˆ†æçµæœ
    """
    
    analyzer = EventLevelAnalyzer()
    results = analyzer.analyze_events(
        actual_losses, predicted_payouts, parametric_indices, event_metadata
    )
    
    # è¼¸å‡ºå ±å‘Š
    print(analyzer.generate_event_analysis_report(results))
    
    # ä¿å­˜çµæœ
    if output_prefix:
        analyzer.export_detailed_results(results, output_prefix)
    
    return results


def compare_product_event_performance(products_results: Dict[str, EventLevelResults]) -> pd.DataFrame:
    """
    æ¯”è¼ƒå¤šå€‹ç”¢å“çš„äº‹ä»¶ç´šè¡¨ç¾
    
    Parameters:
    -----------
    products_results : Dict[str, EventLevelResults]
        ç”¢å“çµæœå­—å…¸ {product_name: results}
        
    Returns:
    --------
    pd.DataFrame
        æ¯”è¼ƒè¡¨
    """
    
    comparison_data = []
    
    for product_name, results in products_results.items():
        stats = results.summary_statistics
        basis_risk_dist = results.basis_risk_distribution
        
        # è¨ˆç®—é—œéµæŒ‡æ¨™
        total_events = stats['total_events']
        perfect_match_rate = basis_risk_dist[BasisRiskCategory.PERFECT_MATCH] / total_events
        loss_only_rate = basis_risk_dist[BasisRiskCategory.LOSS_ONLY] / total_events
        
        comparison_data.append({
            'product_name': product_name,
            'total_events': int(total_events),
            'perfect_match_rate': perfect_match_rate,
            'loss_only_rate': loss_only_rate,
            'mean_basis_risk': stats['mean_relative_basis_risk'],
            'loss_payout_correlation': stats['correlation_loss_payout'],
            'mean_coverage_ratio': stats.get('mean_coverage_ratio', 0),
            'total_loss_billion': stats['total_actual_loss'] / 1e9,
            'total_payout_billion': stats['total_predicted_payout'] / 1e9
        })
    
    return pd.DataFrame(comparison_data)