"""
Test script for the new Bayesian framework
æ¸¬è©¦æ–°çš„è²è‘‰æ–¯æ¡†æ¶

This script demonstrates the integrated Method 1 (Model Comparison) and 
Method 2 (Bayesian Decision Theory) frameworks.
"""

import numpy as np
import sys
import os

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def generate_sample_data(n_observations=100, random_seed=42):
    """Generate sample loss and hazard data for testing"""
    
    np.random.seed(random_seed)
    
    # Generate hazard indices (e.g., wind speeds)
    hazard_indices = np.random.uniform(25, 65, n_observations)
    
    # Generate losses based on hazard indices with some noise
    base_losses = np.zeros_like(hazard_indices)
    
    # Threshold-based loss generation
    for i, hazard in enumerate(hazard_indices):
        if hazard < 35:
            # Minor events - mostly zero losses
            base_losses[i] = np.random.exponential(1e6) if np.random.random() < 0.2 else 0
        elif hazard < 45:
            # Moderate events
            base_losses[i] = np.random.lognormal(np.log(5e7), 0.5)
        elif hazard < 55:
            # Severe events
            base_losses[i] = np.random.lognormal(np.log(1.5e8), 0.6)
        else:
            # Extreme events
            base_losses[i] = np.random.lognormal(np.log(4e8), 0.8)
    
    # Add some additional noise
    noise_factor = np.random.lognormal(0, 0.1, n_observations)
    observed_losses = base_losses * noise_factor
    
    return observed_losses, hazard_indices

def test_model_comparison_framework():
    """Test Method 1: Model Comparison Framework"""
    
    print("ğŸ”¬ æ¸¬è©¦æ–¹æ³•ä¸€ï¼šæ¨¡å‹æ¯”è¼ƒæ¡†æ¶")
    print("=" * 60)
    
    try:
        from bayesian import BayesianModelComparison
        
        # Generate sample data
        observed_losses, hazard_indices = generate_sample_data(50)  # Smaller dataset for testing
        
        # Split into train/validation
        n_train = 40
        train_losses = observed_losses[:n_train]
        val_losses = observed_losses[n_train:]
        train_indices = hazard_indices[:n_train]
        val_indices = hazard_indices[n_train:]
        
        print(f"ğŸ“Š æ•¸æ“š: è¨“ç·´({n_train}) / é©—è­‰({len(val_losses)})")
        
        # Initialize model comparison
        model_comparison = BayesianModelComparison(
            n_samples=200,  # Small for testing
            n_chains=2,
            random_seed=42
        )
        
        # Prepare model arguments
        model_kwargs = {
            'wind_speed': train_indices,
            'rainfall': None,
            'storm_surge': None
        }
        
        # Run model comparison
        results = model_comparison.fit_all_models(
            train_data=train_losses,
            validation_data=val_losses,
            **model_kwargs
        )
        
        # Get best model
        best_model = model_comparison.get_best_model()
        
        if best_model:
            print(f"\nâœ… æ–¹æ³•ä¸€æ¸¬è©¦æˆåŠŸ")
            print(f"   æœ€ä½³æ¨¡å‹: {best_model.model_name}")
            print(f"   CRPS åˆ†æ•¸: {best_model.crps_score:.2e}")
        else:
            print("\nâŒ æ–¹æ³•ä¸€æ¸¬è©¦å¤±æ•—ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆæ¨¡å‹")
            
        return best_model, train_losses, train_indices
        
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        return None, None, None
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        return None, None, None

def test_decision_theory_framework(best_model, train_losses, train_indices):
    """Test Method 2: Bayesian Decision Theory Framework"""
    
    print("\nğŸ¯ æ¸¬è©¦æ–¹æ³•äºŒï¼šè²è‘‰æ–¯æ±ºç­–ç†è«–æ¡†æ¶")
    print("=" * 60)
    
    if best_model is None:
        print("âš ï¸ è·³éæ–¹æ³•äºŒæ¸¬è©¦ï¼ˆæ–¹æ³•ä¸€æœªæˆåŠŸï¼‰")
        return
    
    try:
        from bayesian import BayesianDecisionTheory, BasisRiskLossFunction, BasisRiskType, ProductParameters
        
        # Create loss function
        loss_function = BasisRiskLossFunction(
            risk_type=BasisRiskType.WEIGHTED_ASYMMETRIC,
            w_under=2.0,
            w_over=0.5
        )
        
        # Initialize decision theory framework
        decision_theory = BayesianDecisionTheory(
            loss_function=loss_function,
            random_seed=42
        )
        
        # Extract posterior samples (simplified)
        # In real implementation, this would extract from the best model's trace
        posterior_samples = np.random.normal(np.log(1e8), 0.5, 100)
        print(f"ğŸ“Š ä½¿ç”¨ {len(posterior_samples)} å€‹å¾Œé©—æ¨£æœ¬")
        
        # Simulate actual losses
        actual_losses_matrix = decision_theory.simulate_actual_losses(
            posterior_samples=posterior_samples,
            hazard_indices=train_indices
        )
        
        print(f"ğŸ“Š ç”ŸæˆçœŸå¯¦æå¤±çŸ©é™£: {actual_losses_matrix.shape}")
        
        # Define optimization bounds
        product_bounds = {
            'trigger_threshold': (35, 55),
            'payout_amount': (5e7, 3e8),
            'max_payout': (5e8, 5e8)
        }
        
        # Optimize product
        optimization_result = decision_theory.optimize_single_product(
            posterior_samples=posterior_samples,
            hazard_indices=train_indices,
            actual_losses=actual_losses_matrix,
            product_bounds=product_bounds
        )
        
        print(f"\nâœ… æ–¹æ³•äºŒæ¸¬è©¦æˆåŠŸ")
        print(f"   æœ€å„ªè§¸ç™¼é–¾å€¼: {optimization_result.optimal_product.trigger_threshold:.2f}")
        print(f"   æœ€å„ªè³ ä»˜é‡‘é¡: ${optimization_result.optimal_product.payout_amount:.2e}")
        print(f"   æœŸæœ›åŸºå·®é¢¨éšª: ${optimization_result.expected_loss:.2e}")
        
        return optimization_result
        
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        return None

def test_integrated_framework():
    """Test the integrated framework through RobustBayesianAnalyzer"""
    
    print("\nğŸ§  æ¸¬è©¦æ•´åˆæ¡†æ¶ï¼šRobustBayesianAnalyzer")
    print("=" * 60)
    
    try:
        from bayesian import RobustBayesianAnalyzer
        
        # Generate sample data
        observed_losses, hazard_indices = generate_sample_data(80)
        
        print(f"ğŸ“Š æ•¸æ“š: {len(observed_losses)} å€‹è§€æ¸¬å€¼")
        
        # Initialize analyzer
        analyzer = RobustBayesianAnalyzer(
            density_ratio_constraint=2.0,
            n_monte_carlo_samples=100,  # Small for testing
            n_mixture_components=2
        )
        
        # Create sample parametric products
        parametric_products = [
            {
                'product_id': 'test_product_1',
                'wind_threshold': 40,
                'payout_rate': 0.5,
                'max_payout': 2e8,
                'type': 'single_threshold'
            },
            {
                'product_id': 'test_product_2', 
                'wind_threshold': 45,
                'payout_rate': 0.7,
                'max_payout': 3e8,
                'type': 'single_threshold'
            }
        ]
        
        # Run comprehensive analysis
        results = analyzer.comprehensive_bayesian_analysis(
            tc_hazard=None,  # Mock data
            exposure_main=None,  # Mock data
            impact_func_set=None,  # Mock data
            observed_losses=observed_losses,
            parametric_products=parametric_products,
            hazard_indices=hazard_indices
        )
        
        print(f"\nâœ… æ•´åˆæ¡†æ¶æ¸¬è©¦æˆåŠŸ")
        print(f"   æ¡†æ¶ç‰ˆæœ¬: {results['meta_analysis']['framework_version']}")
        print(f"   ä½¿ç”¨æ–¹æ³•: {results['meta_analysis']['methods_used']}")
        
        if results['meta_analysis']['best_model_name']:
            print(f"   æœ€ä½³æ¨¡å‹: {results['meta_analysis']['best_model_name']}")
            
        if results['meta_analysis']['optimal_product']:
            optimal = results['meta_analysis']['optimal_product']
            print(f"   æœ€å„ªç”¢å“è§¸ç™¼é–¾å€¼: {optimal['trigger_threshold']:.2f}")
            print(f"   æœ€å„ªç”¢å“è³ ä»˜é‡‘é¡: ${optimal['payout_amount']:.2e}")
        
        return results
        
    except ImportError as e:
        print(f"âŒ å°å…¥éŒ¯èª¤: {e}")
        return None
    except Exception as e:
        print(f"âŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        return None

def main():
    """Main test function"""
    
    print("ğŸ§ª æ–°è²è‘‰æ–¯æ¡†æ¶æ¸¬è©¦")
    print("=" * 80)
    print("å¯¦ç¾ bayesian_implement.md ä¸­çš„æ–¹æ³•ä¸€å’Œæ–¹æ³•äºŒ")
    print()
    
    # Test Method 1
    best_model, train_losses, train_indices = test_model_comparison_framework()
    
    # Test Method 2
    optimization_result = test_decision_theory_framework(best_model, train_losses, train_indices)
    
    # Test Integrated Framework
    integrated_results = test_integrated_framework()
    
    # Summary
    print("\nğŸ“‹ æ¸¬è©¦ç¸½çµ")
    print("=" * 40)
    
    if best_model:
        print("âœ… æ–¹æ³•ä¸€ï¼ˆæ¨¡å‹æ¯”è¼ƒï¼‰: æˆåŠŸ")
    else:
        print("âŒ æ–¹æ³•ä¸€ï¼ˆæ¨¡å‹æ¯”è¼ƒï¼‰: å¤±æ•—")
    
    if optimization_result:
        print("âœ… æ–¹æ³•äºŒï¼ˆæ±ºç­–ç†è«–ï¼‰: æˆåŠŸ")
    else:
        print("âŒ æ–¹æ³•äºŒï¼ˆæ±ºç­–ç†è«–ï¼‰: å¤±æ•—")
    
    if integrated_results:
        print("âœ… æ•´åˆæ¡†æ¶: æˆåŠŸ")
    else:
        print("âŒ æ•´åˆæ¡†æ¶: å¤±æ•—")
    
    print("\nğŸ‰ æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    main()