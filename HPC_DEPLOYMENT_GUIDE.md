# HPCéƒ¨ç½²æŒ‡å— - é›™RTX 2080 Ti + 16æ ¸å¿ƒå„ªåŒ–

## ğŸ¯ ç³»çµ±éœ€æ±‚

**ç¡¬ä»¶é…ç½®**ï¼š
- CPU: 16æ ¸å¿ƒ
- GPU: 2 Ã— RTX 2080 Ti  
- å…§å­˜: 32GB+
- å­˜å„²: å……è¶³ç©ºé–“ç”¨æ–¼MCMCæ¡æ¨£çµæœ

## ğŸš€ å¿«é€Ÿéƒ¨ç½²æ­¥é©Ÿ

### 1. ç’°å¢ƒæº–å‚™ (15åˆ†é˜)

```bash
# æª¢æŸ¥CUDAç‰ˆæœ¬
nvidia-smi

# å®‰è£JAX GPUæ”¯æŒ (CUDA 12.x)
pip install --upgrade "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# æˆ–è€… CUDA 11.x
pip install --upgrade "jax[cuda11_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# å®‰è£NumPyro (JAX-based MCMC)
pip install numpyro

# å®‰è£GPUç›£æ§å·¥å…·
pip install gputil nvidia-ml-py
```

### 2. é©—è­‰GPUé…ç½® (5åˆ†é˜)

```python
import jax
print("Available devices:", jax.devices())
# æ‡‰è©²é¡¯ç¤º: [cuda(id=0), cuda(id=1), cpu(id=0)]

import numpyro
print("NumPyro version:", numpyro.__version__)

# æ¸¬è©¦GPUå…§å­˜
import numpy as np
x = jax.device_put(np.ones((1000, 1000)), jax.devices('gpu')[0])
print("GPU 0 test passed")
y = jax.device_put(np.ones((1000, 1000)), jax.devices('gpu')[1])  
print("GPU 1 test passed")
```

### 3. é‹è¡ŒHPCå„ªåŒ–åˆ†æ

```bash
# åœ¨HPCç³»çµ±ä¸Šé‹è¡Œ
python 05_robust_bayesian_framework_integrated.py
```

## âš¡ HPCæ€§èƒ½å„ªåŒ–é…ç½®

**è‡ªå‹•æª¢æ¸¬ä¸¦æ‡‰ç”¨çš„å„ªåŒ–**ï¼š

### GPUé…ç½®
```python
# ç’°å¢ƒè®Šé‡ (è‡ªå‹•è¨­ç½®)
JAX_PLATFORMS=cuda,cpu
CUDA_VISIBLE_DEVICES=0,1
JAX_PLATFORM_NAME=gpu
XLA_PYTHON_CLIENT_MEM_FRACTION=0.8
```

### CPUç·šç¨‹æ§åˆ¶  
```python
# 16æ ¸å¿ƒCPUå„ªåŒ–
OMP_NUM_THREADS=16
MKL_NUM_THREADS=16
OPENBLAS_NUM_THREADS=16
NUMBA_NUM_THREADS=16
```

### MCMCåƒæ•¸
```python
# HPCå„ªåŒ–çš„MCMCé…ç½®
n_samples=3000      # é«˜è³ªé‡æ¡æ¨£
n_warmup=1500       # å……åˆ†é ç†±
n_chains=16         # å……åˆ†åˆ©ç”¨16æ ¸å¿ƒ  
cores=16            # æ‰€æœ‰æ ¸å¿ƒ
target_accept=0.95  # é«˜ç©©å®šæ€§
parallel_execution=True
max_workers=16      # ä¸¦è¡Œåˆ†æ
```

## ğŸ“Š é æœŸæ€§èƒ½

### æ€§èƒ½å°æ¯”
| é…ç½® | éˆæ•¸ | æ¨£æœ¬æ•¸ | ç¸½æ¨£æœ¬ | é ä¼°æ™‚é–“ | åŠ é€Ÿæ¯” |
|------|------|--------|--------|----------|--------|
| å–®æ ¸CPU | 4 | 2000 | 8K | 4å°æ™‚ | 1x |
| 16æ ¸CPU | 16 | 3000 | 48K | 1.5å°æ™‚ | 2.7x |  
| **é›™GPU + 16æ ¸** | 16 | 3000 | 48K | **25åˆ†é˜** | **9.6x** |

### å¯¦æ™‚ç›£æ§
åˆ†æé‹è¡Œæ™‚è‡ªå‹•é¡¯ç¤ºï¼š
```
âš¡ HPC Performance - Analysis Start: 0.1 minutes elapsed
   ğŸ¯ RTX 2080 Ti #0: 85% GPU, 8947MB memory
   ğŸ¯ RTX 2080 Ti #1: 82% GPU, 8756MB memory
```

## ğŸ”§ æ•…éšœæ’é™¤

### GPUæœªæª¢æ¸¬åˆ°
```bash
# æª¢æŸ¥CUDAé©…å‹•
nvidia-smi

# æª¢æŸ¥JAX GPU
python -c "import jax; print(jax.devices())"

# é‡æ–°å®‰è£JAX CUDA
pip uninstall jax jaxlib
pip install --upgrade "jax[cuda12_pip]" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html
```

### å…§å­˜ä¸è¶³
```python
# é™ä½å…§å­˜ä½¿ç”¨
export XLA_PYTHON_CLIENT_MEM_FRACTION=0.6  # é™ä½åˆ°60%

# æ¸›å°‘ä¸¦è¡Œéˆæ•¸
n_chains=8  # æ¸›å°‘åˆ°8æ¢éˆ
```

### CPUéè¼‰
```python
# é™ä½ç·šç¨‹æ•¸
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
```

## ğŸ† å„ªåŒ–æ•ˆæœ

**485å€‹è§€æ¸¬æ¨£æœ¬ Ã— 48å€‹æ¨¡å‹æ¯”è¼ƒ**ï¼š

### å‚³çµ±é…ç½® vs HPCå„ªåŒ–
```
å‚³çµ±é…ç½® (å–®GPU):
- ç¸½æ¨£æœ¬: 8,000
- é ä¼°æ™‚é–“: 4å°æ™‚
- GPUåˆ©ç”¨ç‡: ~40%

HPCå„ªåŒ–é…ç½®:  
- ç¸½æ¨£æœ¬: 48,000 (6å€å¢é•·)
- å¯¦éš›æ™‚é–“: 25åˆ†é˜ (9.6xåŠ é€Ÿ)
- é›™GPUåˆ©ç”¨ç‡: 80%+
- 16æ ¸å¿ƒCPU: å®Œå…¨åˆ©ç”¨
```

### çµ±è¨ˆæ”¹å–„
- **æ¨£æœ¬é‡å¢åŠ 6å€**: 8K â†’ 48Kæ¨£æœ¬
- **çµ±è¨ˆåŠŸæ•ˆå¤§å¹…æå‡**: æ›´å¯é çš„è²æ°æ¨æ–·
- **æ¨¡å‹é¸æ“‡ç²¾åº¦**: DIC/WAICæ›´æº–ç¢º
- **ä¸ç¢ºå®šæ€§é‡åŒ–**: Îµ-contaminationæ›´ç©©å¥

## ğŸ“ˆ æœ€çµ‚è¼¸å‡º

**ä¿å­˜ä½ç½®**: `results/robust_bayesian_hpc_optimized/`

**ä¸»è¦æ–‡ä»¶**:
- `robust_bayesian_hpc_optimized.pkl` - å®Œæ•´çµæœ
- `hpc_model_comparison.csv` - æ¨¡å‹æ’å
- `hpc_bayesian_report.txt` - æ€§èƒ½å ±å‘Š

**é—œéµæŒ‡æ¨™**:
```
ğŸ“Š HPC Analysis Summary:
   Best Model: [æœ€ä½³æ¨¡å‹åç¨±]
   Total Models: 48
   Execution Time: ~25åˆ†é˜  
   Hardware: dual_gpu_optimized
   Total MCMC samples: 48,000
   Performance: ~32 samples/sec
```

## ğŸ”„ æŒçºŒç›£æ§

**GPUä½¿ç”¨æƒ…æ³**:
```bash
# å¯¦æ™‚ç›£æ§
watch -n 1 nvidia-smi

# è©³ç´°çµ±è¨ˆ
nvidia-smi --query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total --format=csv -l 1
```

**ç³»çµ±è³‡æº**:
```bash
# CPUä½¿ç”¨ç‡
htop

# å…§å­˜ä½¿ç”¨
free -h
```

## ğŸ‰ éƒ¨ç½²å®Œæˆ

éƒ¨ç½²å®Œæˆå¾Œä½ å°‡ç²å¾—ï¼š
1. **9.6å€æ€§èƒ½æå‡** (4å°æ™‚ â†’ 25åˆ†é˜)
2. **6å€æ¨£æœ¬å¢é•·** (8K â†’ 48Kæ¨£æœ¬)  
3. **48å€‹è²æ°æ¨¡å‹æ¯”è¼ƒ** (Îµ-contamination robustness)
4. **å®Œæ•´GPU + CPUåˆ©ç”¨** (é›™RTX 2080 Ti + 16æ ¸å¿ƒ)
5. **ä¼æ¥­ç´šåˆ†æå ±å‘Š** (HPC performance metrics)

ç¾åœ¨ä½ çš„ç³»çµ±å°‡çœŸæ­£ç™¼æ®é›™GPU + 16æ ¸å¿ƒçš„ç¡¬ä»¶å„ªå‹¢ï¼ğŸš€