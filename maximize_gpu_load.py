#!/usr/bin/env python3
"""
Maximum GPU Load Configuration
æœ€å¤§GPUè² è¼‰é…ç½®

Aggressive MCMC settings to push dual RTX A5000 to 90%+ utilization
æ¿€é€²çš„MCMCè¨­ç½®æ¨å‹•é›™RTX A5000é”åˆ°90%+ä½¿ç”¨ç‡
"""

import os
import numpy as np

def setup_maximum_gpu_environment():
    """è¨­ç½®æœ€å¤§GPUè² è¼‰ç’°å¢ƒ"""
    
    print("ğŸ”¥ Setting up MAXIMUM GPU Load Environment...")
    
    # æœ€æ¿€é€²çš„é›™GPUé…ç½®
    max_gpu_env = {
        # JAXæœ€å¤§è² è¼‰é…ç½®
        'JAX_PLATFORMS': 'cuda',
        'JAX_ENABLE_X64': 'False',  # float32 for maximum speed
        'JAX_PLATFORM_NAME': 'gpu',
        'XLA_FLAGS': '--xla_force_host_platform_device_count=2 --xla_gpu_force_compilation_parallelism=2',
        
        # è¨˜æ†¶é«”æ¿€é€²ä½¿ç”¨
        'XLA_PYTHON_CLIENT_MEM_FRACTION': '0.95',  # ä½¿ç”¨95% GPUè¨˜æ†¶é«”
        'XLA_PYTHON_CLIENT_PREALLOCATE': 'true',
        'XLA_PYTHON_CLIENT_ALLOCATOR': 'platform',
        
        # CUDAæœ€å¤§è² è¼‰
        'CUDA_VISIBLE_DEVICES': '0,1',
        'CUDA_DEVICE_ORDER': 'PCI_BUS_ID',
        
        # NumPyroé«˜è² è¼‰é…ç½®
        'NUMPYRO_PLATFORM': 'gpu',
        'NUMPYRO_NUM_CHAINS': '32',  # å¢åŠ åˆ°32æ¢éˆ
        
        # CPUç·šç¨‹æœ€å¤§åŒ–
        'OMP_NUM_THREADS': '32',     # å¤§å¹…å¢åŠ 
        'MKL_NUM_THREADS': '32',
        'OPENBLAS_NUM_THREADS': '32',
        'NUMBA_NUM_THREADS': '32',
        
        # PyTensoræœ€å¤§åŒ–
        'PYTENSOR_FLAGS': 'device=cuda,floatX=float32,optimizer=fast_run,force_device=True,allow_gc=False',
        'THEANO_FLAGS': 'device=cuda,floatX=float32,force_device=True',
    }
    
    for key, value in max_gpu_env.items():
        os.environ[key] = value
        print(f"   ğŸ”¥ {key} = {value}")
    
    return max_gpu_env

def get_maximum_mcmc_config():
    """ç²å–æœ€å¤§MCMCé…ç½®"""
    
    # æ¿€é€²é…ç½® - æ¨å‹•GPUåˆ°æ¥µé™
    max_mcmc_config = {
        "n_samples": 5000,      # å¤§å¹…å¢åŠ æ¨£æœ¬æ•¸
        "n_warmup": 2500,       # å¢åŠ warmup
        "n_chains": 32,         # å¢åŠ åˆ°32æ¢éˆ (æ¯GPU 16æ¢)
        "cores": 32,            # åŒ¹é…éˆæ•¸
        "target_accept": 0.95,  # é«˜ç²¾åº¦å¢åŠ è¨ˆç®—é‡
        
        # GPUå„ªåŒ–åƒæ•¸
        "nuts_sampler": "numpyro",
        "chain_method": "parallel",
        
        # æ€§èƒ½åƒæ•¸
        "progress_bar": True,
        "return_inferencedata": True,
        "compute_convergence_checks": True,
    }
    
    print("ğŸ”¥ MAXIMUM MCMC Configuration:")
    print("=" * 50)
    for key, value in max_mcmc_config.items():
        print(f"   {key}: {value}")
    
    total_samples = max_mcmc_config["n_chains"] * max_mcmc_config["n_samples"]
    print(f"   ğŸ“Š Total samples: {total_samples:,}")
    print(f"   ğŸ¯ Expected GPU load: 90%+ on both GPUs")
    print(f"   âš¡ Expected power: 200W+ per GPU")
    
    return max_mcmc_config

def test_maximum_load():
    """æ¸¬è©¦æœ€å¤§è² è¼‰é…ç½®"""
    
    print("\nğŸ§ª Testing Maximum GPU Load...")
    
    try:
        import jax
        import jax.numpy as jnp
        
        devices = jax.devices()
        print(f"ğŸ” JAX devices: {devices}")
        
        if len(devices) >= 2:
            print("ğŸ”¥ Testing maximum computational load on both GPUs...")
            
            # å‰µå»ºå¤§å‹è¨ˆç®—ä»»å‹™
            for i, device in enumerate(devices[:2]):
                print(f"   ğŸš€ Loading GPU {i} with heavy computation...")
                
                # å¤§å‹çŸ©é™£é‹ç®—
                x = jax.device_put(jnp.ones((2000, 2000)), device)
                
                # è¤‡é›œè¨ˆç®—éˆ
                @jax.jit
                def heavy_computation(x):
                    for _ in range(10):
                        x = jnp.matmul(x, x.T) / jnp.sum(x)
                        x = jnp.sin(x) + jnp.cos(x)
                    return jnp.sum(x)
                
                result = heavy_computation(x)
                print(f"   âœ… GPU {i} computation: {result:.6f} on {result.device()}")
            
            print("ğŸ”¥ Heavy GPU load test completed!")
        
    except Exception as e:
        print(f"âŒ Maximum load test failed: {e}")

if __name__ == "__main__":
    print("ğŸ”¥ RTX A5000 Maximum GPU Load Configuration")
    print("=" * 60)
    
    # 1. è¨­ç½®ç’°å¢ƒ
    env_config = setup_maximum_gpu_environment()
    
    # 2. ç²å–MCMCé…ç½®
    mcmc_config = get_maximum_mcmc_config()
    
    # 3. æ¸¬è©¦æœ€å¤§è² è¼‰
    test_maximum_load()
    
    print("\n" + "=" * 60)
    print("ğŸ”¥ MAXIMUM LOAD CONFIGURATION READY!")
    print("=" * 60)
    
    print("ğŸ“Š Expected Performance:")
    print("   ğŸ¯ GPU 0: 90%+ usage, 200W+ power")
    print("   ğŸ¯ GPU 1: 90%+ usage, 200W+ power")
    print("   âš¡ Total power: 400W+ (both GPUs)")
    print("   ğŸ’¾ Memory usage: ~45GB (95% of 48GB)")
    
    print("\nâš ï¸  WARNING - Aggressive Configuration:")
    print("   â€¢ High memory usage may cause OOM")
    print("   â€¢ High power consumption (400W+)")
    print("   â€¢ Monitor temperatures")
    print("   â€¢ Reduce settings if system unstable")
    
    print("\nğŸš€ Usage:")
    print("   1. Apply this configuration to your analysis")
    print("   2. Monitor nvidia-smi for 90%+ usage")
    print("   3. Expect single model < 60 seconds")
    print("   4. Watch for thermal throttling")