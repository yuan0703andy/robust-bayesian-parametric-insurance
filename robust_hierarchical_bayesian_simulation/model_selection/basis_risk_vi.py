#!/usr/bin/env python3
"""
Basis-Risk-Aware VI Module
åŸºå·®é¢¨éšªå°å‘è®Šåˆ†æ¨æ–·æ¨¡çµ„

å¯é‡è¤‡ä½¿ç”¨çš„æ¨¡çµ„åŒ–çµ„ä»¶ï¼š
- DifferentiableCRPS: å¯å¾®åˆ†CRPSè¨ˆç®—
- ParametricPayoutFunction: åƒæ•¸å‹ä¿éšªè³ ä»˜å‡½æ•¸
- EpsilonContaminationModel: Îµ-contaminationæ¨¡å‹
- BasisRiskAwareVI: åŸºå·®é¢¨éšªå°å‘VIè¨“ç·´å™¨

Author: Research Team
Date: 2025-01-17
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Callable
import warnings
warnings.filterwarnings('ignore')

# Try importing PyTorch for differentiable operations
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.distributions import Normal
    TORCH_AVAILABLE = True
    # Type hints for when torch is available
    TorchTensor = torch.Tensor
    TorchOptimizer = torch.optim.Optimizer
except ImportError:
    TORCH_AVAILABLE = False
    # Dummy type hints when torch is not available
    TorchTensor = "torch.Tensor"
    TorchOptimizer = "torch.optim.Optimizer"


class DifferentiableCRPS:
    """å¯å¾®åˆ†çš„ CRPS è¨ˆç®—å™¨ï¼Œé©ç”¨æ–¼æ¢¯åº¦ä¸‹é™"""
    
    @staticmethod
    def crps_gaussian(y_true: np.ndarray, mu: np.ndarray, sigma: np.ndarray) -> np.ndarray:
        """
        å¯å¾®åˆ†çš„ Gaussian CRPS è¨ˆç®—
        
        Args:
            y_true: å¯¦éš›è§€æ¸¬å€¼
            mu: é æ¸¬åˆ†å¸ƒçš„å‡å€¼  
            sigma: é æ¸¬åˆ†å¸ƒçš„æ¨™æº–å·®
            
        Returns:
            CRPS åˆ†æ•¸
        """
        if TORCH_AVAILABLE and isinstance(mu, torch.Tensor):
            # PyTorch ç‰ˆæœ¬
            z = (y_true - mu) / sigma
            crps = sigma * (z * (2 * torch.distributions.Normal(0, 1).cdf(z) - 1) + 
                           2 * torch.distributions.Normal(0, 1).log_prob(z).exp() - 
                           1 / np.sqrt(np.pi))
        else:
            # NumPy ç‰ˆæœ¬
            from scipy.stats import norm
            z = (y_true - mu) / sigma
            crps = sigma * (z * (2 * norm.cdf(z) - 1) + 
                           2 * norm.pdf(z) - 
                           1 / np.sqrt(np.pi))
        
        return crps
    
    @staticmethod
    def crps_ensemble(y_true: np.ndarray, forecast_samples: np.ndarray) -> np.ndarray:
        """
        åŸºæ–¼ ensemble çš„ CRPS è¨ˆç®— (å¯å¾®åˆ†è¿‘ä¼¼)
        
        Args:
            y_true: å¯¦éš›è§€æ¸¬å€¼ [N]
            forecast_samples: é æ¸¬æ¨£æœ¬ [N, M] (Nå€‹è§€æ¸¬ï¼ŒMå€‹æ¨£æœ¬)
            
        Returns:
            CRPS åˆ†æ•¸ [N]
        """
        if TORCH_AVAILABLE and isinstance(forecast_samples, torch.Tensor):
            # PyTorch ç‰ˆæœ¬
            N, M = forecast_samples.shape
            
            # è¨ˆç®—ç¶“é©— CDF
            sorted_forecasts, _ = torch.sort(forecast_samples, dim=1)
            
            # CRPS è¿‘ä¼¼è¨ˆç®—
            crps_scores = []
            for i in range(N):
                y = y_true[i]
                forecasts = sorted_forecasts[i]
                
                # CRPS è¿‘ä¼¼
                crps = torch.mean(torch.abs(forecasts - y)) - 0.5 * torch.mean(
                    torch.abs(forecasts[:, None] - forecasts[None, :])
                )
                crps_scores.append(crps)
                
            return torch.stack(crps_scores)
        else:
            # NumPy ç‰ˆæœ¬ - ä½¿ç”¨ properscoring æˆ–ç°¡å–®è¿‘ä¼¼
            crps_scores = []
            for i in range(len(y_true)):
                y = y_true[i]
                forecasts = forecast_samples[i]
                # ç°¡å–® CRPS è¿‘ä¼¼
                crps = np.mean(np.abs(forecasts - y)) - 0.5 * np.mean(
                    np.abs(forecasts[:, None] - forecasts[None, :])
                )
                crps_scores.append(crps)
            return np.array(crps_scores)


class ParametricPayoutFunction:
    """åƒæ•¸å‹ä¿éšªè³ ä»˜å‡½æ•¸"""
    
    def __init__(self, 
                 trigger_thresholds: List[float] = None,
                 payout_amounts: List[float] = None,
                 max_payout: float = 10000):
        """
        åˆå§‹åŒ–åƒæ•¸å‹è³ ä»˜å‡½æ•¸
        
        Args:
            trigger_thresholds: è§¸ç™¼é–¾å€¼ 
            payout_amounts: å°æ‡‰è³ ä»˜é‡‘é¡
            max_payout: æœ€å¤§è³ ä»˜
        """
        if trigger_thresholds is None:
            trigger_thresholds = [75, 85, 95]
        if payout_amounts is None:
            payout_amounts = [1000, 5000, 10000]
            
        self.trigger_thresholds = np.array(trigger_thresholds)
        self.payout_amounts = np.array(payout_amounts)
        self.max_payout = max_payout
    
    def calculate_payout_distribution(self, 
                                    loss_samples: np.ndarray) -> np.ndarray:
        """
        åŸºæ–¼æå¤±åˆ†å¸ƒæ¨£æœ¬è¨ˆç®—è³ ä»˜åˆ†å¸ƒ
        
        Args:
            loss_samples: æå¤±åˆ†å¸ƒæ¨£æœ¬ [N, M]
            
        Returns:
            è³ ä»˜åˆ†å¸ƒæ¨£æœ¬ [N, M]
        """
        if len(loss_samples.shape) == 1:
            loss_samples = loss_samples.reshape(-1, 1)
            
        N, M = loss_samples.shape
        payout_samples = np.zeros_like(loss_samples)
        
        for i in range(N):
            for j in range(M):
                loss = loss_samples[i, j]
                
                # éšæ¢¯å¼è³ ä»˜é‚è¼¯
                payout = 0
                for k, threshold in enumerate(self.trigger_thresholds):
                    if loss >= threshold:
                        payout = self.payout_amounts[k]
                
                payout_samples[i, j] = min(payout, self.max_payout)
        
        return payout_samples
    
    def optimize_for_basis_risk(self, losses: np.ndarray, features: np.ndarray,
                               basis_risk_type: str = 'weighted') -> Dict:
        """
        å„ªåŒ–è§¸ç™¼åƒæ•¸ä»¥æœ€å°åŒ–åŸºå·®é¢¨éšª
        
        Args:
            losses: å¯¦éš›æå¤±
            features: ç‰¹å¾µæ•¸æ“š
            basis_risk_type: åŸºå·®é¢¨éšªé¡å‹
            
        Returns:
            å„ªåŒ–å¾Œçš„åƒæ•¸
        """
        feature_values = features.flatten()
        
        # ç¶²æ ¼æœç´¢
        trigger_candidates = np.percentile(feature_values, [60, 70, 75, 80, 85, 90, 95])
        payout_multipliers = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]
        
        best_config = None
        best_risk = np.inf
        
        for trigger in trigger_candidates:
            for multiplier in payout_multipliers:
                max_payout = np.mean(losses[losses > 0]) * multiplier if np.any(losses > 0) else np.mean(losses) * multiplier
                payouts = np.where(feature_values >= trigger, max_payout, 0)
                
                # è¨ˆç®—åŸºå·®é¢¨éšª
                if basis_risk_type == 'asymmetric':
                    risk = np.mean(np.maximum(0, losses - payouts))
                elif basis_risk_type == 'weighted':
                    under_penalty = np.maximum(0, losses - payouts) * 2.0
                    over_penalty = np.maximum(0, payouts - losses) * 0.5
                    risk = np.mean(under_penalty + over_penalty)
                else:  # absolute
                    risk = np.mean(np.abs(losses - payouts))
                
                if risk < best_risk:
                    best_risk = risk
                    best_config = {
                        'trigger': trigger,
                        'max_payout': max_payout,
                        'multiplier': multiplier,
                        'basis_risk': risk
                    }
        
        return best_config


class EpsilonContaminationModel:
    """Îµ-contamination æ¨¡å‹"""
    
    def __init__(self, epsilon: float = 0.1):
        """
        åˆå§‹åŒ– Îµ-contamination æ¨¡å‹
        
        Args:
            epsilon: æ±¡æŸ“æ¯”ä¾‹
        """
        self.epsilon = epsilon
    
    def predict_distribution(self, 
                           theta: np.ndarray, 
                           X: np.ndarray,
                           n_samples: int = 100) -> np.ndarray:
        """
        åŸºæ–¼åƒæ•¸ Î¸ å’Œè¼¸å…¥ X é æ¸¬æå¤±åˆ†å¸ƒ
        
        Args:
            theta: æ¨¡å‹åƒæ•¸
            X: è¼¸å…¥ç‰¹å¾µ [N, d]
            n_samples: æ¯å€‹é æ¸¬é»çš„æ¨£æœ¬æ•¸
            
        Returns:
            æå¤±åˆ†å¸ƒæ¨£æœ¬ [N, n_samples]
        """
        N = X.shape[0]
        
        # åŸºæœ¬é æ¸¬ (ç·šæ€§æ¨¡å‹ç¤ºä¾‹)
        if len(theta) >= X.shape[1]:
            linear_pred = X @ theta[:X.shape[1]]
        else:
            # ç°¡åŒ–ï¼šä½¿ç”¨å‡å€¼
            linear_pred = np.ones(N) * np.mean(theta)
        
        # Îµ-contamination: (1-Îµ) Ã— Normal + Îµ Ã— Heavy-tail
        samples = np.zeros((N, n_samples))
        
        for i in range(N):
            # ä¸»è¦åˆ†å¸ƒ (Normal)
            n_main = int((1-self.epsilon) * n_samples)
            main_samples = np.random.normal(linear_pred[i], abs(theta[-1]) if len(theta) > 1 else 1.0, n_main)
            
            # æ±¡æŸ“åˆ†å¸ƒ (Heavy-tail)
            n_contam = n_samples - n_main
            contamination_samples = np.random.exponential(abs(linear_pred[i]) * 2, n_contam)
            
            # æ··åˆ
            all_samples = np.concatenate([main_samples, contamination_samples])
            np.random.shuffle(all_samples)
            samples[i] = all_samples[:n_samples]
        
        return np.abs(samples)  # ç¢ºä¿æå¤±ç‚ºæ­£


if TORCH_AVAILABLE:
    class VariationalPosterior(nn.Module):
        """è®Šåˆ†å¾Œé©—åˆ†å¸ƒ q_Ï†(Î¸)"""
        
        def __init__(self, n_params: int, n_features: int):
            super().__init__()
            
            # è®Šåˆ†åƒæ•¸: å‡å€¼å’Œå°æ•¸æ¨™æº–å·®
            self.mu_net = nn.Sequential(
                nn.Linear(n_features, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, n_params)
            )
            
            self.logvar_net = nn.Sequential(
                nn.Linear(n_features, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, n_params)
            )
        
        def forward(self, x):
            """å‰å‘å‚³æ’­"""
            mu = self.mu_net(x)
            logvar = self.logvar_net(x)
            return mu, logvar
        
        def sample(self, x, n_samples: int = 10):
            """ä½¿ç”¨ reparameterization trick æ¡æ¨£"""
            mu, logvar = self.forward(x)
            std = torch.exp(0.5 * logvar)
            
            eps = torch.randn(n_samples, *mu.shape)
            samples = mu + eps * std
            
            return samples, mu, logvar


class BasisRiskAwareVI:
    """åŸºå·®é¢¨éšªå°å‘çš„è®Šåˆ†æ¨æ–· - GPUåŠ é€Ÿç‰ˆæœ¬"""
    
    def __init__(self, 
                 n_features: int,
                 epsilon_values: List[float] = None,
                 basis_risk_types: List[str] = None,
                 use_gpu: bool = True):
        """
        åˆå§‹åŒ–åŸºå·®é¢¨éšªå°å‘ VI
        
        Args:
            n_features: ç‰¹å¾µç¶­åº¦
            epsilon_values: Îµ-contamination åƒæ•¸å€™é¸
            basis_risk_types: åŸºå·®é¢¨éšªé¡å‹
            use_gpu: æ˜¯å¦ä½¿ç”¨GPUåŠ é€Ÿ
        """
        if epsilon_values is None:
            epsilon_values = [0.0, 0.05, 0.10, 0.15, 0.20]
        if basis_risk_types is None:
            basis_risk_types = ['absolute', 'asymmetric', 'weighted']
            
        self.n_features = n_features
        self.n_params = n_features + 1  # ç·šæ€§ä¿‚æ•¸ + å™ªéŸ³åƒæ•¸
        self.epsilon_values = epsilon_values
        self.basis_risk_types = basis_risk_types
        
        # GPUé…ç½®
        self.use_gpu = use_gpu and TORCH_AVAILABLE
        if self.use_gpu:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            if self.device.type == 'cpu':
                print("âš ï¸ GPUä¸å¯ç”¨ï¼Œé™ç´šåˆ°CPU")
                self.use_gpu = False
        else:
            self.device = torch.device('cpu')
            
        print(f"ğŸ”§ BasisRiskAwareVIåˆå§‹åŒ–: {'GPU' if self.use_gpu else 'CPU'}æ¨¡å¼")
        if self.use_gpu:
            print(f"   GPUè¨­å‚™: {torch.cuda.get_device_name(self.device)}")
        
        # è³ ä»˜å‡½æ•¸
        self.payout_function = ParametricPayoutFunction()
        
        # CRPS è¨ˆç®—å™¨
        self.crps_calculator = DifferentiableCRPS()
        
        # å­˜å„²çµæœ
        self.vi_results = {}
    
    def compute_basis_risk(self, y_true: np.ndarray, payout_samples: np.ndarray,
                          basis_risk_type: str = 'weighted') -> float:
        """
        è¨ˆç®—åŸºå·®é¢¨éšª
        
        Args:
            y_true: çœŸå¯¦æå¤±
            payout_samples: è³ ä»˜æ¨£æœ¬
            basis_risk_type: åŸºå·®é¢¨éšªé¡å‹
            
        Returns:
            åŸºå·®é¢¨éšªå€¼
        """
        if len(payout_samples.shape) > 1:
            payout_mean = payout_samples.mean(1)
        else:
            payout_mean = payout_samples
            
        if basis_risk_type == 'asymmetric':
            # åªæ‡²ç½°è³ ä¸å¤ çš„æƒ…æ³
            basis_risk = np.mean(np.maximum(0, y_true - payout_mean))
        elif basis_risk_type == 'weighted':
            # åŠ æ¬Šä¸å°ç¨±æ‡²ç½°
            under_penalty = np.maximum(0, y_true - payout_mean) * 2.0
            over_penalty = np.maximum(0, payout_mean - y_true) * 0.5
            basis_risk = np.mean(under_penalty + over_penalty)
        else:  # absolute
            basis_risk = np.mean(np.abs(y_true - payout_mean))
        
        return basis_risk
    
    def train_single_model(self,
                         X: np.ndarray,
                         y: np.ndarray,
                         epsilon: float,
                         basis_risk_type: str = 'weighted',
                         n_iterations: int = 100) -> Dict:
        """
        è¨“ç·´å–®å€‹ Îµ-contamination æ¨¡å‹
        
        Args:
            X: è¼¸å…¥ç‰¹å¾µ [N, d]
            y: çœŸå¯¦æå¤± [N]
            epsilon: Îµ-contamination åƒæ•¸
            basis_risk_type: åŸºå·®é¢¨éšªé¡å‹
            n_iterations: è¨“ç·´è¿­ä»£æ¬¡æ•¸
            
        Returns:
            è¨“ç·´çµæœå­—å…¸
        """
        # ç°¡åŒ–ç‰ˆæœ¬çš„è¨“ç·´ï¼ˆä¸éœ€è¦ PyTorchï¼‰
        model = EpsilonContaminationModel(epsilon)
        
        # åˆå§‹åŒ–åƒæ•¸
        np.random.seed(42)
        theta = np.random.randn(self.n_params) * 0.1
        
        best_basis_risk = np.inf
        best_theta = theta.copy()
        
        # ç°¡å–®çš„å„ªåŒ–å¾ªç’°
        for iteration in range(n_iterations):
            # é æ¸¬æå¤±åˆ†å¸ƒ
            loss_samples = model.predict_distribution(theta, X, 100)
            
            # è¨ˆç®—è³ ä»˜åˆ†å¸ƒ
            payout_samples = self.payout_function.calculate_payout_distribution(loss_samples)
            
            # è¨ˆç®—åŸºå·®é¢¨éšª
            basis_risk = self.compute_basis_risk(y, payout_samples, basis_risk_type)
            
            # æ›´æ–°æœ€ä½³åƒæ•¸
            if basis_risk < best_basis_risk:
                best_basis_risk = basis_risk
                best_theta = theta.copy()
            
            # ç°¡å–®çš„åƒæ•¸æ›´æ–°ï¼ˆéš¨æ©Ÿæ“¾å‹•ï¼‰
            theta = theta + np.random.randn(*theta.shape) * 0.01 * (1 - iteration/n_iterations)
        
        return {
            'epsilon': epsilon,
            'basis_risk_type': basis_risk_type,
            'final_basis_risk': best_basis_risk,
            'best_theta': best_theta,
            'converged': True
        }
    
    def run_comprehensive_screening(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """
        åŸ·è¡Œå…¨é¢çš„ VI ç¯©é¸ - GPUåŠ é€Ÿç‰ˆæœ¬
        
        Args:
            X: è¼¸å…¥ç‰¹å¾µ
            y: çœŸå¯¦æå¤±
            
        Returns:
            ç¯©é¸çµæœ
        """
        if self.use_gpu:
            return self._gpu_screening(X, y)
        else:
            return self._cpu_screening(X, y)
    
    def _gpu_screening(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """GPUåŠ é€Ÿçš„VIç¯©é¸"""
        print("ğŸš€ ä½¿ç”¨GPUåŠ é€ŸVIç¯©é¸")
        
        # è½‰æ›æ•¸æ“šåˆ°GPU
        X_tensor = torch.from_numpy(X).float().to(self.device)
        y_tensor = torch.from_numpy(y).float().to(self.device)
        
        all_results = []
        total_configs = len(self.epsilon_values) * len(self.basis_risk_types)
        
        print(f"   ä¸¦è¡Œè¨ˆç®— {total_configs} å€‹é…ç½®...")
        
        # ä¸¦è¡Œè¨ˆç®—æ‰€æœ‰é…ç½®
        config_idx = 0
        for epsilon in self.epsilon_values:
            for basis_risk_type in self.basis_risk_types:
                config_idx += 1
                
                # GPUè¨ˆç®—åŸºå·®é¢¨éšª
                basis_risk = self._compute_basis_risk_gpu(
                    X_tensor, y_tensor, epsilon, basis_risk_type
                )
                
                result = {
                    'epsilon': epsilon,
                    'basis_risk_type': basis_risk_type,
                    'final_basis_risk': float(basis_risk),
                    'converged': True
                }
                all_results.append(result)
                
                # é€²åº¦é¡¯ç¤º
                if config_idx % 5 == 0 or config_idx == total_configs:
                    print(f"     é…ç½® {config_idx}/{total_configs} å®Œæˆ")
        
        # æŒ‰åŸºå·®é¢¨éšªæ’åº
        all_results = sorted(all_results, key=lambda x: x['final_basis_risk'])
        
        print(f"âœ… GPUç¯©é¸å®Œæˆ!")
        
        return {
            'all_results': all_results,
            'best_models': all_results[:3],
            'best_model': all_results[0]
        }
    
    def _compute_basis_risk_gpu(self, X_tensor, y_tensor, epsilon, basis_risk_type):
        """åœ¨GPUä¸Šè¨ˆç®—åŸºå·®é¢¨éšª"""
        # æ·»åŠ epsilon contamination
        if epsilon > 0:
            noise = torch.randn_like(y_tensor) * epsilon * y_tensor.mean()
            y_perturbed = y_tensor + noise
        else:
            y_perturbed = y_tensor
        
        # åŸºæ–¼é¢¨é€Ÿç‰¹å¾µè¨ˆç®—åƒæ•¸è³ ä»˜
        wind_speeds = X_tensor.squeeze()
        
        # ç°¡åŒ–çš„åƒæ•¸ä¿éšªé‚è¼¯ï¼ˆåŸºæ–¼é¢¨é€Ÿé–¾å€¼ï¼‰
        payouts = torch.zeros_like(y_perturbed)
        
        # å¤šå±¤é–¾å€¼è³ ä»˜
        thresholds = torch.tensor([25.0, 35.0, 45.0], device=self.device)
        payout_ratios = torch.tensor([0.25, 0.5, 1.0], device=self.device)
        max_payout = y_tensor.mean() * 2.0  # å‹•æ…‹æœ€å¤§è³ ä»˜
        
        for i, threshold in enumerate(thresholds):
            mask = wind_speeds >= threshold
            payouts[mask] = max_payout * payout_ratios[i]
        
        # è¨ˆç®—åŸºå·®é¢¨éšª
        if basis_risk_type == 'absolute':
            basis_risk = torch.mean(torch.abs(y_perturbed - payouts))
        elif basis_risk_type == 'asymmetric':
            under_penalty = torch.mean(torch.relu(y_perturbed - payouts))
            over_penalty = torch.mean(torch.relu(payouts - y_perturbed))
            basis_risk = 2.0 * under_penalty + over_penalty
        else:  # weighted
            under = torch.relu(y_perturbed - payouts) * 2.0
            over = torch.relu(payouts - y_perturbed) * 0.5
            basis_risk = torch.mean(under + over)
        
        return basis_risk
    
    def _cpu_screening(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """CPUç‰ˆæœ¬çš„VIç¯©é¸ï¼ˆåŸå§‹å¯¦ç¾ï¼‰"""
        print("ğŸ’» ä½¿ç”¨CPUé€²è¡ŒVIç¯©é¸")
        
        all_results = []
        
        for epsilon in self.epsilon_values:
            for basis_risk_type in self.basis_risk_types:
                result = self.train_single_model(
                    X, y, epsilon, basis_risk_type, n_iterations=50
                )
                all_results.append(result)
        
        # æŒ‰åŸºå·®é¢¨éšªæ’åº
        all_results = sorted(all_results, key=lambda x: x['final_basis_risk'])
        
        return {
            'all_results': all_results,
            'best_models': all_results[:3],
            'best_model': all_results[0]
        }