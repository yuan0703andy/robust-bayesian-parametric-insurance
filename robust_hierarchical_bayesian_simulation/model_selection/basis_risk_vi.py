#!/usr/bin/env python3
"""
Basis-Risk-Aware VI Module
基差風險導向變分推斷模組

可重複使用的模組化組件：
- DifferentiableCRPS: 可微分CRPS計算
- ParametricPayoutFunction: 參數型保險賠付函數
- EpsilonContaminationModel: ε-contamination模型
- BasisRiskAwareVI: 基差風險導向VI訓練器

Author: Research Team
Date: 2025-01-17
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Callable
import warnings
warnings.filterwarnings('ignore')

# Try importing PyTorch for differentiable operations
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.distributions import Normal
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False


class DifferentiableCRPS:
    """可微分的 CRPS 計算器，適用於梯度下降"""
    
    @staticmethod
    def crps_gaussian(y_true: np.ndarray, mu: np.ndarray, sigma: np.ndarray) -> np.ndarray:
        """
        可微分的 Gaussian CRPS 計算
        
        Args:
            y_true: 實際觀測值
            mu: 預測分布的均值  
            sigma: 預測分布的標準差
            
        Returns:
            CRPS 分數
        """
        if TORCH_AVAILABLE and isinstance(mu, torch.Tensor):
            # PyTorch 版本
            z = (y_true - mu) / sigma
            crps = sigma * (z * (2 * torch.distributions.Normal(0, 1).cdf(z) - 1) + 
                           2 * torch.distributions.Normal(0, 1).log_prob(z).exp() - 
                           1 / np.sqrt(np.pi))
        else:
            # NumPy 版本
            from scipy.stats import norm
            z = (y_true - mu) / sigma
            crps = sigma * (z * (2 * norm.cdf(z) - 1) + 
                           2 * norm.pdf(z) - 
                           1 / np.sqrt(np.pi))
        
        return crps
    
    @staticmethod
    def crps_ensemble(y_true: np.ndarray, forecast_samples: np.ndarray) -> np.ndarray:
        """
        基於 ensemble 的 CRPS 計算 (可微分近似)
        
        Args:
            y_true: 實際觀測值 [N]
            forecast_samples: 預測樣本 [N, M] (N個觀測，M個樣本)
            
        Returns:
            CRPS 分數 [N]
        """
        if TORCH_AVAILABLE and isinstance(forecast_samples, torch.Tensor):
            # PyTorch 版本
            N, M = forecast_samples.shape
            
            # 計算經驗 CDF
            sorted_forecasts, _ = torch.sort(forecast_samples, dim=1)
            
            # CRPS 近似計算
            crps_scores = []
            for i in range(N):
                y = y_true[i]
                forecasts = sorted_forecasts[i]
                
                # CRPS 近似
                crps = torch.mean(torch.abs(forecasts - y)) - 0.5 * torch.mean(
                    torch.abs(forecasts[:, None] - forecasts[None, :])
                )
                crps_scores.append(crps)
                
            return torch.stack(crps_scores)
        else:
            # NumPy 版本 - 使用 properscoring 或簡單近似
            crps_scores = []
            for i in range(len(y_true)):
                y = y_true[i]
                forecasts = forecast_samples[i]
                # 簡單 CRPS 近似
                crps = np.mean(np.abs(forecasts - y)) - 0.5 * np.mean(
                    np.abs(forecasts[:, None] - forecasts[None, :])
                )
                crps_scores.append(crps)
            return np.array(crps_scores)


class ParametricPayoutFunction:
    """參數型保險賠付函數"""
    
    def __init__(self, 
                 trigger_thresholds: List[float] = None,
                 payout_amounts: List[float] = None,
                 max_payout: float = 10000):
        """
        初始化參數型賠付函數
        
        Args:
            trigger_thresholds: 觸發閾值 
            payout_amounts: 對應賠付金額
            max_payout: 最大賠付
        """
        if trigger_thresholds is None:
            trigger_thresholds = [75, 85, 95]
        if payout_amounts is None:
            payout_amounts = [1000, 5000, 10000]
            
        self.trigger_thresholds = np.array(trigger_thresholds)
        self.payout_amounts = np.array(payout_amounts)
        self.max_payout = max_payout
    
    def calculate_payout_distribution(self, 
                                    loss_samples: np.ndarray) -> np.ndarray:
        """
        基於損失分布樣本計算賠付分布
        
        Args:
            loss_samples: 損失分布樣本 [N, M]
            
        Returns:
            賠付分布樣本 [N, M]
        """
        if len(loss_samples.shape) == 1:
            loss_samples = loss_samples.reshape(-1, 1)
            
        N, M = loss_samples.shape
        payout_samples = np.zeros_like(loss_samples)
        
        for i in range(N):
            for j in range(M):
                loss = loss_samples[i, j]
                
                # 階梯式賠付邏輯
                payout = 0
                for k, threshold in enumerate(self.trigger_thresholds):
                    if loss >= threshold:
                        payout = self.payout_amounts[k]
                
                payout_samples[i, j] = min(payout, self.max_payout)
        
        return payout_samples
    
    def optimize_for_basis_risk(self, losses: np.ndarray, features: np.ndarray,
                               basis_risk_type: str = 'weighted') -> Dict:
        """
        優化觸發參數以最小化基差風險
        
        Args:
            losses: 實際損失
            features: 特徵數據
            basis_risk_type: 基差風險類型
            
        Returns:
            優化後的參數
        """
        feature_values = features.flatten()
        
        # 網格搜索
        trigger_candidates = np.percentile(feature_values, [60, 70, 75, 80, 85, 90, 95])
        payout_multipliers = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]
        
        best_config = None
        best_risk = np.inf
        
        for trigger in trigger_candidates:
            for multiplier in payout_multipliers:
                max_payout = np.mean(losses[losses > 0]) * multiplier if np.any(losses > 0) else np.mean(losses) * multiplier
                payouts = np.where(feature_values >= trigger, max_payout, 0)
                
                # 計算基差風險
                if basis_risk_type == 'asymmetric':
                    risk = np.mean(np.maximum(0, losses - payouts))
                elif basis_risk_type == 'weighted':
                    under_penalty = np.maximum(0, losses - payouts) * 2.0
                    over_penalty = np.maximum(0, payouts - losses) * 0.5
                    risk = np.mean(under_penalty + over_penalty)
                else:  # absolute
                    risk = np.mean(np.abs(losses - payouts))
                
                if risk < best_risk:
                    best_risk = risk
                    best_config = {
                        'trigger': trigger,
                        'max_payout': max_payout,
                        'multiplier': multiplier,
                        'basis_risk': risk
                    }
        
        return best_config


class EpsilonContaminationModel:
    """ε-contamination 模型"""
    
    def __init__(self, epsilon: float = 0.1):
        """
        初始化 ε-contamination 模型
        
        Args:
            epsilon: 污染比例
        """
        self.epsilon = epsilon
    
    def predict_distribution(self, 
                           theta: np.ndarray, 
                           X: np.ndarray,
                           n_samples: int = 100) -> np.ndarray:
        """
        基於參數 θ 和輸入 X 預測損失分布
        
        Args:
            theta: 模型參數
            X: 輸入特徵 [N, d]
            n_samples: 每個預測點的樣本數
            
        Returns:
            損失分布樣本 [N, n_samples]
        """
        N = X.shape[0]
        
        # 基本預測 (線性模型示例)
        if len(theta) >= X.shape[1]:
            linear_pred = X @ theta[:X.shape[1]]
        else:
            # 簡化：使用均值
            linear_pred = np.ones(N) * np.mean(theta)
        
        # ε-contamination: (1-ε) × Normal + ε × Heavy-tail
        samples = np.zeros((N, n_samples))
        
        for i in range(N):
            # 主要分布 (Normal)
            n_main = int((1-self.epsilon) * n_samples)
            main_samples = np.random.normal(linear_pred[i], abs(theta[-1]) if len(theta) > 1 else 1.0, n_main)
            
            # 污染分布 (Heavy-tail)
            n_contam = n_samples - n_main
            contamination_samples = np.random.exponential(abs(linear_pred[i]) * 2, n_contam)
            
            # 混合
            all_samples = np.concatenate([main_samples, contamination_samples])
            np.random.shuffle(all_samples)
            samples[i] = all_samples[:n_samples]
        
        return np.abs(samples)  # 確保損失為正


if TORCH_AVAILABLE:
    class VariationalPosterior(nn.Module):
        """變分後驗分布 q_φ(θ)"""
        
        def __init__(self, n_params: int, n_features: int):
            super().__init__()
            
            # 變分參數: 均值和對數標準差
            self.mu_net = nn.Sequential(
                nn.Linear(n_features, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, n_params)
            )
            
            self.logvar_net = nn.Sequential(
                nn.Linear(n_features, 64),
                nn.ReLU(),
                nn.Linear(64, 32),
                nn.ReLU(),
                nn.Linear(32, n_params)
            )
        
        def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
            """前向傳播"""
            mu = self.mu_net(x)
            logvar = self.logvar_net(x)
            return mu, logvar
        
        def sample(self, x: torch.Tensor, n_samples: int = 10) -> Tuple:
            """使用 reparameterization trick 採樣"""
            mu, logvar = self.forward(x)
            std = torch.exp(0.5 * logvar)
            
            eps = torch.randn(n_samples, *mu.shape)
            samples = mu + eps * std
            
            return samples, mu, logvar


class BasisRiskAwareVI:
    """基差風險導向的變分推斷"""
    
    def __init__(self, 
                 n_features: int,
                 epsilon_values: List[float] = None,
                 basis_risk_types: List[str] = None):
        """
        初始化基差風險導向 VI
        
        Args:
            n_features: 特徵維度
            epsilon_values: ε-contamination 參數候選
            basis_risk_types: 基差風險類型
        """
        if epsilon_values is None:
            epsilon_values = [0.0, 0.05, 0.10, 0.15, 0.20]
        if basis_risk_types is None:
            basis_risk_types = ['absolute', 'asymmetric', 'weighted']
            
        self.n_features = n_features
        self.n_params = n_features + 1  # 線性係數 + 噪音參數
        self.epsilon_values = epsilon_values
        self.basis_risk_types = basis_risk_types
        
        # 賠付函數
        self.payout_function = ParametricPayoutFunction()
        
        # CRPS 計算器
        self.crps_calculator = DifferentiableCRPS()
        
        # 存儲結果
        self.vi_results = {}
    
    def compute_basis_risk(self, y_true: np.ndarray, payout_samples: np.ndarray,
                          basis_risk_type: str = 'weighted') -> float:
        """
        計算基差風險
        
        Args:
            y_true: 真實損失
            payout_samples: 賠付樣本
            basis_risk_type: 基差風險類型
            
        Returns:
            基差風險值
        """
        if len(payout_samples.shape) > 1:
            payout_mean = payout_samples.mean(1)
        else:
            payout_mean = payout_samples
            
        if basis_risk_type == 'asymmetric':
            # 只懲罰賠不夠的情況
            basis_risk = np.mean(np.maximum(0, y_true - payout_mean))
        elif basis_risk_type == 'weighted':
            # 加權不對稱懲罰
            under_penalty = np.maximum(0, y_true - payout_mean) * 2.0
            over_penalty = np.maximum(0, payout_mean - y_true) * 0.5
            basis_risk = np.mean(under_penalty + over_penalty)
        else:  # absolute
            basis_risk = np.mean(np.abs(y_true - payout_mean))
        
        return basis_risk
    
    def train_single_model(self,
                         X: np.ndarray,
                         y: np.ndarray,
                         epsilon: float,
                         basis_risk_type: str = 'weighted',
                         n_iterations: int = 100) -> Dict:
        """
        訓練單個 ε-contamination 模型
        
        Args:
            X: 輸入特徵 [N, d]
            y: 真實損失 [N]
            epsilon: ε-contamination 參數
            basis_risk_type: 基差風險類型
            n_iterations: 訓練迭代次數
            
        Returns:
            訓練結果字典
        """
        # 簡化版本的訓練（不需要 PyTorch）
        model = EpsilonContaminationModel(epsilon)
        
        # 初始化參數
        np.random.seed(42)
        theta = np.random.randn(self.n_params) * 0.1
        
        best_basis_risk = np.inf
        best_theta = theta.copy()
        
        # 簡單的優化循環
        for iteration in range(n_iterations):
            # 預測損失分布
            loss_samples = model.predict_distribution(theta, X, 100)
            
            # 計算賠付分布
            payout_samples = self.payout_function.calculate_payout_distribution(loss_samples)
            
            # 計算基差風險
            basis_risk = self.compute_basis_risk(y, payout_samples, basis_risk_type)
            
            # 更新最佳參數
            if basis_risk < best_basis_risk:
                best_basis_risk = basis_risk
                best_theta = theta.copy()
            
            # 簡單的參數更新（隨機擾動）
            theta = theta + np.random.randn(*theta.shape) * 0.01 * (1 - iteration/n_iterations)
        
        return {
            'epsilon': epsilon,
            'basis_risk_type': basis_risk_type,
            'final_basis_risk': best_basis_risk,
            'best_theta': best_theta,
            'converged': True
        }
    
    def run_comprehensive_screening(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """
        執行全面的 VI 篩選
        
        Args:
            X: 輸入特徵
            y: 真實損失
            
        Returns:
            篩選結果
        """
        all_results = []
        
        for epsilon in self.epsilon_values:
            for basis_risk_type in self.basis_risk_types:
                result = self.train_single_model(
                    X, y, epsilon, basis_risk_type, n_iterations=50
                )
                all_results.append(result)
        
        # 按基差風險排序
        all_results = sorted(all_results, key=lambda x: x['final_basis_risk'])
        
        return {
            'all_results': all_results,
            'best_models': all_results[:3],
            'best_model': all_results[0]
        }