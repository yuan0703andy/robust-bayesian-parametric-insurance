#!/usr/bin/env python3
"""
Hierarchical Model Builder
éšå±¤æ¨¡å‹æ§‹å»ºå™¨

ä¿®æ­£ç¾æœ‰visualize_bayesian_model.pyä¸­çš„å•é¡Œï¼š
1. ç¡¬ç·¨ç¢¼çš„region_mapping
2. æœªå®šç¾©çš„distance_matrix  
3. æ²’æœ‰æ•´åˆCat-in-Circleæ•¸æ“šä½œç‚ºH_ij

æä¾›æ­£ç¢ºçš„4å±¤éšå±¤çµæ§‹å¯¦ç¾ï¼Œå¯è¢«ç¾æœ‰ä»£ç¢¼importä½¿ç”¨

ç”¨æ³•ï¼š
from robust_hierarchical_bayesian_simulation.hierarchical_model_builder import build_hierarchical_model
from robust_hierarchical_bayesian_simulation.spatial_data_processor import SpatialDataProcessor

spatial_data = processor.process_hospital_spatial_data(coords)
model = build_hierarchical_model(spatial_data, contamination_epsilon=0.05)
"""

import numpy as np
import pymc as pm
from typing import Dict, Optional, Tuple
from .spatial_data_processor import SpatialData


def build_hierarchical_model(spatial_data: SpatialData,
                           contamination_epsilon: float = 0.0,
                           emanuel_threshold: float = 25.7,
                           model_name: str = "hierarchical_model") -> pm.Model:
    """
    æ§‹å»ºæ­£ç¢ºçš„4å±¤ä½ç½®ç‰¹å®šéšå±¤æ¨¡å‹
    
    Parameters:
    -----------
    spatial_data : SpatialData
        ç©ºé–“æ•¸æ“š (åŒ…å«é†«é™¢åº§æ¨™ã€è·é›¢çŸ©é™£ã€å€åŸŸåˆ†é…ã€Cat-in-Circleæ•¸æ“š)
    contamination_epsilon : float
        Îµ-contaminationåƒæ•¸
    emanuel_threshold : float
        Emanuelè„†å¼±åº¦å‡½æ•¸é–¾å€¼ (mph)
    model_name : str
        æ¨¡å‹åç¨±
        
    Returns:
    --------
    pm.Model : PyMCéšå±¤æ¨¡å‹
    """
    if spatial_data.hazard_intensities is None:
        raise ValueError("spatial_dataç¼ºå°‘hazard_intensitiesï¼Œè«‹èª¿ç”¨add_cat_in_circle_data()")
    
    n_hospitals = spatial_data.n_hospitals
    n_regions = spatial_data.n_regions
    n_events = spatial_data.hazard_intensities.shape[1]
    
    print(f"ğŸ—ï¸ æ§‹å»º{model_name}: {n_hospitals}é†«é™¢, {n_events}äº‹ä»¶, {n_regions}å€åŸŸ")
    
    with pm.Model(name=model_name) as model:
        
        # =================================================================
        # Level 4: è¶…åƒæ•¸å±¤ (Hyperparameter Level)
        # =================================================================
        print("   Level 4: è¶…åƒæ•¸å±¤")
        
        # è®Šç•°æ•¸åƒæ•¸
        Ïƒ_obs = pm.HalfCauchy("Ïƒ_obs", beta=2.5)
        Ïƒ_Î± = pm.HalfCauchy("Ïƒ_Î±", beta=2.5)
        Ïƒ_Î³ = pm.HalfCauchy("Ïƒ_Î³", beta=2.5)
        Ïƒ_Î´ = pm.HalfCauchy("Ïƒ_Î´", beta=2.5)
        
        # ç©ºé–“ç›¸é—œç¯„åœåƒæ•¸
        Ï_spatial = pm.Lognormal("Ï_spatial", mu=np.log(50), sigma=0.5)
        
        # Emanuelè„†å¼±åº¦å‡½æ•¸åƒæ•¸
        vulnerability_power = pm.Gamma("vulnerability_power", alpha=2, beta=0.5)
        
        # =================================================================
        # Level 3: åƒæ•¸å±¤ (Parameter Level) 
        # =================================================================
        print("   Level 3: åƒæ•¸å±¤")
        
        # å€åŸŸå¹³å‡æ•ˆæ‡‰ Î±_r
        Î±_region = pm.Normal("Î±_region", mu=0, sigma=Ïƒ_Î±, shape=n_regions)
        
        # éçµæ§‹åŒ–å€‹é«”éš¨æ©Ÿæ•ˆæ‡‰ Î³_i
        Î³_individual = pm.Normal("Î³_individual", mu=0, sigma=Ïƒ_Î³, shape=n_hospitals)
        
        # ç©ºé–“çµæ§‹åŒ–éš¨æ©Ÿæ•ˆæ‡‰ Î´_i
        # ä½¿ç”¨çœŸå¯¦è·é›¢çŸ©é™£æ§‹å»ºå”æ–¹å·®
        cov_matrix = Ïƒ_Î´**2 * pm.math.exp(-spatial_data.distance_matrix / Ï_spatial)
        nugget = 0.01
        cov_matrix_stable = cov_matrix + nugget * np.eye(n_hospitals)
        
        Î´_spatial = pm.MvNormal("Î´_spatial", mu=0, cov=cov_matrix_stable, shape=n_hospitals)
        
        # =================================================================
        # Level 2: éç¨‹å±¤ (Process Level) - ä½ç½®ç‰¹å®šè„†å¼±åº¦åƒæ•¸
        # =================================================================
        print("   Level 2: éç¨‹å±¤")
        
        # ä½¿ç”¨çœŸå¯¦å€åŸŸåˆ†é…è€Œéç¡¬ç·¨ç¢¼
        region_effects = Î±_region[spatial_data.region_assignments]
        
        # Î²_i = Î±_{r(i)} + Î´_i + Î³_i
        Î²_vulnerability = pm.Deterministic("Î²_vulnerability", 
                                         region_effects + Î´_spatial + Î³_individual)
        
        # =================================================================
        # Level 1: è§€æ¸¬å±¤ (Likelihood) - ç½å®³é¢¨éšªæ ¸å¿ƒå…¬å¼
        # =================================================================
        print("   Level 1: è§€æ¸¬å±¤")
        
        # ä½¿ç”¨çœŸå¯¦Cat-in-Circleæ•¸æ“šä½œç‚ºç½å®³å¼·åº¦H_ij
        H_ij = spatial_data.hazard_intensities  # (n_hospitals, n_events)
        E_i = spatial_data.exposure_values      # (n_hospitals,)
        
        # Emanuelè„†å¼±åº¦å‡½æ•¸: V(H_ij; Î²_i) = exp(Î²_i) * max(H_ij - threshold, 0)^power
        hazard_excess = pm.math.maximum(H_ij - emanuel_threshold, 0.0)
        
        # å»£æ’­è™•ç†
        Î²_broadcast = Î²_vulnerability[:, None]      # (n_hospitals, 1)
        E_broadcast = E_i[:, None]                  # (n_hospitals, 1)
        
        # æœŸæœ›æå¤±: Î¼_ij = E_i Ã— V(H_ij; Î²_i)
        expected_losses = pm.Deterministic("expected_losses",
            E_broadcast * pm.math.exp(Î²_broadcast) * 
            (hazard_excess ** vulnerability_power))
        
        # Îµ-contaminationè™•ç†
        if contamination_epsilon > 0:
            print(f"   ğŸ›¡ï¸ æ‡‰ç”¨Îµ-contamination (Îµ={contamination_epsilon})")
            contamination_factor = pm.Lognormal("contamination_factor", mu=0, sigma=1.5)
            
            expected_losses_contaminated = pm.Deterministic("expected_losses_contaminated",
                (1 - contamination_epsilon) * expected_losses + 
                contamination_epsilon * expected_losses * contamination_factor)
            
            likelihood_mean = expected_losses_contaminated
        else:
            likelihood_mean = expected_losses
        
        # æ•¸å€¼ç©©å®šæ€§è™•ç†
        likelihood_stable = pm.math.maximum(likelihood_mean, 1.0)
        
        # è§€æ¸¬æå¤±: L_ij ~ LogNormal(log(Î¼_ij), Ïƒ_obsÂ²)
        observed_flat = spatial_data.observed_losses.flatten()
        likelihood_flat = likelihood_stable.flatten()
        
        L_obs = pm.Lognormal("L_obs",
                           mu=pm.math.log(likelihood_flat),
                           sigma=Ïƒ_obs,
                           observed=observed_flat)
    
    print(f"âœ… éšå±¤æ¨¡å‹æ§‹å»ºå®Œæˆ")
    return model


def get_portfolio_loss_predictions(trace, spatial_data: SpatialData, 
                                 event_indices: Optional[list] = None) -> Dict:
    """
    ç²å–æŠ•è³‡çµ„åˆç´šæå¤±é æ¸¬
    
    Parameters:
    -----------
    trace : az.InferenceData
        MCMCå¾Œé©—æ¨£æœ¬
    spatial_data : SpatialData
        ç©ºé–“æ•¸æ“š
    event_indices : list, optional
        è¦åˆ†æçš„äº‹ä»¶ç´¢å¼•ï¼Œé»˜èªåˆ†ææ‰€æœ‰äº‹ä»¶
        
    Returns:
    --------
    Dict : æŠ•è³‡çµ„åˆæå¤±çµ±è¨ˆ
    """
    if event_indices is None:
        event_indices = list(range(spatial_data.hazard_intensities.shape[1]))
    
    expected_losses = trace.posterior["expected_losses"]  # (chains, draws, hospitals, events)
    
    portfolio_results = {}
    
    for event_idx in event_indices:
        # é¸æ“‡ç‰¹å®šäº‹ä»¶çš„æå¤±
        event_losses = expected_losses[:, :, :, event_idx]  # (chains, draws, hospitals)
        
        # æŠ•è³‡çµ„åˆç¸½æå¤± = æ‰€æœ‰é†«é™¢æå¤±ä¹‹å’Œ
        portfolio_losses = event_losses.sum(axis=2)  # (chains, draws)
        portfolio_flat = portfolio_losses.values.flatten()
        
        portfolio_results[f"event_{event_idx}"] = {
            "total_loss_samples": portfolio_flat,
            "mean": np.mean(portfolio_flat),
            "std": np.std(portfolio_flat),
            "percentiles": {
                "5%": np.percentile(portfolio_flat, 5),
                "25%": np.percentile(portfolio_flat, 25),
                "50%": np.percentile(portfolio_flat, 50),
                "75%": np.percentile(portfolio_flat, 75),
                "95%": np.percentile(portfolio_flat, 95)
            },
            "individual_means": event_losses.mean(axis=(0,1)),  # æ¯å®¶é†«é™¢çš„å¹³å‡æå¤±
            "spatial_correlation": np.corrcoef(event_losses.mean(axis=(0,1)))
        }
    
    # æ•´é«”çµ±è¨ˆ
    all_events_losses = expected_losses.sum(axis=2)  # (chains, draws, events)
    portfolio_results["summary"] = {
        "mean_loss_per_event": np.mean(all_events_losses.values, axis=(0,1)),
        "total_expected_loss": np.sum(all_events_losses.values.mean(axis=(0,1))),
        "portfolio_volatility": np.std(all_events_losses.values.sum(axis=2))
    }
    
    return portfolio_results


def validate_model_inputs(spatial_data: SpatialData) -> bool:
    """
    é©—è­‰æ¨¡å‹è¼¸å…¥æ•¸æ“šçš„å®Œæ•´æ€§
    
    Parameters:
    -----------
    spatial_data : SpatialData
        è¦é©—è­‰çš„ç©ºé–“æ•¸æ“š
        
    Returns:
    --------
    bool : æ˜¯å¦é€šéé©—è­‰
    """
    issues = []
    
    # æª¢æŸ¥åŸºæœ¬æ•¸æ“š
    if spatial_data.hospital_coords is None:
        issues.append("ç¼ºå°‘hospital_coords")
    
    if spatial_data.distance_matrix is None:
        issues.append("ç¼ºå°‘distance_matrix")
    
    if spatial_data.region_assignments is None:
        issues.append("ç¼ºå°‘region_assignments")
    
    # æª¢æŸ¥Cat-in-Circleæ•¸æ“š
    if spatial_data.hazard_intensities is None:
        issues.append("ç¼ºå°‘hazard_intensities (Cat-in-Circleæ•¸æ“š)")
    
    if spatial_data.exposure_values is None:
        issues.append("ç¼ºå°‘exposure_values")
    
    if spatial_data.observed_losses is None:
        issues.append("ç¼ºå°‘observed_losses")
    
    # æª¢æŸ¥ç¶­åº¦ä¸€è‡´æ€§
    if spatial_data.hazard_intensities is not None and spatial_data.exposure_values is not None:
        n_hospitals_h = spatial_data.hazard_intensities.shape[0]
        n_hospitals_e = len(spatial_data.exposure_values)
        if n_hospitals_h != n_hospitals_e:
            issues.append(f"é†«é™¢æ•¸é‡ä¸ä¸€è‡´: hazard {n_hospitals_h} vs exposure {n_hospitals_e}")
    
    if spatial_data.distance_matrix is not None:
        n_hospitals_d = spatial_data.distance_matrix.shape[0]
        if n_hospitals_d != spatial_data.n_hospitals:
            issues.append(f"è·é›¢çŸ©é™£ç¶­åº¦ä¸åŒ¹é…: {n_hospitals_d} vs {spatial_data.n_hospitals}")
    
    if issues:
        print(f"âŒ æ¨¡å‹è¼¸å…¥é©—è­‰å¤±æ•—:")
        for issue in issues:
            print(f"   â€¢ {issue}")
        return False
    else:
        print(f"âœ… æ¨¡å‹è¼¸å…¥é©—è­‰é€šé")
        return True


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    from .spatial_data_processor import SpatialDataProcessor
    
    # å‰µå»ºæ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    hospital_coords = np.random.uniform([35.0, -84.0], [36.5, -75.5], (5, 2))
    
    processor = SpatialDataProcessor()
    spatial_data = processor.process_hospital_spatial_data(hospital_coords, n_regions=3)
    
    # æ·»åŠ Cat-in-Circleæ•¸æ“š
    n_hospitals, n_events = 5, 20
    hazard_intensities = np.random.uniform(20, 60, (n_hospitals, n_events))
    exposure_values = np.random.uniform(1e7, 5e7, n_hospitals)
    observed_losses = np.random.lognormal(15, 1, (n_hospitals, n_events))
    
    spatial_data = processor.add_cat_in_circle_data(
        hazard_intensities, exposure_values, observed_losses
    )
    
    # é©—è­‰ä¸¦æ§‹å»ºæ¨¡å‹
    if validate_model_inputs(spatial_data):
        model = build_hierarchical_model(spatial_data, contamination_epsilon=0.05)
        print(f"æ¨¡å‹è®Šé‡æ•¸é‡: {len(model.free_RVs)}")
    else:
        print("æ¨¡å‹è¼¸å…¥é©—è­‰å¤±æ•—")