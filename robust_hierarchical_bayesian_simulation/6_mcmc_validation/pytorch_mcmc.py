#!/usr/bin/env python3
"""
PyTorch-based MCMC Implementation
åŸºæ–¼PyTorchçš„MCMCå¯¦ç¾

å®Œå…¨ä½¿ç”¨PyTorché‡å¯«MCMCï¼Œæ”¯æ´GPUåŠ é€Ÿ
å¯¦ç¾HMC (Hamiltonian Monte Carlo) å’Œ NUTS (No-U-Turn Sampler)

Author: Research Team
Date: 2025-01-18
"""

import torch
import torch.nn as nn
import torch.distributions as dist
import numpy as np
from typing import Dict, List, Optional, Tuple, Callable, Any
from dataclasses import dataclass
import time
import warnings
warnings.filterwarnings('ignore')

# ========================================
# MCMCé…ç½®
# ========================================

@dataclass
class MCMCConfig:
    """MCMCé…ç½®"""
    n_samples: int = 2000
    n_warmup: int = 1000
    n_chains: int = 4
    step_size: float = 0.01
    num_steps: int = 10
    target_accept: float = 0.8
    adapt_step_size: bool = True
    adapt_mass_matrix: bool = True
    max_tree_depth: int = 10
    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'
    dtype: torch.dtype = torch.float32
    seed: int = 42

# ========================================
# PyTorch MCMCåŸºç¤é¡
# ========================================

class PytorchMCMC:
    """PyTorch MCMCåŸºç¤é¡"""
    
    def __init__(self, config: MCMCConfig = None):
        """
        åˆå§‹åŒ–MCMCæ¡æ¨£å™¨
        
        Parameters:
        -----------
        config : MCMCConfig
            MCMCé…ç½®
        """
        self.config = config or MCMCConfig()
        
        # è¨­å®šè¨­å‚™å’Œæ•¸æ“šé¡å‹
        self.device = torch.device(self.config.device)
        self.dtype = self.config.dtype
        
        # è¨­å®šéš¨æ©Ÿç¨®å­
        torch.manual_seed(self.config.seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(self.config.seed)
        
        print(f"ğŸš€ PyTorch MCMCåˆå§‹åŒ–")
        print(f"   è¨­å‚™: {self.device}")
        print(f"   æ•¸æ“šé¡å‹: {self.dtype}")
        
        # æ¡æ¨£çµæœå­˜å„²
        self.samples = None
        self.log_probs = None
        self.accept_rates = None
        self.diagnostics = {}
    
    def log_prob_fn(self, theta: torch.Tensor, data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        è¨ˆç®—log probability (éœ€è¦å­é¡å¯¦ç¾)
        
        Parameters:
        -----------
        theta : torch.Tensor
            åƒæ•¸å‘é‡
        data : Dict[str, torch.Tensor]
            è§€æ¸¬æ•¸æ“š
            
        Returns:
        --------
        torch.Tensor
            log probability
        """
        raise NotImplementedError("éœ€è¦å¯¦ç¾log_prob_fn")
    
    def grad_log_prob(self, theta: torch.Tensor, data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        è¨ˆç®—log probabilityçš„æ¢¯åº¦
        
        Parameters:
        -----------
        theta : torch.Tensor
            åƒæ•¸å‘é‡
        data : Dict[str, torch.Tensor]
            è§€æ¸¬æ•¸æ“š
            
        Returns:
        --------
        torch.Tensor
            æ¢¯åº¦
        """
        theta = theta.requires_grad_(True)
        log_prob = self.log_prob_fn(theta, data)
        grad = torch.autograd.grad(log_prob.sum(), theta)[0]
        return grad

# ========================================
# HMC (Hamiltonian Monte Carlo)
# ========================================

class HamiltonianMonteCarlo(PytorchMCMC):
    """Hamiltonian Monte Carloæ¡æ¨£å™¨"""
    
    def __init__(self, config: MCMCConfig = None):
        super().__init__(config)
        self.step_size = self.config.step_size
        self.num_steps = self.config.num_steps
        self.mass_matrix = None
    
    def leapfrog(self, theta: torch.Tensor, momentum: torch.Tensor, 
                 data: Dict[str, torch.Tensor]) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        Leapfrogç©åˆ†å™¨
        
        Parameters:
        -----------
        theta : torch.Tensor
            ç•¶å‰ä½ç½®
        momentum : torch.Tensor
            ç•¶å‰å‹•é‡
        data : Dict[str, torch.Tensor]
            æ•¸æ“š
            
        Returns:
        --------
        Tuple[torch.Tensor, torch.Tensor]
            æ–°ä½ç½®å’Œæ–°å‹•é‡
        """
        # è¤‡è£½ä»¥é¿å…åŸåœ°ä¿®æ”¹
        theta = theta.clone()
        momentum = momentum.clone()
        
        # åŠæ­¥æ›´æ–°å‹•é‡
        grad = self.grad_log_prob(theta, data)
        momentum = momentum + 0.5 * self.step_size * grad
        
        # å®Œæ•´æ­¥æ›´æ–°ä½ç½®å’Œå‹•é‡
        for _ in range(self.num_steps - 1):
            theta = theta + self.step_size * momentum
            grad = self.grad_log_prob(theta, data)
            momentum = momentum + self.step_size * grad
        
        # æœ€å¾Œæ›´æ–°ä½ç½®
        theta = theta + self.step_size * momentum
        
        # æœ€å¾ŒåŠæ­¥æ›´æ–°å‹•é‡
        grad = self.grad_log_prob(theta, data)
        momentum = momentum + 0.5 * self.step_size * grad
        
        return theta, momentum
    
    def sample_one_chain(self, initial_theta: torch.Tensor, 
                        data: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:
        """
        é‹è¡Œå–®æ¢éˆçš„HMCæ¡æ¨£
        
        Parameters:
        -----------
        initial_theta : torch.Tensor
            åˆå§‹åƒæ•¸å€¼
        data : Dict[str, torch.Tensor]
            æ•¸æ“š
            
        Returns:
        --------
        Dict[str, torch.Tensor]
            æ¡æ¨£çµæœ
        """
        n_params = initial_theta.shape[0]
        n_total = self.config.n_warmup + self.config.n_samples
        
        # åˆå§‹åŒ–å­˜å„²
        samples = torch.zeros((n_total, n_params), device=self.device, dtype=self.dtype)
        log_probs = torch.zeros(n_total, device=self.device, dtype=self.dtype)
        accepted = torch.zeros(n_total, dtype=torch.bool, device=self.device)
        
        # åˆå§‹åŒ–
        current_theta = initial_theta.clone()
        current_log_prob = self.log_prob_fn(current_theta, data)
        
        # è‡ªé©æ‡‰åƒæ•¸
        if self.config.adapt_step_size:
            step_size_adapter = DualAveragingStepSize(
                initial_step_size=self.step_size,
                target_accept=self.config.target_accept
            )
        
        # ä¸»æ¡æ¨£å¾ªç’°
        for i in range(n_total):
            # æ¡æ¨£å‹•é‡
            momentum = torch.randn_like(current_theta)
            current_momentum = momentum.clone()
            
            # Leapfrogç©åˆ†
            proposed_theta, proposed_momentum = self.leapfrog(
                current_theta, momentum, data
            )
            
            # è¨ˆç®—æ¥å—æ¦‚ç‡
            proposed_log_prob = self.log_prob_fn(proposed_theta, data)
            
            current_hamiltonian = current_log_prob - 0.5 * torch.sum(current_momentum ** 2)
            proposed_hamiltonian = proposed_log_prob - 0.5 * torch.sum(proposed_momentum ** 2)
            
            log_accept_prob = proposed_hamiltonian - current_hamiltonian
            accept_prob = torch.exp(torch.clamp(log_accept_prob, max=0))
            
            # æ¥å—/æ‹’çµ•
            if torch.rand(1, device=self.device) < accept_prob:
                current_theta = proposed_theta
                current_log_prob = proposed_log_prob
                accepted[i] = True
            
            # å­˜å„²æ¨£æœ¬
            samples[i] = current_theta
            log_probs[i] = current_log_prob
            
            # è‡ªé©æ‡‰èª¿æ•´ï¼ˆç†±èº«æœŸï¼‰
            if i < self.config.n_warmup and self.config.adapt_step_size:
                self.step_size = step_size_adapter.update(accept_prob.item())
        
        # åªè¿”å›æ¡æ¨£æœŸçš„æ¨£æœ¬
        return {
            'samples': samples[self.config.n_warmup:],
            'log_probs': log_probs[self.config.n_warmup:],
            'accept_rate': accepted[self.config.n_warmup:].float().mean().item(),
            'warmup_accept_rate': accepted[:self.config.n_warmup].float().mean().item()
        }
    
    def sample(self, data: Dict[str, torch.Tensor], 
              initial_values: Optional[torch.Tensor] = None) -> Dict[str, Any]:
        """
        é‹è¡Œå¤šéˆHMCæ¡æ¨£
        
        Parameters:
        -----------
        data : Dict[str, torch.Tensor]
            æ•¸æ“š
        initial_values : torch.Tensor, optional
            åˆå§‹å€¼
            
        Returns:
        --------
        Dict[str, Any]
            æ¡æ¨£çµæœå’Œè¨ºæ–·
        """
        print(f"\nğŸ¯ é–‹å§‹HMCæ¡æ¨£")
        print(f"   éˆæ•¸: {self.config.n_chains}")
        print(f"   æ¨£æœ¬æ•¸/éˆ: {self.config.n_samples}")
        print(f"   ç†±èº«æ•¸/éˆ: {self.config.n_warmup}")
        
        start_time = time.time()
        
        # ç¢ºå®šåƒæ•¸ç¶­åº¦
        if initial_values is None:
            # éœ€è¦å¾æ•¸æ“šæ¨æ–·åƒæ•¸ç¶­åº¦
            n_params = 10  # é è¨­å€¼ï¼Œå¯¦éš›æ‡‰è©²æ ¹æ“šæ¨¡å‹ç¢ºå®š
            initial_values = torch.randn(self.config.n_chains, n_params, 
                                        device=self.device, dtype=self.dtype)
        
        # é‹è¡Œå¤šæ¢éˆ
        chain_results = []
        for chain_id in range(self.config.n_chains):
            print(f"   é‹è¡Œéˆ {chain_id + 1}/{self.config.n_chains}...")
            
            result = self.sample_one_chain(
                initial_theta=initial_values[chain_id],
                data=data
            )
            chain_results.append(result)
        
        # åˆä½µçµæœ
        all_samples = torch.stack([r['samples'] for r in chain_results])
        all_log_probs = torch.stack([r['log_probs'] for r in chain_results])
        accept_rates = [r['accept_rate'] for r in chain_results]
        
        # è¨ˆç®—è¨ºæ–·çµ±è¨ˆ
        self.samples = all_samples
        self.log_probs = all_log_probs
        self.accept_rates = accept_rates
        
        self.diagnostics = self.compute_diagnostics()
        
        elapsed_time = time.time() - start_time
        
        print(f"\nâœ… HMCæ¡æ¨£å®Œæˆ")
        print(f"   ç¸½æ™‚é–“: {elapsed_time:.2f} ç§’")
        print(f"   å¹³å‡æ¥å—ç‡: {np.mean(accept_rates):.2%}")
        print(f"   R-hat: {self.diagnostics['rhat']:.3f}")
        print(f"   ESS: {self.diagnostics['ess']:.0f}")
        
        return {
            'samples': all_samples,
            'log_probs': all_log_probs,
            'accept_rates': accept_rates,
            'diagnostics': self.diagnostics,
            'elapsed_time': elapsed_time
        }
    
    def compute_diagnostics(self) -> Dict[str, Any]:
        """è¨ˆç®—MCMCè¨ºæ–·çµ±è¨ˆ"""
        if self.samples is None:
            return {}
        
        # è½‰æ›ç‚ºnumpyé€²è¡Œè¨ºæ–·è¨ˆç®—
        samples_np = self.samples.cpu().numpy()
        
        # R-hat (Gelman-Rubinçµ±è¨ˆ)
        rhat = self.compute_rhat(samples_np)
        
        # ESS (æœ‰æ•ˆæ¨£æœ¬å¤§å°)
        ess = self.compute_ess(samples_np)
        
        return {
            'rhat': rhat,
            'ess': ess,
            'mean_accept_rate': np.mean(self.accept_rates),
            'min_accept_rate': np.min(self.accept_rates),
            'max_accept_rate': np.max(self.accept_rates)
        }
    
    def compute_rhat(self, samples: np.ndarray) -> float:
        """è¨ˆç®—R-hatçµ±è¨ˆ"""
        n_chains, n_samples, n_params = samples.shape
        
        # è¨ˆç®—éˆé–“å’Œéˆå…§è®Šç•°
        chain_means = np.mean(samples, axis=1)
        grand_mean = np.mean(chain_means, axis=0)
        
        B = n_samples * np.var(chain_means, axis=0, ddof=1)
        W = np.mean(np.var(samples, axis=1, ddof=1), axis=0)
        
        var_estimate = ((n_samples - 1) * W + B) / n_samples
        rhat = np.sqrt(var_estimate / W)
        
        return np.mean(rhat)
    
    def compute_ess(self, samples: np.ndarray) -> float:
        """è¨ˆç®—æœ‰æ•ˆæ¨£æœ¬å¤§å°"""
        n_chains, n_samples, n_params = samples.shape
        
        # ç°¡åŒ–çš„ESSè¨ˆç®—
        # å¯¦éš›æ‡‰è©²ä½¿ç”¨æ›´è¤‡é›œçš„è‡ªç›¸é—œæ–¹æ³•
        pooled_samples = samples.reshape(-1, n_params)
        ess = n_chains * n_samples  # ç°¡åŒ–ç‰ˆæœ¬
        
        return ess

# ========================================
# è‡ªé©æ‡‰æ­¥é•·èª¿æ•´
# ========================================

class DualAveragingStepSize:
    """é›™é‡å¹³å‡æ­¥é•·è‡ªé©æ‡‰"""
    
    def __init__(self, initial_step_size: float = 1.0, 
                 target_accept: float = 0.8,
                 gamma: float = 0.05,
                 t0: float = 10.0,
                 kappa: float = 0.75):
        self.mu = np.log(10 * initial_step_size)
        self.target_accept = target_accept
        self.gamma = gamma
        self.t0 = t0
        self.kappa = kappa
        
        self.log_step_size = np.log(initial_step_size)
        self.log_step_size_bar = 0.0
        self.h_bar = 0.0
        self.iteration = 0
    
    def update(self, accept_prob: float) -> float:
        """æ›´æ–°æ­¥é•·"""
        self.iteration += 1
        
        # æ›´æ–°Hçµ±è¨ˆ
        self.h_bar = (1 - 1 / (self.iteration + self.t0)) * self.h_bar + \
                     (self.target_accept - accept_prob) / (self.iteration + self.t0)
        
        # æ›´æ–°æ­¥é•·
        self.log_step_size = self.mu - np.sqrt(self.iteration) / self.gamma * self.h_bar
        
        # æ›´æ–°å¹³å‡æ­¥é•·
        eta = self.iteration ** (-self.kappa)
        self.log_step_size_bar = eta * self.log_step_size + (1 - eta) * self.log_step_size_bar
        
        return np.exp(self.log_step_size)

# ========================================
# CRPS-aware MCMC
# ========================================

class CRPSAwareMCMC(HamiltonianMonteCarlo):
    """CRPS-aware MCMCæ¡æ¨£å™¨"""
    
    def __init__(self, config: MCMCConfig = None, crps_weight: float = 1.0):
        super().__init__(config)
        self.crps_weight = crps_weight
    
    def crps_score(self, predictions: torch.Tensor, observations: torch.Tensor) -> torch.Tensor:
        """
        è¨ˆç®—CRPSåˆ†æ•¸
        
        Parameters:
        -----------
        predictions : torch.Tensor
            é æ¸¬åˆ†å¸ƒæ¨£æœ¬ [n_samples, n_obs]
        observations : torch.Tensor
            è§€æ¸¬å€¼ [n_obs]
            
        Returns:
        --------
        torch.Tensor
            CRPSåˆ†æ•¸
        """
        # ä½¿ç”¨ç°¡åŒ–çš„CRPSè¨ˆç®—
        # CRPS = E[|X - y|] - 0.5 * E[|X - X'|]
        
        n_samples = predictions.shape[0]
        
        # ç¬¬ä¸€é …ï¼šé æ¸¬èˆ‡è§€æ¸¬çš„å·®ç•°
        term1 = torch.mean(torch.abs(predictions - observations.unsqueeze(0)))
        
        # ç¬¬äºŒé …ï¼šé æ¸¬æ¨£æœ¬é–“çš„å·®ç•°
        if n_samples > 1:
            # éš¨æ©Ÿé¸æ“‡æ¨£æœ¬å°
            idx1 = torch.randperm(n_samples)[:n_samples//2]
            idx2 = torch.randperm(n_samples)[:n_samples//2]
            term2 = torch.mean(torch.abs(predictions[idx1] - predictions[idx2]))
        else:
            term2 = 0.0
        
        crps = term1 - 0.5 * term2
        return crps
    
    def log_prob_fn(self, theta: torch.Tensor, data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        CRPS-aware log probability
        
        çµåˆæ¨™æº–log likelihoodå’ŒCRPSæ‡²ç½°
        """
        # æ¨™æº–log likelihood
        X = data['X']
        y = data['y']
        
        # ç°¡å–®ç·šæ€§æ¨¡å‹ä½œç‚ºç¤ºä¾‹
        predictions = torch.matmul(X, theta[:X.shape[1]])
        
        # æ­£æ…‹ä¼¼ç„¶
        sigma = torch.exp(theta[-1])  # æœ€å¾Œä¸€å€‹åƒæ•¸æ˜¯log(sigma)
        log_likelihood = -0.5 * torch.sum((y - predictions) ** 2) / (sigma ** 2) - \
                        len(y) * torch.log(sigma)
        
        # CRPSæ‡²ç½°
        # ç”Ÿæˆé æ¸¬åˆ†å¸ƒæ¨£æœ¬
        pred_samples = predictions.unsqueeze(0) + sigma * torch.randn(100, len(y), 
                                                                      device=self.device)
        crps = self.crps_score(pred_samples, y)
        
        # çµåˆå…©è€…
        log_prob = log_likelihood - self.crps_weight * crps
        
        # æ·»åŠ å…ˆé©—
        prior = -0.5 * torch.sum(theta ** 2) / 100  # å¼±å…ˆé©—
        
        return log_prob + prior

# ========================================
# æ¨¡å‹ç‰¹å®šçš„MCMCå¯¦ç¾
# ========================================

class BayesianHierarchicalMCMC(CRPSAwareMCMC):
    """è²è‘‰æ–¯éšå±¤æ¨¡å‹MCMC"""
    
    def __init__(self, vulnerability_type: str = 'emanuel', 
                 config: MCMCConfig = None):
        super().__init__(config)
        self.vulnerability_type = vulnerability_type
    
    def emanuel_vulnerability(self, wind_speed: torch.Tensor, 
                             params: Dict[str, torch.Tensor]) -> torch.Tensor:
        """Emanuelè„†å¼±åº¦å‡½æ•¸"""
        a = params['a']
        b = params['b']
        threshold = 25.0
        
        wind_excess = torch.clamp(wind_speed - threshold, min=0)
        vulnerability = torch.clamp(a * wind_excess ** b, max=1.0)
        
        return vulnerability
    
    def log_prob_fn(self, theta: torch.Tensor, data: Dict[str, torch.Tensor]) -> torch.Tensor:
        """
        éšå±¤æ¨¡å‹çš„log probability
        """
        # è§£åŒ…åƒæ•¸
        n_params = len(theta)
        
        # Emanuelå‡½æ•¸åƒæ•¸
        log_a = theta[0]
        b = theta[1]
        
        # éšå±¤åƒæ•¸
        alpha = theta[2]  # æˆªè·
        beta = theta[3:5] if n_params > 4 else torch.zeros(2, device=self.device)
        
        # è§€æ¸¬èª¤å·®
        log_sigma = theta[-1]
        
        # è½‰æ›åƒæ•¸
        a = torch.exp(log_a)
        sigma = torch.exp(log_sigma)
        
        # è¨ˆç®—è„†å¼±åº¦
        params = {'a': a, 'b': b}
        vulnerability = self.emanuel_vulnerability(data['wind_speed'], params)
        
        # è¨ˆç®—é æœŸæå¤±
        expected_loss = vulnerability * data['exposure'] * torch.exp(alpha)
        
        # å°æ•¸ä¼¼ç„¶
        log_likelihood = -0.5 * torch.sum((data['losses'] - expected_loss) ** 2) / (sigma ** 2)
        log_likelihood -= len(data['losses']) * torch.log(sigma)
        
        # å…ˆé©—
        log_prior = 0.0
        
        # açš„Gammaå…ˆé©—
        log_prior += -2 * log_a - a / 500  # Gamma(2, 500)
        
        # bçš„æ­£æ…‹å…ˆé©—
        log_prior += -0.5 * (b - 2.0) ** 2 / 0.25  # Normal(2, 0.5)
        
        # alphaçš„æ­£æ…‹å…ˆé©—
        log_prior += -0.5 * alpha ** 2 / 4  # Normal(0, 2)
        
        # sigmaçš„åŠæ­£æ…‹å…ˆé©—
        log_prior += -0.5 * log_sigma ** 2  # HalfNormal via log transform
        
        return log_likelihood + log_prior

# ========================================
# ä¾¿åˆ©å‡½æ•¸
# ========================================

def run_pytorch_mcmc(data: Dict[str, Any], 
                     model_type: str = 'hierarchical',
                     use_gpu: bool = True,
                     n_chains: int = 4,
                     n_samples: int = 2000) -> Dict[str, Any]:
    """
    é‹è¡ŒPyTorch MCMCçš„ä¾¿åˆ©å‡½æ•¸
    
    Parameters:
    -----------
    data : Dict[str, Any]
        æ•¸æ“š
    model_type : str
        æ¨¡å‹é¡å‹
    use_gpu : bool
        æ˜¯å¦ä½¿ç”¨GPU
    n_chains : int
        éˆæ•¸
    n_samples : int
        æ¨£æœ¬æ•¸
        
    Returns:
    --------
    Dict[str, Any]
        MCMCçµæœ
    """
    # é…ç½®
    device = 'cuda' if (use_gpu and torch.cuda.is_available()) else 'cpu'
    config = MCMCConfig(
        n_chains=n_chains,
        n_samples=n_samples,
        n_warmup=n_samples // 2,
        device=device
    )
    
    # è½‰æ›æ•¸æ“šåˆ°torch
    torch_data = {}
    for key, value in data.items():
        if isinstance(value, np.ndarray):
            torch_data[key] = torch.tensor(value, device=device, dtype=torch.float32)
        else:
            torch_data[key] = value
    
    # é¸æ“‡æ¨¡å‹
    if model_type == 'hierarchical':
        mcmc = BayesianHierarchicalMCMC(config=config)
    elif model_type == 'crps':
        mcmc = CRPSAwareMCMC(config=config)
    elif model_type == 'basic':
        mcmc = CRPSAwareMCMC(config=config)  # ä½¿ç”¨CRPS-awareä½œç‚ºåŸºæœ¬å¯¦ç¾
    else:
        mcmc = HamiltonianMonteCarlo(config=config)
    
    # é‹è¡ŒMCMC
    results = mcmc.sample(torch_data)
    
    return results

# ========================================
# æ¸¬è©¦
# ========================================

def test_pytorch_mcmc():
    """æ¸¬è©¦PyTorch MCMC"""
    print("ğŸ§ª æ¸¬è©¦PyTorch MCMCå¯¦ç¾")
    
    # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
    np.random.seed(42)
    n_obs = 100
    
    data = {
        'wind_speed': np.random.uniform(20, 80, n_obs),
        'exposure': np.random.uniform(1e6, 1e8, n_obs),
        'losses': np.random.uniform(0, 1e6, n_obs),
        'X': np.random.randn(n_obs, 5),
        'y': np.random.randn(n_obs)
    }
    
    # æ¸¬è©¦åŸºæœ¬HMC
    print("\n1. æ¸¬è©¦åŸºæœ¬HMC")
    results = run_pytorch_mcmc(
        data=data,
        model_type='basic',
        use_gpu=torch.cuda.is_available(),
        n_chains=2,
        n_samples=500
    )
    
    print(f"   æ¡æ¨£å½¢ç‹€: {results['samples'].shape}")
    print(f"   æ¥å—ç‡: {np.mean(results['accept_rates']):.2%}")
    
    # æ¸¬è©¦éšå±¤æ¨¡å‹
    print("\n2. æ¸¬è©¦éšå±¤æ¨¡å‹MCMC")
    results = run_pytorch_mcmc(
        data=data,
        model_type='hierarchical',
        use_gpu=torch.cuda.is_available(),
        n_chains=2,
        n_samples=500
    )
    
    print(f"   R-hat: {results['diagnostics']['rhat']:.3f}")
    print(f"   ESS: {results['diagnostics']['ess']:.0f}")
    
    print("\nâœ… PyTorch MCMCæ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    test_pytorch_mcmc()