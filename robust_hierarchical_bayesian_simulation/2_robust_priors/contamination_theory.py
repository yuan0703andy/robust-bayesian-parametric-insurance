#!/usr/bin/env python3
"""
Contamination Theory Module
æ±¡æŸ“ç†è«–æ¨¡çµ„

å¾ epsilon_contamination.py æ‹†åˆ†å‡ºçš„ç†è«–åŸºç¤éƒ¨åˆ†
åŒ…å«åŸºæœ¬çš„æ•¸å­¸ç†è«–ã€æšèˆ‰å®šç¾©å’Œæ ¸å¿ƒæ¦‚å¿µ

æ•¸å­¸åŸºç¤:
Î“_Îµ = {Ï€(Î¸): Ï€(Î¸) = (1-Îµ)Ï€â‚€(Î¸) + Îµq(Î¸), for all q âˆˆ Q}

æ ¸å¿ƒåŠŸèƒ½:
- æ±¡æŸ“åˆ†å¸ƒé¡åˆ¥å®šç¾©
- Îµ-contamination è¦æ ¼é…ç½®
- åŸºæœ¬ç†è«–å·¥å…·

Author: Research Team  
Date: 2025-01-17
"""

import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union
from enum import Enum
from dataclasses import dataclass, field
from scipy import stats

# ========================================
# åŸºæœ¬æšèˆ‰å®šç¾©
# ========================================

class ContaminationDistributionClass(Enum):
    """
    æ±¡æŸ“åˆ†ä½ˆé¡åˆ¥ Q çš„å®šç¾©
    Definition of contamination distribution class Q
    """
    ALL_DISTRIBUTIONS = "all"                    # æ‰€æœ‰æ¦‚ç‡åˆ†ä½ˆ
    TYPHOON_SPECIFIC = "typhoon_specific"        # é¢±é¢¨ç‰¹å®šæ¥µå€¼åˆ†ä½ˆ
    HEAVY_TAILED = "heavy_tailed"               # é‡å°¾åˆ†ä½ˆ
    MOMENT_BOUNDED = "moment_bounded"           # çŸ©æœ‰ç•Œåˆ†ä½ˆ
    UNIMODAL = "unimodal"                      # å–®å³°åˆ†ä½ˆ

class RobustnessCriterion(Enum):
    """å¼·å¥æ€§æº–å‰‡"""
    WORST_CASE = "worst_case"                    # æœ€å£æƒ…æ³
    AVERAGE_CASE = "average_case"                # å¹³å‡æƒ…æ³
    MINIMAX = "minimax"                          # æœ€å°æœ€å¤§
    MAXIMUM_ENTROPY = "maximum_entropy"          # æœ€å¤§ç†µ

class EstimationMethod(Enum):
    """Îµä¼°è¨ˆæ–¹æ³•"""
    EMPIRICAL_FREQUENCY = "empirical_frequency"  # ç¶“é©—é »ç‡
    KOLMOGOROV_SMIRNOV = "kolmogorov_smirnov"   # K-Sæª¢é©—
    ANDERSON_DARLING = "anderson_darling"        # A-Dæª¢é©—
    BAYESIAN_MODEL_SELECTION = "bayesian_model_selection"  # è²æ°æ¨¡å‹é¸æ“‡
    CROSS_VALIDATION = "cross_validation"        # äº¤å‰é©—è­‰

# ========================================
# é…ç½®çµæ§‹
# ========================================

@dataclass
class EpsilonContaminationSpec:
    """
    Îµ-æ±¡æŸ“è¦æ ¼é…ç½®
    Îµ-Contamination specification configuration
    """
    epsilon_range: Tuple[float, float] = (0.01, 0.20)  # æ±¡æŸ“ç¨‹åº¦ç¯„åœ
    contamination_class: ContaminationDistributionClass = ContaminationDistributionClass.TYPHOON_SPECIFIC
    nominal_prior_family: str = "normal"                # åŸºæº–å…ˆé©—åˆ†ä½ˆæ—
    contamination_prior_family: str = "gev"             # æ±¡æŸ“å…ˆé©—åˆ†ä½ˆæ—
    robustness_criterion: RobustnessCriterion = RobustnessCriterion.WORST_CASE
    
    # é¢±é¢¨ç‰¹å®šåƒæ•¸
    typhoon_frequency_per_year: float = 3.2            # å¹´å‡é¢±é¢¨é »ç‡
    simulation_years: int = 365                         # æ¨¡æ“¬å¤©æ•¸
    
    def __post_init__(self):
        # é¡å‹è½‰æ›æ”¯æ´
        if isinstance(self.contamination_class, str):
            self.contamination_class = ContaminationDistributionClass(self.contamination_class)
        if isinstance(self.robustness_criterion, str):
            self.robustness_criterion = RobustnessCriterion(self.robustness_criterion)
    
    @property
    def empirical_epsilon(self) -> float:
        """åŸºæ–¼é¢±é¢¨é »ç‡çš„ç¶“é©—Îµå€¼"""
        return self.typhoon_frequency_per_year / self.simulation_years

@dataclass 
class ContaminationEstimateResult:
    """
    æ±¡æŸ“ç¨‹åº¦ä¼°è¨ˆçµæœ
    Contamination level estimation results
    """
    epsilon_estimates: Dict[str, float]          # ä¸åŒæ–¹æ³•çš„Îµä¼°è¨ˆ
    epsilon_consensus: float                     # å…±è­˜ä¼°è¨ˆ
    epsilon_uncertainty: float                  # ä¼°è¨ˆä¸ç¢ºå®šæ€§
    thresholds: Dict[str, float]                # å„ç¨®é–¾å€¼
    test_statistics: Dict[str, float]           # æª¢é©—çµ±è¨ˆé‡
    p_values: Dict[str, float]                  # på€¼
    method_weights: Dict[str, float]            # æ–¹æ³•æ¬Šé‡
    
    def __post_init__(self):
        if not self.epsilon_estimates:
            raise ValueError("è‡³å°‘éœ€è¦ä¸€å€‹Îµä¼°è¨ˆ")
        
        # å¦‚æœæ²’æœ‰æä¾›å…±è­˜ä¼°è¨ˆï¼Œè¨ˆç®—åŠ æ¬Šå¹³å‡
        if self.epsilon_consensus == 0:
            if self.method_weights:
                self.epsilon_consensus = sum(
                    self.method_weights.get(method, 1.0) * estimate 
                    for method, estimate in self.epsilon_estimates.items()
                ) / sum(self.method_weights.values())
            else:
                self.epsilon_consensus = np.mean(list(self.epsilon_estimates.values()))

@dataclass
class RobustPosteriorResult:
    """
    ç©©å¥å¾Œé©—çµæœ
    Robust posterior analysis results
    """
    worst_case_posterior: Dict[str, np.ndarray]   # æœ€å£æƒ…æ³å¾Œé©—
    best_case_posterior: Dict[str, np.ndarray]    # æœ€ä½³æƒ…æ³å¾Œé©—
    robust_credible_intervals: Dict[str, Tuple[float, float]]  # ç©©å¥å¯ä¿¡å€é–“
    sensitivity_analysis: Dict[str, Any]          # æ•æ„Ÿæ€§åˆ†æ
    robustness_measures: Dict[str, float]         # ç©©å¥æ€§æŒ‡æ¨™

# ========================================
# ç†è«–åŸºç¤å‡½æ•¸
# ========================================

def contamination_bound(epsilon: float, 
                       base_measure: float, 
                       contamination_measure: float) -> Tuple[float, float]:
    """
    è¨ˆç®—æ±¡æŸ“é‚Šç•Œ
    
    å°æ–¼ Ï€(Î¸) = (1-Îµ)Ï€â‚€(Î¸) + Îµq(Î¸)ï¼Œè¨ˆç®—æ¸¬åº¦çš„é‚Šç•Œ
    
    Parameters:
    -----------
    epsilon : float
        æ±¡æŸ“ç¨‹åº¦
    base_measure : float
        åŸºæº–åˆ†å¸ƒçš„æ¸¬åº¦å€¼
    contamination_measure : float
        æ±¡æŸ“åˆ†å¸ƒçš„æ¸¬åº¦å€¼
        
    Returns:
    --------
    Tuple[float, float]
        (ä¸‹ç•Œ, ä¸Šç•Œ)
    """
    lower_bound = (1 - epsilon) * base_measure
    upper_bound = (1 - epsilon) * base_measure + epsilon * contamination_measure
    return lower_bound, upper_bound

def worst_case_risk(epsilon: float,
                   risk_function: callable,
                   base_distribution: Any,
                   contamination_class: ContaminationDistributionClass) -> float:
    """
    è¨ˆç®—æœ€å£æƒ…æ³é¢¨éšª
    
    max_{qâˆˆQ} R[(1-Îµ)Ï€â‚€ + Îµq]
    
    Parameters:
    -----------
    epsilon : float
        æ±¡æŸ“ç¨‹åº¦
    risk_function : callable
        é¢¨éšªå‡½æ•¸
    base_distribution : 
        åŸºæº–åˆ†å¸ƒ
    contamination_class : ContaminationDistributionClass
        æ±¡æŸ“åˆ†å¸ƒé¡åˆ¥
        
    Returns:
    --------
    float
        æœ€å£æƒ…æ³é¢¨éšª
    """
    # ç°¡åŒ–å¯¦ç¾ - å¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›´è¤‡é›œçš„å„ªåŒ–
    base_risk = risk_function(base_distribution)
    
    # æ ¹æ“šæ±¡æŸ“é¡åˆ¥ä¼°è¨ˆæœ€å¤§å¯èƒ½é¢¨éšªå¢åŠ 
    if contamination_class == ContaminationDistributionClass.HEAVY_TAILED:
        contamination_multiplier = 10.0  # é‡å°¾åˆ†å¸ƒå¯èƒ½å¸¶ä¾†çš„é¢¨éšªå€æ•¸
    elif contamination_class == ContaminationDistributionClass.TYPHOON_SPECIFIC:
        contamination_multiplier = 5.0   # é¢±é¢¨ç‰¹å®šé¢¨éšªå€æ•¸
    else:
        contamination_multiplier = 2.0   # ä¸€èˆ¬æƒ…æ³
    
    worst_case = (1 - epsilon) * base_risk + epsilon * contamination_multiplier * base_risk
    return worst_case

def compute_robustness_radius(epsilon_max: float,
                            base_posterior: np.ndarray,
                            contamination_distributions: List[np.ndarray]) -> float:
    """
    è¨ˆç®—ç©©å¥æ€§åŠå¾‘
    
    è¡¡é‡åœ¨çµ¦å®šæ±¡æŸ“ç¨‹åº¦ä¸‹å¾Œé©—çš„è®ŠåŒ–ç¯„åœ
    
    Parameters:
    -----------
    epsilon_max : float
        æœ€å¤§æ±¡æŸ“ç¨‹åº¦
    base_posterior : np.ndarray
        åŸºæº–å¾Œé©—æ¨£æœ¬
    contamination_distributions : List[np.ndarray]
        å¯èƒ½çš„æ±¡æŸ“åˆ†å¸ƒæ¨£æœ¬
        
    Returns:
    --------
    float
        ç©©å¥æ€§åŠå¾‘
    """
    base_mean = np.mean(base_posterior)
    base_std = np.std(base_posterior)
    
    max_deviation = 0.0
    
    for contamination_samples in contamination_distributions:
        # è¨ˆç®—æ±¡æŸ“å¾Œçš„å¾Œé©—
        contaminated_posterior = (
            (1 - epsilon_max) * base_posterior[:len(contamination_samples)] + 
            epsilon_max * contamination_samples
        )
        
        contaminated_mean = np.mean(contaminated_posterior)
        contaminated_std = np.std(contaminated_posterior)
        
        # è¨ˆç®—æ¨™æº–åŒ–åå·®
        mean_deviation = abs(contaminated_mean - base_mean) / base_std
        std_deviation = abs(contaminated_std - base_std) / base_std
        
        total_deviation = mean_deviation + std_deviation
        max_deviation = max(max_deviation, total_deviation)
    
    return max_deviation

def sensitivity_to_epsilon(epsilon_values: np.ndarray,
                         base_distribution: Any,
                         contamination_distribution: Any,
                         metric_function: callable) -> Dict[str, np.ndarray]:
    """
    åˆ†æå°Îµçš„æ•æ„Ÿæ€§
    
    Parameters:
    -----------
    epsilon_values : np.ndarray
        Îµå€¼ç¯„åœ
    base_distribution : 
        åŸºæº–åˆ†å¸ƒ
    contamination_distribution : 
        æ±¡æŸ“åˆ†å¸ƒ
    metric_function : callable
        åº¦é‡å‡½æ•¸
        
    Returns:
    --------
    Dict[str, np.ndarray]
        æ•æ„Ÿæ€§åˆ†æçµæœ
    """
    metrics = []
    
    for eps in epsilon_values:
        # æ¨¡æ“¬æ··åˆåˆ†å¸ƒ
        mixed_distribution = create_mixed_distribution(
            base_distribution, contamination_distribution, eps
        )
        
        # è¨ˆç®—åº¦é‡
        metric_value = metric_function(mixed_distribution)
        metrics.append(metric_value)
    
    metrics = np.array(metrics)
    
    return {
        "epsilon_values": epsilon_values,
        "metric_values": metrics,
        "sensitivity": np.gradient(metrics, epsilon_values),
        "max_sensitivity": np.max(np.abs(np.gradient(metrics, epsilon_values))),
        "sensitivity_at_zero": np.gradient(metrics, epsilon_values)[0] if len(metrics) > 1 else 0
    }

def create_mixed_distribution(base_dist: Any, 
                            contamination_dist: Any, 
                            epsilon: float) -> Any:
    """
    å‰µå»ºæ··åˆåˆ†å¸ƒ Ï€(Î¸) = (1-Îµ)Ï€â‚€(Î¸) + Îµq(Î¸)
    
    Parameters:
    -----------
    base_dist : 
        åŸºæº–åˆ†å¸ƒ
    contamination_dist : 
        æ±¡æŸ“åˆ†å¸ƒ
    epsilon : float
        æ··åˆæ¬Šé‡
        
    Returns:
    --------
    æ··åˆåˆ†å¸ƒå°è±¡
    """
    # é€™æ˜¯ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ›´è¤‡é›œçš„åˆ†å¸ƒè™•ç†
    class MixedDistribution:
        def __init__(self, base, contamination, eps):
            self.base = base
            self.contamination = contamination
            self.epsilon = eps
        
        def rvs(self, size=1000):
            """ç”Ÿæˆæ··åˆåˆ†å¸ƒæ¨£æœ¬"""
            n_contamination = int(size * self.epsilon)
            n_base = size - n_contamination
            
            if hasattr(self.base, 'rvs'):
                base_samples = self.base.rvs(n_base)
            else:
                base_samples = np.random.choice(self.base, n_base)
            
            if hasattr(self.contamination, 'rvs'):
                contamination_samples = self.contamination.rvs(n_contamination)
            else:
                contamination_samples = np.random.choice(self.contamination, n_contamination)
            
            mixed_samples = np.concatenate([base_samples, contamination_samples])
            np.random.shuffle(mixed_samples)
            return mixed_samples
        
        def mean(self):
            """æ··åˆåˆ†å¸ƒå‡å€¼"""
            if hasattr(self.base, 'mean'):
                base_mean = self.base.mean()
            else:
                base_mean = np.mean(self.base)
                
            if hasattr(self.contamination, 'mean'):
                contamination_mean = self.contamination.mean()
            else:
                contamination_mean = np.mean(self.contamination)
            
            return (1 - self.epsilon) * base_mean + self.epsilon * contamination_mean
    
    return MixedDistribution(base_dist, contamination_dist, epsilon)

# ========================================
# æ±¡æŸ“åˆ†å¸ƒç”Ÿæˆå™¨
# ========================================

class ContaminationDistributionGenerator:
    """æ±¡æŸ“åˆ†å¸ƒç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_typhoon_specific(location: float = 0, 
                                scale: float = 1, 
                                shape: float = 0.1) -> stats.genextreme:
        """
        ç”Ÿæˆé¢±é¢¨ç‰¹å®šçš„æ¥µå€¼åˆ†å¸ƒ
        
        Parameters:
        -----------
        location : float
            ä½ç½®åƒæ•¸
        scale : float
            å°ºåº¦åƒæ•¸
        shape : float
            å½¢ç‹€åƒæ•¸
            
        Returns:
        --------
        scipy.stats.genextreme
            å»£ç¾©æ¥µå€¼åˆ†å¸ƒ
        """
        return stats.genextreme(c=shape, loc=location, scale=scale)
    
    @staticmethod
    def generate_heavy_tailed(df: float = 3, 
                            location: float = 0, 
                            scale: float = 1) -> stats.t:
        """
        ç”Ÿæˆé‡å°¾åˆ†å¸ƒ (Student-t)
        
        Parameters:
        -----------
        df : float
            è‡ªç”±åº¦
        location : float
            ä½ç½®åƒæ•¸
        scale : float
            å°ºåº¦åƒæ•¸
            
        Returns:
        --------
        scipy.stats.t
            Student-tåˆ†å¸ƒ
        """
        return stats.t(df=df, loc=location, scale=scale)
    
    @staticmethod
    def generate_moment_bounded(a: float = -2, 
                              b: float = 2) -> stats.uniform:
        """
        ç”ŸæˆçŸ©æœ‰ç•Œåˆ†å¸ƒ (å‡å‹»åˆ†å¸ƒ)
        
        Parameters:
        -----------
        a : float
            ä¸‹ç•Œ
        b : float
            ä¸Šç•Œ
            
        Returns:
        --------
        scipy.stats.uniform
            å‡å‹»åˆ†å¸ƒ
        """
        return stats.uniform(loc=a, scale=b-a)

def test_contamination_theory():
    """æ¸¬è©¦æ±¡æŸ“ç†è«–åŠŸèƒ½"""
    print("ğŸ§ª æ¸¬è©¦æ±¡æŸ“ç†è«–æ¨¡çµ„...")
    
    # æ¸¬è©¦åŸºæœ¬é…ç½®
    print("âœ… æ¸¬è©¦Îµ-contaminationè¦æ ¼:")
    spec = EpsilonContaminationSpec()
    print(f"   ç¶“é©—Îµå€¼: {spec.empirical_epsilon:.4f}")
    print(f"   æ±¡æŸ“é¡åˆ¥: {spec.contamination_class.value}")
    
    # æ¸¬è©¦æ±¡æŸ“é‚Šç•Œè¨ˆç®—
    print("âœ… æ¸¬è©¦æ±¡æŸ“é‚Šç•Œ:")
    lower, upper = contamination_bound(0.1, 5.0, 15.0)
    print(f"   é‚Šç•Œ: [{lower:.2f}, {upper:.2f}]")
    
    # æ¸¬è©¦åˆ†å¸ƒç”Ÿæˆå™¨
    print("âœ… æ¸¬è©¦åˆ†å¸ƒç”Ÿæˆå™¨:")
    typhoon_dist = ContaminationDistributionGenerator.generate_typhoon_specific()
    samples = typhoon_dist.rvs(100)
    print(f"   é¢±é¢¨åˆ†å¸ƒæ¨£æœ¬å‡å€¼: {np.mean(samples):.3f}")
    
    print("âœ… æ±¡æŸ“ç†è«–æ¸¬è©¦å®Œæˆ")

if __name__ == "__main__":
    test_contamination_theory()