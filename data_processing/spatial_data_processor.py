#!/usr/bin/env python3
"""
Spatial Data Processor for Hierarchical Bayesian Model
ç©ºé–“æ•¸æ“šè™•ç†æ¨¡çµ„

å°ˆé–€è™•ç†ï¼š
1. çœŸå¯¦é†«é™¢åº§æ¨™ â†’ è·é›¢çŸ©é™£è¨ˆç®—
2. åœ°ç†å€åŸŸè‡ªå‹•åˆ†é…
3. Cat-in-Circleæ•¸æ“šé è™•ç†
4. ç‚ºéšå±¤æ¨¡å‹æä¾›æ­£ç¢ºçš„ç©ºé–“çµæ§‹æ•¸æ“š

ç”¨æ³•ï¼š
from robust_hierarchical_bayesian_simulation.spatial_data_processor import SpatialDataProcessor
processor = SpatialDataProcessor()
spatial_data = processor.process_hospital_spatial_data(hospital_coords, cat_in_circle_data)
"""

import numpy as np
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from sklearn.cluster import KMeans
import warnings

@dataclass
class SpatialData:
    """ç©ºé–“æ•¸æ“šçµæ§‹"""
    hospital_coords: np.ndarray          # (n_hospitals, 2) lat,lon
    distance_matrix: np.ndarray          # (n_hospitals, n_hospitals) km
    region_assignments: np.ndarray       # (n_hospitals,) region indices
    n_hospitals: int
    n_regions: int
    
    # Cat-in-Circleæ•¸æ“š
    hazard_intensities: Optional[np.ndarray] = None  # (n_hospitals, n_events) H_ij
    exposure_values: Optional[np.ndarray] = None     # (n_hospitals,) E_i
    observed_losses: Optional[np.ndarray] = None     # (n_hospitals, n_events) L_ij
    

class SpatialDataProcessor:
    """ç©ºé–“æ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self):
        self.spatial_data = None
        
    def process_hospital_spatial_data(self,
                                    hospital_coords: np.ndarray,
                                    n_regions: int = 3,
                                    region_method: str = "geographic") -> SpatialData:
        """
        è™•ç†é†«é™¢ç©ºé–“æ•¸æ“š
        
        Parameters:
        -----------
        hospital_coords : np.ndarray, shape (n_hospitals, 2)
            é†«é™¢åº§æ¨™ [lat, lon]
        n_regions : int
            å€åŸŸæ•¸é‡ï¼Œé è¨­3 (æ²¿æµ·/å…§é™¸/å±±å€)
        region_method : str
            å€åŸŸåˆ†é…æ–¹æ³• "geographic" æˆ– "risk_based"
            
        Returns:
        --------
        SpatialData : è™•ç†å¾Œçš„ç©ºé–“æ•¸æ“š
        """
        n_hospitals = len(hospital_coords)
        
        print(f"ğŸ—ºï¸ è™•ç†é†«é™¢ç©ºé–“æ•¸æ“š...")
        print(f"   é†«é™¢æ•¸é‡: {n_hospitals}")
        print(f"   åº§æ¨™ç¯„åœ: lat [{hospital_coords[:,0].min():.3f}, {hospital_coords[:,0].max():.3f}]")
        print(f"              lon [{hospital_coords[:,1].min():.3f}, {hospital_coords[:,1].max():.3f}]")
        
        # è¨ˆç®—è·é›¢çŸ©é™£
        distance_matrix = self._calculate_haversine_distance_matrix(hospital_coords)
        print(f"   è·é›¢ç¯„åœ: {distance_matrix[distance_matrix > 0].min():.1f} - {distance_matrix.max():.1f} km")
        
        # å€åŸŸåˆ†é…
        if region_method == "geographic":
            region_assignments = self._assign_geographic_regions(hospital_coords, n_regions)
        elif region_method == "risk_based":
            region_assignments = self._assign_risk_based_regions(hospital_coords, n_regions)
        else:
            raise ValueError(f"æœªçŸ¥çš„å€åŸŸåˆ†é…æ–¹æ³•: {region_method}")
            
        region_counts = np.bincount(region_assignments)
        print(f"   å€åŸŸåˆ†é…: {dict(enumerate(region_counts))}")
        
        self.spatial_data = SpatialData(
            hospital_coords=hospital_coords,
            distance_matrix=distance_matrix,
            region_assignments=region_assignments,
            n_hospitals=n_hospitals,
            n_regions=n_regions
        )
        
        return self.spatial_data
    
    def add_cat_in_circle_data(self,
                              hazard_intensities: np.ndarray,
                              exposure_values: np.ndarray,
                              observed_losses: np.ndarray) -> SpatialData:
        """
        æ·»åŠ Cat-in-Circleæ•¸æ“š
        
        Parameters:
        -----------
        hazard_intensities : np.ndarray, shape (n_hospitals, n_events)
            ç½å®³å¼·åº¦ H_ij (ä¾†è‡ªCat-in-Circleåˆ†æ)
        exposure_values : np.ndarray, shape (n_hospitals,)
            æ›éšªåƒ¹å€¼ E_i
        observed_losses : np.ndarray, shape (n_hospitals, n_events)
            è§€æ¸¬æå¤± L_ij
        """
        if self.spatial_data is None:
            raise ValueError("è«‹å…ˆèª¿ç”¨process_hospital_spatial_data()")
            
        n_hospitals, n_events = hazard_intensities.shape
        
        if n_hospitals != self.spatial_data.n_hospitals:
            raise ValueError(f"é†«é™¢æ•¸é‡ä¸åŒ¹é…: {n_hospitals} vs {self.spatial_data.n_hospitals}")
            
        print(f"ğŸŒªï¸ æ·»åŠ Cat-in-Circleæ•¸æ“š...")
        print(f"   äº‹ä»¶æ•¸é‡: {n_events}")
        print(f"   ç½å®³å¼·åº¦ç¯„åœ: {hazard_intensities.min():.1f} - {hazard_intensities.max():.1f}")
        print(f"   æ›éšªåƒ¹å€¼ç¸½å’Œ: ${exposure_values.sum():,.0f}")
        print(f"   æå¤±ç¯„åœ: ${observed_losses.min():,.0f} - ${observed_losses.max():,.0f}")
        
        self.spatial_data.hazard_intensities = hazard_intensities
        self.spatial_data.exposure_values = exposure_values  
        self.spatial_data.observed_losses = observed_losses
        
        return self.spatial_data
    
    def get_spatial_correlation_matrix(self, 
                                     spatial_range: float = 50.0,
                                     nugget: float = 0.01) -> np.ndarray:
        """
        è¨ˆç®—ç©ºé–“ç›¸é—œçŸ©é™£
        
        Parameters:
        -----------
        spatial_range : float
            ç©ºé–“ç›¸é—œç¯„åœ (km)
        nugget : float
            nuggetæ•ˆæ‡‰ (æœ€å°ç›¸é—œå€¼)
            
        Returns:
        --------
        np.ndarray : ç©ºé–“ç›¸é—œçŸ©é™£ (n_hospitals, n_hospitals)
        """
        if self.spatial_data is None:
            raise ValueError("è«‹å…ˆè™•ç†ç©ºé–“æ•¸æ“š")
            
        # æŒ‡æ•¸è¡°æ¸›ç›¸é—œ: exp(-distance / range)
        correlation_matrix = np.exp(-self.spatial_data.distance_matrix / spatial_range)
        
        # æ·»åŠ nuggetæ•ˆæ‡‰
        np.fill_diagonal(correlation_matrix, 1.0 + nugget)
        
        return correlation_matrix
    
    def _calculate_haversine_distance_matrix(self, coords: np.ndarray) -> np.ndarray:
        """è¨ˆç®—Haversineè·é›¢çŸ©é™£ (km)"""
        def haversine_distance(lat1, lon1, lat2, lon2):
            R = 6371.0  # åœ°çƒåŠå¾‘ km
            
            lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
            dlat = lat2 - lat1
            dlon = lon2 - lon1
            
            a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
            c = 2 * np.arcsin(np.sqrt(a))
            
            return R * c
        
        n = len(coords)
        distance_matrix = np.zeros((n, n))
        
        for i in range(n):
            for j in range(i+1, n):
                dist = haversine_distance(coords[i,0], coords[i,1], 
                                        coords[j,0], coords[j,1])
                distance_matrix[i,j] = distance_matrix[j,i] = dist
        
        return distance_matrix
    
    def _assign_geographic_regions(self, coords: np.ndarray, n_regions: int) -> np.ndarray:
        """åŸºæ–¼åœ°ç†ä½ç½®çš„å€åŸŸåˆ†é… (K-meansèšé¡)"""
        kmeans = KMeans(n_clusters=n_regions, random_state=42, n_init=10)
        region_assignments = kmeans.fit_predict(coords)
        
        return region_assignments
    
    def _assign_risk_based_regions(self, coords: np.ndarray, n_regions: int) -> np.ndarray:
        """åŸºæ–¼é¢¨éšªçš„å€åŸŸåˆ†é… (ä¾‹å¦‚ï¼šæ²¿æµ·è·é›¢)"""
        # ç°¡åŒ–å¯¦ç¾ï¼šåŸºæ–¼ç¶“åº¦åˆ†é… (æ±éƒ¨æ²¿æµ· vs è¥¿éƒ¨å…§é™¸)
        lons = coords[:, 1]
        
        if n_regions == 2:
            # æ²¿æµ· vs å…§é™¸
            coastal_threshold = np.percentile(lons, 40)  # æ±éƒ¨40%ç‚ºæ²¿æµ·
            regions = (lons > coastal_threshold).astype(int)
        elif n_regions == 3:
            # æ²¿æµ· / ä¸­éƒ¨ / å±±å€
            coastal_threshold = np.percentile(lons, 33)
            mountain_threshold = np.percentile(lons, 67)
            regions = np.zeros(len(lons), dtype=int)
            regions[lons > coastal_threshold] = 1  # æ²¿æµ·
            regions[lons < mountain_threshold] = 2  # å±±å€
        else:
            # å›åˆ°åœ°ç†èšé¡
            return self._assign_geographic_regions(coords, n_regions)
            
        return regions


def load_spatial_data_from_02_results(spatial_analysis_path: str) -> Optional[SpatialData]:
    """
    å¾02_spatial_analysis.pyçš„çµæœè¼‰å…¥ç©ºé–“æ•¸æ“š
    
    Parameters:
    -----------
    spatial_analysis_path : str
        ç©ºé–“åˆ†æçµæœè·¯å¾‘ (é€šå¸¸æ˜¯ "results/spatial_analysis/cat_in_circle_results.pkl")
        
    Returns:
    --------
    Optional[SpatialData] : ç©ºé–“æ•¸æ“šï¼Œå¦‚æœè¼‰å…¥å¤±æ•—å‰‡è¿”å›None
    """
    try:
        import pickle
        with open(spatial_analysis_path, 'rb') as f:
            spatial_results = pickle.load(f)
        
        print(f"ğŸ“‚ è¼‰å…¥02ç©ºé–“åˆ†æçµæœ...")
        
        if 'hospital_coordinates' in spatial_results and 'hospitals' in spatial_results:
            processor = SpatialDataProcessor()
            
            # è™•ç†é†«é™¢ç©ºé–“æ•¸æ“š
            spatial_data = processor.process_hospital_spatial_data(
                hospital_coords=spatial_results['hospital_coordinates'],
                n_regions=3
            )
            
            # å¦‚æœæœ‰Cat-in-Circleæ•¸æ“šä¹ŸåŠ å…¥
            if 'indices' in spatial_results:
                indices = spatial_results['indices']
                # é¸æ“‡50kmä½œç‚ºä¸»è¦æŒ‡æ¨™
                if 'cat_in_circle_50km_max' in indices:
                    n_events = len(indices['cat_in_circle_50km_max'])
                    n_hospitals = len(spatial_results['hospital_coordinates'])
                    
                    # å‰µå»ºç½å®³å¼·åº¦çŸ©é™£ (æ‰€æœ‰é†«é™¢ä½¿ç”¨ç›¸åŒçš„é¢¨é€Ÿåºåˆ—)
                    hazard_intensities = np.tile(
                        indices['cat_in_circle_50km_max'], 
                        (n_hospitals, 1)
                    )
                    
                    # æ¨¡æ“¬æ›éšªåƒ¹å€¼å’Œè§€æ¸¬æå¤± (å¯¦éš›æ‡‰ç”¨ä¸­é€™äº›ä¾†è‡ªCLIMADA)
                    exposure_values = np.random.uniform(1e7, 5e7, n_hospitals)
                    observed_losses = np.random.lognormal(15, 1, (n_hospitals, n_events))
                    
                    spatial_data = processor.add_cat_in_circle_data(
                        hazard_intensities, exposure_values, observed_losses
                    )
            
            print(f"âœ… æˆåŠŸè¼‰å…¥ç©ºé–“æ•¸æ“š: {spatial_data.n_hospitals}å®¶é†«é™¢")
            return spatial_data
            
        else:
            print(f"âš ï¸ 02çµæœä¸­ç¼ºå°‘é†«é™¢æ•¸æ“š")
            return None
            
    except Exception as e:
        print(f"âŒ è¼‰å…¥02çµæœå¤±æ•—: {e}")
        return None


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # æ¸¬è©¦ç©ºé–“æ•¸æ“šè™•ç†
    np.random.seed(42)
    
    # æ¨¡æ“¬åŒ—å¡é†«é™¢åº§æ¨™
    hospital_coords = np.random.uniform([35.0, -84.0], [36.5, -75.5], (10, 2))
    
    # è™•ç†ç©ºé–“æ•¸æ“š
    processor = SpatialDataProcessor()
    spatial_data = processor.process_hospital_spatial_data(hospital_coords, n_regions=3)
    
    # æ·»åŠ Cat-in-Circleæ•¸æ“š
    n_hospitals, n_events = 10, 50
    hazard_intensities = np.random.uniform(20, 60, (n_hospitals, n_events))
    exposure_values = np.random.uniform(1e7, 5e7, n_hospitals)
    observed_losses = np.random.lognormal(15, 1, (n_hospitals, n_events))
    
    spatial_data = processor.add_cat_in_circle_data(
        hazard_intensities, exposure_values, observed_losses
    )
    
    # è¨ˆç®—ç©ºé–“ç›¸é—œçŸ©é™£
    correlation_matrix = processor.get_spatial_correlation_matrix()
    print(f"\nç©ºé–“ç›¸é—œç¯„åœ: {correlation_matrix.min():.3f} - {correlation_matrix.max():.3f}")